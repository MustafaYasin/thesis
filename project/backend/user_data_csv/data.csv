,username,fullName,bio,email,readme,location,isHireable,company,yearsofExperience,domainofExpertise,activity,feature_1,feature_2,feature_3,totalOfFeatures,isEmployee,avatar_url,createdAt,updatedAt,twitterUsername,isGitHubStar,isCampusExpert,isDeveloperProgramMember,isSiteAdmin,isViewer,anyPinnableItems,viewerIsFollowing,sponsors,followers,following,organizations,repository_count,star_time,primary_language
C,alexbw,Alex Wiltschko,,alex.bw@gmail.com,"Sampling Inference for Bayesian HSMMs and HMMs 
 This is a Python library for approximate unsupervised sampling inference in
Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov
Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM
and HDP-HSMM, via the weak-limit approximation. 
 There are also some plugins to extend the functionality: 
 
 factorial models 
 autoregressive models 
 collapsed HDP sampling inference . 
 
 The inference can be run in parallel over multiple cores and/or multiple
machines (even on EC2!) using  ipython 's
excellent  ipython.parallel  module. Someday I might even document how to do
it! 
 Installing 
 You can clone this library and its dependencies with 
 git clone --recursive git://github.com/mattjj/pyhsmm.git 
 The library depends on  numpy ,  scipy , and, for visualization,  matplotlib . 
 Disabling assertions may speed things up; to disable assertions, run your
CPython interpreter with the  -O  flag. 
 A Simple Demonstration 
 Here's how to draw from the HDP-HSMM posterior over HSMMs given a sequence of
observations. (The same example, along with the code to generate the synthetic
data loaded in this example, can be found in  examples/basic.py .) 
 Let's say we have some 2D data in a data.txt file: 
 bash
 head -5 data.txt
-3.711962552600095444e-02 1.456401745267922598e-01
7.553818775915704942e-02 2.457422192223903679e-01
-2.465977987699214502e+00 5.537627981813508793e-01
-7.031638516485749779e-01 1.536468304146855757e-01
-9.224669847039665971e-01 3.680035337673161489e-01 
 In Python, we can plot the data in a 2D plot, collapsing out the time dimension: 
 ```python
import numpy as np
from matplotlib import pyplot as plt 
 data = np.loadtxt('data.txt')
plt.plot(data[:,0],data[:,1],'kx')
``` 
 
 We can also make a plot of time versus the first principal component: 
 python
from pyhsmm.util.plot import pca_project_data
plt.plot(pca_project_data(data,1)) 
 
 To learn an HSMM, we'll use  pyhsmm  to create an  HSMM  instance using some
reasonable hyperparameters. We'll ask this model to infer the number of states
as well (since an HDP-HSMM is instantiated by default), so we'll give it an
 Nmax  parameter: 
 ```python
import pyhsmm
import pyhsmm.basic.distributions as distributions 
 obs_dim = 2
Nmax = 25 
 obs_hypparams = {'mu_0':np.zeros(obs_dim),
                'sigma_0':np.eye(obs_dim),
                'kappa_0':0.3,
                'nu_0':obs_dim+5}
dur_hypparams = {'alpha_0':2*30,
                 'beta_0':2} 
 obs_distns = [distributions.Gaussian( obs_hypparams) for state in range(Nmax)]
dur_distns = [distributions.PoissonDuration( dur_hypparams) for state in range(Nmax)] 
 posteriormodel = pyhsmm.models.HSMM(
        alpha=6.,gamma=6., # better to sample over these; see concentration-resampling.py
        init_state_concentration=6., # pretty inconsequential
        obs_distns=obs_distns,
        dur_distns=dur_distns,
        trunc=60) # duration truncation speeds things up when it's possible
``` 
 (The first two arguments set the ""new-table"" proportionality constant for the
meta-Chinese Restaurant Process and the other CRPs, respectively, in the HDP
prior on transition matrices. For this example, they really don't matter at
all, but on real data it's much better to infer these parameters, as in
 examples/concentration_resampling.py .) 
 The  trunc  parameter is an optional argument that can speed up inference: it
sets a truncation limit on the maximum duration for any state. If you don't
pass in the  trunc  argument, no truncation is used and all possible state
duration lengths are considered. 
 Then, we add the data we want to condition on: 
 python
posteriormodel.add_data(data) 
 (If we had multiple observation sequences to learn from, we could add them to the
model just by calling  add_data()  for each observation sequence.) 
 Now we run a resampling loop. For each iteration of the loop, all the latent
variables of the model will be resampled by Gibbs sampling steps, including the
transition matrix, the observation means and covariances, the duration
parameters, and the hidden state sequence. We'll also copy some samples so that
we can plot them. 
 python
models = []
for idx in progprint_xrange(150):
    posteriormodel.resample_model()
    if (idx+1) % 10 == 0:
        models.append(copy.deepcopy(posteriormodel)) 
 Now we can plot our saved samples: 
 python
fig = plt.figure()
for idx, model in enumerate(models):
    plt.clf()
    model.plot()
    plt.gcf().suptitle('HDP-HSMM sampled after %d iterations' % (10*(idx+1)))
    plt.savefig('iter_%.3d.png' % (10*(idx+1))) 
 
 I generated these data from an HSMM that looked like this: 
 
 So the posterior samples look pretty good! 
 Speed 
 HSMMs constitute a much more powerful model class than plain-old HMMs, and that
enhanced power comes with a computational price: each sampling iteration for an
HSMM is much slower than that of an HMM. But that price is often worthwhile if
you want to place priors on state durations or have the model learn duration
structure present in the data. (In the example, strong duration structure is
what made the inference algorithm latch onto the correct explanation so
easily.) In addition, the increased cost of each iteration often pays for
itself, since HSMM samplers empirically seem to take fewer iterations to
converge than comparable HMM samplers. 
 Using my nothing-special i7-920 desktop machine and a NumPy/SciPy built against
Intel's MKL BLAS (which generally outperforms ATLAS for vectorized operations)
along with the Eigen-backed classes, here's how long the demo iterations took: 
 $ python examples/hsmm.py
.........................  [  25/100,    0.05sec avg,    3.95sec ETA ]
.........................  [  50/100,    0.05sec avg,    2.64sec ETA ]
.........................  [  75/100,    0.05sec avg,    1.34sec ETA ]
.........................  [ 100/100,    0.05sec avg,    0.05sec ETA ]
   0.05sec avg,    5.21sec total 
 Extending the Code 
 To add your own observation or duration distributions, implement the interfaces
defined in  basic/abstractions.py . Also see the plugins. To get a flavor of
the style, see  pybasicbayes . 
 Contributors 
 Contributions by Chia-ying Lee. 
 References 
 
 
 Matthew J. Johnson and Alan S. Willsky.  Bayesian Nonparametric Hidden
  Semi-Markov Models .
  Journal of Machine Learning Research (JMLR), 14:673â€“701, February 2013. 
 
 
 Matthew J. Johnson and Alan S. Willsky,  The Hierarchical Dirichlet Process
  Hidden Semi-Markov Model . 26th
  Conference on Uncertainty in Artificial Intelligence (UAI 2010), Avalon,
  California, July 2010. 
 
 
 bibtex
@article{johnson2013hdphsmm,
    title={Bayesian Nonparametric Hidden Semi-Markov Models},
    author={Johnson, Matthew J. and Willsky, Alan S.},
    journal={Journal of Machine Learning Research},
    pages={673--701},
    volume={14},
    month={February},
    year={2013},
}An analgesic for high-performance audio on iOS and OSX. 
 Really fast audio in iOS and Mac OS X using Audio Units is hard, and will leave you scarred and bloody. What used to take days can now be done with just a few lines of code. 
 Getting Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setInputBlock:^(float *newAudio, UInt32 numSamples, UInt32 numChannels) {
    // Now you're getting audio from the microphone every 20 milliseconds or so. How's that for easy?
    // Audio comes in interleaved, so,
    // if numChannels = 2, newAudio[0] is channel 1, newAudio[1] is channel 2, newAudio[2] is channel 1, etc.
}];
[audioManager play]; 
 Playing Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setOutputBlock:^(float *audioToPlay, UInt32 numSamples, UInt32 numChannels) {
    // All you have to do is put your audio into ""audioToPlay"".
}];
[audioManager play]; 
 Does anybody actually use it? 
 Yep. Novocaine is result of three years of work on the audio engine of  Octave ,  Fourier  and  oScope , a powerful suite of audio analysis apps. Please do check them out! 
 A thing to note: 
 The RingBuffer class is written in C++ to make things extra zippy, so the classes that use it will have to be Objective-C++. Change all the files that use RingBuffer from MyClass.m to MyClass.mm. 
 Want some examples? 
 Inside of ViewController.mm are a bunch of tiny little examples I wrote. Uncomment one and see how it sounds. 
Do note, however, for examples involving play-through, that you should be using headphones. Having the 
mic and speaker close to each other will produce some gnarly feedback.   
 Want to learn the nitty-gritty of Core Audio? 
 If you want to get down and dirty, if you want to get brave and get close to the hardware, I can only point you to the places where I learned how to do this stuff. Chris Adamson and Michael Tyson are two giants in the field of iOS audio, and they each wrote indispensable blog posts ( this is Chris's ,  this is Michael's ). Also, Chris Adamson now has a  whole gosh-darned BOOK on Core Audio . I would have done unspeakable things to get my hands on this when I was first starting. 
My Code for the Netflix Prize 
 I'm not aware of folks having published their code for the Netflix Prize. Here's mine. 
Under the team name ""Hi!"", I competed alone in college. I did it mostly for fun, and to learn modern machine learning techniques. It was an incredibly valuable, but strenuous, time. Well worth it on all fronts, though.  
I peaked out at #45 or so, and then dropped out to work on my senior thesis, and came in #145 or so.   
What I learned in the process was that smarter wasn't always better -- make an algorithm, and then scale it up, and then make a dozen tweaks to it, and then average all of the results together. That's how you climbed the leaderboard.    
 Anyhoo, I haven't touched this code in awhile, but perhaps it'll be useful to folks interested in competitive data mining. 
Specifically, the lessons I learned: 
 
 Get the raw data into a saved and manageable format  fast . The easier it is to load your data in and start mutating it, the better. 
 If doing simple pivots on your data is hard, and slows you down from visualizing whats in your data, spend time making data structures which make that easy.   
 Generalize. Iterate. If you have a method you think will work, but it has a lot of knobs, and you don't know the best way to set those knobs, make it easy for you to try  every possible iteration . There is often not a good way to figure out what the  best  approach is. You will have to try many of them in order to build up an intuition. Specifically, that means (for me) a pluggable architecture. If there's ten ways to try a particular step, make sure you write your overarching algorithm so that it takes a function that you can pass to it, as opposed to having a method hardwired in the code. That way, you can hotswap all your ideas.   
 Speed is a feature. Of course you make sure it works first. But your goal is to see if something works. If an algorithm takes a day to run, but you can spend five hours making it run in 1/3 of a day, do it. You'll be running it over and over again, and you'll learn more if you can iterate.  
 
 As for the technical nitty-gritty, everything that's speed sensitive is written in Cython, which was the best balance of speed and convenience in 2009. If I were to do it al again, I would use (Numba)[http://github.com/numba/numba].   
 The original data is gone, I believe, but I might have it stored somewhere. I'll look for that.  NURBS - Non Uniform Rational B-Splines. 
 This python module is a revival and update of Runar Tenfjord's NURBS toolbox, which itself
is a port of Mark Spink's SCILAB/MATLAB tolbox to python with help of numpy. 
 Dependency 
 Python 2.0 or above 
NumPy 
Dislin -> optional but recomended 
PyOpenGL -> optional   
 Installation 
 Just run   python setup.py install   
 License 
 Runar Tenfjord originally relased this package under the GPL Version 2 license,  
so I suppose that means it has to stay that way.    
 Originally by: Runar Tenfjord, runten@netcom.no 
Minor updates to work with NumPy by Alex Wiltschko  cuda-tests 
 Gotta learn some CUDA stuffpypatent 
 Scrape patents from the USPTOairruler 
 A ruler. Made of air. paralleltools 
 A summary of parallelizing moderate amounts of work in Pythonnsgt 
 Non-stationary Gabor transforms (GitHub mirror of http://grrrr.org/research/software/nsgt/)IDA 
 This code accompanies the publication from the Whitesides lab to Lab on a Chip, concerning automated analysis of red blood cell health using affordable field tests. Specifically, this code implements the automated extraction of scanned AMPS tubes from flatbed scanner images, the distillation of those images into 1D data traces, and then the automated identification of the anemic disease state of the blood in those 1D data traces, as well as the prediction of continuously-varying red blood cell (RBC) parameters. 
 Installation 
 This code requires Python, as well as some extra 3rd-party libraries. All routines have only been tested on Mac OS, but should work on Linux. No guarantees for Windows.
1) First, we recommend using the ""Anaconda"" Python distribution, specifically the Python 2.7 version.  Download and install here .
1) With anaconda installed, you will need one extra library, to read TIFF files.
 pip install imageio 
1) You should be able to run the notebooks now. Inside this code repository, start up an IPython notebook:
 jupyter notebook 
1) You should now be able to browser around the ""extraction"" and ""analysis"" folders, which contain the relevant code. 
 Running extraction 
 The first step required will be to prepare the raw data of TIFF file scans of 4x3=12 tubes from a flatbed scanner. We will also have to associate metadata for each patient that the blood in a tube was drawn from.
Our end goal will be a 1D array for each tube, along with the corresponding patient data (anemic state & RBC parameters). 
 The extraction algorithm is explained step-by-step in the notebook  extraction/Explaining the Extraction Algorithm.ipynb .
The implementation we use in the paper (which also fuses patient metadata with AMPS image data) can be found in  extraction/Data Extraction Pipeline.ipynb . Most of the code in this notebook is specific to the particular Excel file format that we used to record patient metadata, and may have to be largely rewritten for reuse. 
 Running analysis 
 There are two sets of analyses done in the paper: classification and regression. 
 Running classification analysis 
 The goal of this analysis is to predict disease state only from the 1D data trace extracted from each AMPS tube. We use logistic regression, a linear classifier, and transform the 1D data representation using PCA to remove redundancy and constrain the input dimensionality of the problem. We also used Bayesian Optimization (bayesopt) to tune the hyperparameters of the problem, including the specific output dimension of PCA, the regularization parameter of logistic regression, and some image preprocessing parameters. Unfortunately, the service we used for bayesopt is no longer available. If you would like to automatically tune these parameters, we recommend either using random search (a surprisingly effective hueristic), or the open source library ""Spearmint"", upon which the now-defunct service we used was based, or products from the company SigOpt, which also implements bayesopt. The file we used to automatically tune these hypers is  classify.py .
The best set of hyperparameters is stored in the notebook  Analyzing best classification.ipynb .
This notebook examines ROC performance of the classifier for discriminating different anemia types, as well as the effect of centrifugation time of the tube on IDA classification AUC performance. 
 Running regression analysis. 
 Similar to above, we used a defunct bayesopt service to automatically tune some parameters of this algorithm. The original file is in  regress.py . The original methodology will work well, even without automated tuning.
The best set of hyperparameters is stored in the notebook  Analyzing best regression.ipynb . 
 License 
 See the LICENSE file. It is under a GPL license, and this code may only be used for academic purposes.adabayes 
 To do: 
 
 [x] Find candidate last layer features (DeCAF, Overfeat) 
 [x] Find AlexNet code (5 convolutional layers with max-pooling, then three fully connected layers) 
 [X]  Find download script for MNIST dataset 
 [X]  Find download script for CIFAR10 dataset 
 [x] Fork torch-dist repo 
 [x] Update torch-dist repo for OS X 10.10 install 
 [x] Add new required submodules to distro (nnx, iTorch, ccn2, cunnx, cudnn, sdl2, cutorch) 
 [x] Figure out model serialization and loading 
 Built-in model serialization.  Loading  and  saving . 
 There is also facebook's  Thrift library , which I haven't seen many examples for. 
 
 
 [ ] Get the data out of the  DataSource  models that we're using 
 [ ] Train and Whetlab a net on MNIST (to get the whole workflow going) 
 [ ] Train and Whetlab a net on CIFAR10 
 [ ] Train and Whetlab a net on STL10 
 [ ] Build dumb ensemble on CIFAR10 
 [ ] Build dumb ensemble on STL10 
 [ ] Grok boosting criterion 
 [ ] Whetlab a net with progressive ensembling on CIFAR10 
 [ ] Whetlab a net with progressive ensembling on STL10 
 [ ] Whetlab a net with progressive ensembling on the last-layer features of ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on CIFAR10 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on STL10 
 [ ] Extract last-layer ImageNet features 
 [ ] Host last-layer ImageNet features 
 [ ] Build download script for last-layer ImageNet features 
 [ ] Train and Whetlab a net on last-layer features on ImageNet 
 [ ] Build a dumb ensemble on ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on the last-layer features of ImageNet 
 
 Collecting some resources 
 AlexNet:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/alexnet.lua 
 I think this is NiN:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/googlenet.lua 
 OverFeat:
https://github.com/facebook/fbcunn/blob/master/examples/imagenet/models/overfeat_cunn.lua 
 Multiclass criterion:
https://github.com/torch/nn/blob/master/doc/criterion.md#classnllcriterion 
 Some other interesting nets:
https://github.com/culurciello/profiling 
 Bunch of demos, not all nets:
https://github.com/torch/demos 
 Overfeat features:
http://cilvr.nyu.edu/doku.php?id=software:overfeat:start 
 Decaf ImageNet submission:
https://github.com/UCB-ICSI-Vision-Group/decaf-release/wiki/imagenet 
 Some other net implementations:
https://github.com/eladhoffer/ImageNet-TrainingConda recipes for installing packages from the Torch ecosystem. 
 NOTE: No longer maintained. 
 To install packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 conda install lua=5.2 lua-science -c alexbw 
 Available versions of Lua: 2.0, 5.1, 5.2, 5.3 
 2.0 is LuaJIT 
 ``` 
 To build packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Get the newest version of conda, as well as some conda build tools 
 conda update conda -y
conda install conda-build anaconda-client -y 
 Build all packages 
 sh build_all.sh 
 Ideally, all you have to do to install everything is this 
 conda install lua=5.2 lua-science
``` 
 TODO:
 - https://github.com/AlexMili/torch-dataframe
 - https://github.com/twitter/torch-ipc
 - https://github.com/twitter/torch-distlearn
 - https://github.com/twitter/torch-dataset 
 Resources: 
 
 
 Making packages relocatable (LuaJIT hard-codes path) 
 
 
 Build instructions for luarocks 
 
 
 Build instructions for Lua 
 
 
 Patching files with git diffs is finicky 
 
 
 Linking against readline  (need a few extra flags, and link against -lncursesw, not -lncurses) 
 
 
 Upgrading old Debian .  Also this . 
 
 
 Misc notes:
 metadata:ns_cfg() â€” defines for YAML directives
main_build: â€”Â defines version numbers 
environ:get_lua_include_dir() â€”Â uses version numbers to locate the include directory
config:Config._get_lua â€”Â uses version numbers to locate the binary
This is where the linked package name is converted into what is usedvalidata 
 Continuous integration for your data 
 We do continuous integration on code. Why not data?
Validata is a small package to run basic sanity checks on your data.
I haven't found anything that aggregates all of these checks and tricks in one place. 
 There is only one method which is exposed,  check(data,labels)  (optionally taking data or labels).
If any data check fails, it throws a well-named error, as well as hints for how you might fix the problem -- data covariance matrix ill-conditioned? Try whitening. 
 Initially, this will be a Python/NumPy only package running basic checks, but hopefully it becomes a resource of data sanity and sanitation checks.
Still very much a work in progress. 
 Examples (some implemented, some not) include: 
 
 If your labels are one-hot, are you using all slots? 
 Is the covariance matrix of your data ill-conditioned? 
 Do you have any constant variables? 
 Can you train a classifier to distinguish train and test data, using whether they are in train or test as a label? Indicates different data distributions. 
 If you're using integer labels, are the unique labels contiguous? 
 Do you have just one unique label? 
 Is the data under different labels statistically separable? 
 If you have an old dataset and a new dataset (or two halves of the same dataset), is the distribution of each dimension stationary? Check for divergence with a KS test. 
 What else? I end up applying these tricks in a very ad hoc fashion, whenever a subtle bug pops up, and not rigorously before each project I tackle. I'd like to stuff all these tricks in one place, and run them like a unit test, or a continuous integration test, on data that I start working with. 
 
 Should probably also think about engardebayarea-dl-summerschool 
 Torch notebooks and slides for the Bay Area Deep Learning Summer School 
 Installation Instructions 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 ```
conda install lua=5.2 lua-science -c alexbw 
 Although, you could install other Lua versions like 2.0 (LuaJIT), 5.1, 5.2 and 5.3 
 ``` 
 Clone this repository and start the notebook server 
 ```
git clone https://github.com/alexbw/bayarea-dl-summerschool.git
cd bayarea-dl-summerschool
itorch notebook 
 Will open a browser tab, then you can navigate to the notebooks 
 ```","Boston, MA",False,Google,7,DevOps,95,0.31,0.38,0.29,0,False,https://avatars.githubusercontent.com/u/161935?u=f722a589176ab3dce6285bcce174117e3c103ec3&v=4,2009-12-04T14:50:40Z,2022-08-23T18:31:52Z,,False,False,False,False,False,True,False,0,396,332,0,47,2016-08-15 18:39:55,5
C#,alexbw,Alex Wiltschko,,alex.bw@gmail.com,"Sampling Inference for Bayesian HSMMs and HMMs 
 This is a Python library for approximate unsupervised sampling inference in
Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov
Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM
and HDP-HSMM, via the weak-limit approximation. 
 There are also some plugins to extend the functionality: 
 
 factorial models 
 autoregressive models 
 collapsed HDP sampling inference . 
 
 The inference can be run in parallel over multiple cores and/or multiple
machines (even on EC2!) using  ipython 's
excellent  ipython.parallel  module. Someday I might even document how to do
it! 
 Installing 
 You can clone this library and its dependencies with 
 git clone --recursive git://github.com/mattjj/pyhsmm.git 
 The library depends on  numpy ,  scipy , and, for visualization,  matplotlib . 
 Disabling assertions may speed things up; to disable assertions, run your
CPython interpreter with the  -O  flag. 
 A Simple Demonstration 
 Here's how to draw from the HDP-HSMM posterior over HSMMs given a sequence of
observations. (The same example, along with the code to generate the synthetic
data loaded in this example, can be found in  examples/basic.py .) 
 Let's say we have some 2D data in a data.txt file: 
 bash
 head -5 data.txt
-3.711962552600095444e-02 1.456401745267922598e-01
7.553818775915704942e-02 2.457422192223903679e-01
-2.465977987699214502e+00 5.537627981813508793e-01
-7.031638516485749779e-01 1.536468304146855757e-01
-9.224669847039665971e-01 3.680035337673161489e-01 
 In Python, we can plot the data in a 2D plot, collapsing out the time dimension: 
 ```python
import numpy as np
from matplotlib import pyplot as plt 
 data = np.loadtxt('data.txt')
plt.plot(data[:,0],data[:,1],'kx')
``` 
 
 We can also make a plot of time versus the first principal component: 
 python
from pyhsmm.util.plot import pca_project_data
plt.plot(pca_project_data(data,1)) 
 
 To learn an HSMM, we'll use  pyhsmm  to create an  HSMM  instance using some
reasonable hyperparameters. We'll ask this model to infer the number of states
as well (since an HDP-HSMM is instantiated by default), so we'll give it an
 Nmax  parameter: 
 ```python
import pyhsmm
import pyhsmm.basic.distributions as distributions 
 obs_dim = 2
Nmax = 25 
 obs_hypparams = {'mu_0':np.zeros(obs_dim),
                'sigma_0':np.eye(obs_dim),
                'kappa_0':0.3,
                'nu_0':obs_dim+5}
dur_hypparams = {'alpha_0':2*30,
                 'beta_0':2} 
 obs_distns = [distributions.Gaussian( obs_hypparams) for state in range(Nmax)]
dur_distns = [distributions.PoissonDuration( dur_hypparams) for state in range(Nmax)] 
 posteriormodel = pyhsmm.models.HSMM(
        alpha=6.,gamma=6., # better to sample over these; see concentration-resampling.py
        init_state_concentration=6., # pretty inconsequential
        obs_distns=obs_distns,
        dur_distns=dur_distns,
        trunc=60) # duration truncation speeds things up when it's possible
``` 
 (The first two arguments set the ""new-table"" proportionality constant for the
meta-Chinese Restaurant Process and the other CRPs, respectively, in the HDP
prior on transition matrices. For this example, they really don't matter at
all, but on real data it's much better to infer these parameters, as in
 examples/concentration_resampling.py .) 
 The  trunc  parameter is an optional argument that can speed up inference: it
sets a truncation limit on the maximum duration for any state. If you don't
pass in the  trunc  argument, no truncation is used and all possible state
duration lengths are considered. 
 Then, we add the data we want to condition on: 
 python
posteriormodel.add_data(data) 
 (If we had multiple observation sequences to learn from, we could add them to the
model just by calling  add_data()  for each observation sequence.) 
 Now we run a resampling loop. For each iteration of the loop, all the latent
variables of the model will be resampled by Gibbs sampling steps, including the
transition matrix, the observation means and covariances, the duration
parameters, and the hidden state sequence. We'll also copy some samples so that
we can plot them. 
 python
models = []
for idx in progprint_xrange(150):
    posteriormodel.resample_model()
    if (idx+1) % 10 == 0:
        models.append(copy.deepcopy(posteriormodel)) 
 Now we can plot our saved samples: 
 python
fig = plt.figure()
for idx, model in enumerate(models):
    plt.clf()
    model.plot()
    plt.gcf().suptitle('HDP-HSMM sampled after %d iterations' % (10*(idx+1)))
    plt.savefig('iter_%.3d.png' % (10*(idx+1))) 
 
 I generated these data from an HSMM that looked like this: 
 
 So the posterior samples look pretty good! 
 Speed 
 HSMMs constitute a much more powerful model class than plain-old HMMs, and that
enhanced power comes with a computational price: each sampling iteration for an
HSMM is much slower than that of an HMM. But that price is often worthwhile if
you want to place priors on state durations or have the model learn duration
structure present in the data. (In the example, strong duration structure is
what made the inference algorithm latch onto the correct explanation so
easily.) In addition, the increased cost of each iteration often pays for
itself, since HSMM samplers empirically seem to take fewer iterations to
converge than comparable HMM samplers. 
 Using my nothing-special i7-920 desktop machine and a NumPy/SciPy built against
Intel's MKL BLAS (which generally outperforms ATLAS for vectorized operations)
along with the Eigen-backed classes, here's how long the demo iterations took: 
 $ python examples/hsmm.py
.........................  [  25/100,    0.05sec avg,    3.95sec ETA ]
.........................  [  50/100,    0.05sec avg,    2.64sec ETA ]
.........................  [  75/100,    0.05sec avg,    1.34sec ETA ]
.........................  [ 100/100,    0.05sec avg,    0.05sec ETA ]
   0.05sec avg,    5.21sec total 
 Extending the Code 
 To add your own observation or duration distributions, implement the interfaces
defined in  basic/abstractions.py . Also see the plugins. To get a flavor of
the style, see  pybasicbayes . 
 Contributors 
 Contributions by Chia-ying Lee. 
 References 
 
 
 Matthew J. Johnson and Alan S. Willsky.  Bayesian Nonparametric Hidden
  Semi-Markov Models .
  Journal of Machine Learning Research (JMLR), 14:673â€“701, February 2013. 
 
 
 Matthew J. Johnson and Alan S. Willsky,  The Hierarchical Dirichlet Process
  Hidden Semi-Markov Model . 26th
  Conference on Uncertainty in Artificial Intelligence (UAI 2010), Avalon,
  California, July 2010. 
 
 
 bibtex
@article{johnson2013hdphsmm,
    title={Bayesian Nonparametric Hidden Semi-Markov Models},
    author={Johnson, Matthew J. and Willsky, Alan S.},
    journal={Journal of Machine Learning Research},
    pages={673--701},
    volume={14},
    month={February},
    year={2013},
}An analgesic for high-performance audio on iOS and OSX. 
 Really fast audio in iOS and Mac OS X using Audio Units is hard, and will leave you scarred and bloody. What used to take days can now be done with just a few lines of code. 
 Getting Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setInputBlock:^(float *newAudio, UInt32 numSamples, UInt32 numChannels) {
    // Now you're getting audio from the microphone every 20 milliseconds or so. How's that for easy?
    // Audio comes in interleaved, so,
    // if numChannels = 2, newAudio[0] is channel 1, newAudio[1] is channel 2, newAudio[2] is channel 1, etc.
}];
[audioManager play]; 
 Playing Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setOutputBlock:^(float *audioToPlay, UInt32 numSamples, UInt32 numChannels) {
    // All you have to do is put your audio into ""audioToPlay"".
}];
[audioManager play]; 
 Does anybody actually use it? 
 Yep. Novocaine is result of three years of work on the audio engine of  Octave ,  Fourier  and  oScope , a powerful suite of audio analysis apps. Please do check them out! 
 A thing to note: 
 The RingBuffer class is written in C++ to make things extra zippy, so the classes that use it will have to be Objective-C++. Change all the files that use RingBuffer from MyClass.m to MyClass.mm. 
 Want some examples? 
 Inside of ViewController.mm are a bunch of tiny little examples I wrote. Uncomment one and see how it sounds. 
Do note, however, for examples involving play-through, that you should be using headphones. Having the 
mic and speaker close to each other will produce some gnarly feedback.   
 Want to learn the nitty-gritty of Core Audio? 
 If you want to get down and dirty, if you want to get brave and get close to the hardware, I can only point you to the places where I learned how to do this stuff. Chris Adamson and Michael Tyson are two giants in the field of iOS audio, and they each wrote indispensable blog posts ( this is Chris's ,  this is Michael's ). Also, Chris Adamson now has a  whole gosh-darned BOOK on Core Audio . I would have done unspeakable things to get my hands on this when I was first starting. 
My Code for the Netflix Prize 
 I'm not aware of folks having published their code for the Netflix Prize. Here's mine. 
Under the team name ""Hi!"", I competed alone in college. I did it mostly for fun, and to learn modern machine learning techniques. It was an incredibly valuable, but strenuous, time. Well worth it on all fronts, though.  
I peaked out at #45 or so, and then dropped out to work on my senior thesis, and came in #145 or so.   
What I learned in the process was that smarter wasn't always better -- make an algorithm, and then scale it up, and then make a dozen tweaks to it, and then average all of the results together. That's how you climbed the leaderboard.    
 Anyhoo, I haven't touched this code in awhile, but perhaps it'll be useful to folks interested in competitive data mining. 
Specifically, the lessons I learned: 
 
 Get the raw data into a saved and manageable format  fast . The easier it is to load your data in and start mutating it, the better. 
 If doing simple pivots on your data is hard, and slows you down from visualizing whats in your data, spend time making data structures which make that easy.   
 Generalize. Iterate. If you have a method you think will work, but it has a lot of knobs, and you don't know the best way to set those knobs, make it easy for you to try  every possible iteration . There is often not a good way to figure out what the  best  approach is. You will have to try many of them in order to build up an intuition. Specifically, that means (for me) a pluggable architecture. If there's ten ways to try a particular step, make sure you write your overarching algorithm so that it takes a function that you can pass to it, as opposed to having a method hardwired in the code. That way, you can hotswap all your ideas.   
 Speed is a feature. Of course you make sure it works first. But your goal is to see if something works. If an algorithm takes a day to run, but you can spend five hours making it run in 1/3 of a day, do it. You'll be running it over and over again, and you'll learn more if you can iterate.  
 
 As for the technical nitty-gritty, everything that's speed sensitive is written in Cython, which was the best balance of speed and convenience in 2009. If I were to do it al again, I would use (Numba)[http://github.com/numba/numba].   
 The original data is gone, I believe, but I might have it stored somewhere. I'll look for that.  NURBS - Non Uniform Rational B-Splines. 
 This python module is a revival and update of Runar Tenfjord's NURBS toolbox, which itself
is a port of Mark Spink's SCILAB/MATLAB tolbox to python with help of numpy. 
 Dependency 
 Python 2.0 or above 
NumPy 
Dislin -> optional but recomended 
PyOpenGL -> optional   
 Installation 
 Just run   python setup.py install   
 License 
 Runar Tenfjord originally relased this package under the GPL Version 2 license,  
so I suppose that means it has to stay that way.    
 Originally by: Runar Tenfjord, runten@netcom.no 
Minor updates to work with NumPy by Alex Wiltschko  cuda-tests 
 Gotta learn some CUDA stuffpypatent 
 Scrape patents from the USPTOairruler 
 A ruler. Made of air. paralleltools 
 A summary of parallelizing moderate amounts of work in Pythonnsgt 
 Non-stationary Gabor transforms (GitHub mirror of http://grrrr.org/research/software/nsgt/)IDA 
 This code accompanies the publication from the Whitesides lab to Lab on a Chip, concerning automated analysis of red blood cell health using affordable field tests. Specifically, this code implements the automated extraction of scanned AMPS tubes from flatbed scanner images, the distillation of those images into 1D data traces, and then the automated identification of the anemic disease state of the blood in those 1D data traces, as well as the prediction of continuously-varying red blood cell (RBC) parameters. 
 Installation 
 This code requires Python, as well as some extra 3rd-party libraries. All routines have only been tested on Mac OS, but should work on Linux. No guarantees for Windows.
1) First, we recommend using the ""Anaconda"" Python distribution, specifically the Python 2.7 version.  Download and install here .
1) With anaconda installed, you will need one extra library, to read TIFF files.
 pip install imageio 
1) You should be able to run the notebooks now. Inside this code repository, start up an IPython notebook:
 jupyter notebook 
1) You should now be able to browser around the ""extraction"" and ""analysis"" folders, which contain the relevant code. 
 Running extraction 
 The first step required will be to prepare the raw data of TIFF file scans of 4x3=12 tubes from a flatbed scanner. We will also have to associate metadata for each patient that the blood in a tube was drawn from.
Our end goal will be a 1D array for each tube, along with the corresponding patient data (anemic state & RBC parameters). 
 The extraction algorithm is explained step-by-step in the notebook  extraction/Explaining the Extraction Algorithm.ipynb .
The implementation we use in the paper (which also fuses patient metadata with AMPS image data) can be found in  extraction/Data Extraction Pipeline.ipynb . Most of the code in this notebook is specific to the particular Excel file format that we used to record patient metadata, and may have to be largely rewritten for reuse. 
 Running analysis 
 There are two sets of analyses done in the paper: classification and regression. 
 Running classification analysis 
 The goal of this analysis is to predict disease state only from the 1D data trace extracted from each AMPS tube. We use logistic regression, a linear classifier, and transform the 1D data representation using PCA to remove redundancy and constrain the input dimensionality of the problem. We also used Bayesian Optimization (bayesopt) to tune the hyperparameters of the problem, including the specific output dimension of PCA, the regularization parameter of logistic regression, and some image preprocessing parameters. Unfortunately, the service we used for bayesopt is no longer available. If you would like to automatically tune these parameters, we recommend either using random search (a surprisingly effective hueristic), or the open source library ""Spearmint"", upon which the now-defunct service we used was based, or products from the company SigOpt, which also implements bayesopt. The file we used to automatically tune these hypers is  classify.py .
The best set of hyperparameters is stored in the notebook  Analyzing best classification.ipynb .
This notebook examines ROC performance of the classifier for discriminating different anemia types, as well as the effect of centrifugation time of the tube on IDA classification AUC performance. 
 Running regression analysis. 
 Similar to above, we used a defunct bayesopt service to automatically tune some parameters of this algorithm. The original file is in  regress.py . The original methodology will work well, even without automated tuning.
The best set of hyperparameters is stored in the notebook  Analyzing best regression.ipynb . 
 License 
 See the LICENSE file. It is under a GPL license, and this code may only be used for academic purposes.adabayes 
 To do: 
 
 [x] Find candidate last layer features (DeCAF, Overfeat) 
 [x] Find AlexNet code (5 convolutional layers with max-pooling, then three fully connected layers) 
 [X]  Find download script for MNIST dataset 
 [X]  Find download script for CIFAR10 dataset 
 [x] Fork torch-dist repo 
 [x] Update torch-dist repo for OS X 10.10 install 
 [x] Add new required submodules to distro (nnx, iTorch, ccn2, cunnx, cudnn, sdl2, cutorch) 
 [x] Figure out model serialization and loading 
 Built-in model serialization.  Loading  and  saving . 
 There is also facebook's  Thrift library , which I haven't seen many examples for. 
 
 
 [ ] Get the data out of the  DataSource  models that we're using 
 [ ] Train and Whetlab a net on MNIST (to get the whole workflow going) 
 [ ] Train and Whetlab a net on CIFAR10 
 [ ] Train and Whetlab a net on STL10 
 [ ] Build dumb ensemble on CIFAR10 
 [ ] Build dumb ensemble on STL10 
 [ ] Grok boosting criterion 
 [ ] Whetlab a net with progressive ensembling on CIFAR10 
 [ ] Whetlab a net with progressive ensembling on STL10 
 [ ] Whetlab a net with progressive ensembling on the last-layer features of ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on CIFAR10 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on STL10 
 [ ] Extract last-layer ImageNet features 
 [ ] Host last-layer ImageNet features 
 [ ] Build download script for last-layer ImageNet features 
 [ ] Train and Whetlab a net on last-layer features on ImageNet 
 [ ] Build a dumb ensemble on ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on the last-layer features of ImageNet 
 
 Collecting some resources 
 AlexNet:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/alexnet.lua 
 I think this is NiN:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/googlenet.lua 
 OverFeat:
https://github.com/facebook/fbcunn/blob/master/examples/imagenet/models/overfeat_cunn.lua 
 Multiclass criterion:
https://github.com/torch/nn/blob/master/doc/criterion.md#classnllcriterion 
 Some other interesting nets:
https://github.com/culurciello/profiling 
 Bunch of demos, not all nets:
https://github.com/torch/demos 
 Overfeat features:
http://cilvr.nyu.edu/doku.php?id=software:overfeat:start 
 Decaf ImageNet submission:
https://github.com/UCB-ICSI-Vision-Group/decaf-release/wiki/imagenet 
 Some other net implementations:
https://github.com/eladhoffer/ImageNet-TrainingConda recipes for installing packages from the Torch ecosystem. 
 NOTE: No longer maintained. 
 To install packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 conda install lua=5.2 lua-science -c alexbw 
 Available versions of Lua: 2.0, 5.1, 5.2, 5.3 
 2.0 is LuaJIT 
 ``` 
 To build packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Get the newest version of conda, as well as some conda build tools 
 conda update conda -y
conda install conda-build anaconda-client -y 
 Build all packages 
 sh build_all.sh 
 Ideally, all you have to do to install everything is this 
 conda install lua=5.2 lua-science
``` 
 TODO:
 - https://github.com/AlexMili/torch-dataframe
 - https://github.com/twitter/torch-ipc
 - https://github.com/twitter/torch-distlearn
 - https://github.com/twitter/torch-dataset 
 Resources: 
 
 
 Making packages relocatable (LuaJIT hard-codes path) 
 
 
 Build instructions for luarocks 
 
 
 Build instructions for Lua 
 
 
 Patching files with git diffs is finicky 
 
 
 Linking against readline  (need a few extra flags, and link against -lncursesw, not -lncurses) 
 
 
 Upgrading old Debian .  Also this . 
 
 
 Misc notes:
 metadata:ns_cfg() â€” defines for YAML directives
main_build: â€”Â defines version numbers 
environ:get_lua_include_dir() â€”Â uses version numbers to locate the include directory
config:Config._get_lua â€”Â uses version numbers to locate the binary
This is where the linked package name is converted into what is usedvalidata 
 Continuous integration for your data 
 We do continuous integration on code. Why not data?
Validata is a small package to run basic sanity checks on your data.
I haven't found anything that aggregates all of these checks and tricks in one place. 
 There is only one method which is exposed,  check(data,labels)  (optionally taking data or labels).
If any data check fails, it throws a well-named error, as well as hints for how you might fix the problem -- data covariance matrix ill-conditioned? Try whitening. 
 Initially, this will be a Python/NumPy only package running basic checks, but hopefully it becomes a resource of data sanity and sanitation checks.
Still very much a work in progress. 
 Examples (some implemented, some not) include: 
 
 If your labels are one-hot, are you using all slots? 
 Is the covariance matrix of your data ill-conditioned? 
 Do you have any constant variables? 
 Can you train a classifier to distinguish train and test data, using whether they are in train or test as a label? Indicates different data distributions. 
 If you're using integer labels, are the unique labels contiguous? 
 Do you have just one unique label? 
 Is the data under different labels statistically separable? 
 If you have an old dataset and a new dataset (or two halves of the same dataset), is the distribution of each dimension stationary? Check for divergence with a KS test. 
 What else? I end up applying these tricks in a very ad hoc fashion, whenever a subtle bug pops up, and not rigorously before each project I tackle. I'd like to stuff all these tricks in one place, and run them like a unit test, or a continuous integration test, on data that I start working with. 
 
 Should probably also think about engardebayarea-dl-summerschool 
 Torch notebooks and slides for the Bay Area Deep Learning Summer School 
 Installation Instructions 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 ```
conda install lua=5.2 lua-science -c alexbw 
 Although, you could install other Lua versions like 2.0 (LuaJIT), 5.1, 5.2 and 5.3 
 ``` 
 Clone this repository and start the notebook server 
 ```
git clone https://github.com/alexbw/bayarea-dl-summerschool.git
cd bayarea-dl-summerschool
itorch notebook 
 Will open a browser tab, then you can navigate to the notebooks 
 ```","Boston, MA",False,Google,7,DevOps,95,0.31,0.38,0.29,0,False,https://avatars.githubusercontent.com/u/161935?u=f722a589176ab3dce6285bcce174117e3c103ec3&v=4,2009-12-04T14:50:40Z,2022-08-23T18:31:52Z,,False,False,False,False,False,True,False,0,396,332,0,47,2016-08-15 18:39:55,1
C++,alexbw,Alex Wiltschko,,alex.bw@gmail.com,"Sampling Inference for Bayesian HSMMs and HMMs 
 This is a Python library for approximate unsupervised sampling inference in
Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov
Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM
and HDP-HSMM, via the weak-limit approximation. 
 There are also some plugins to extend the functionality: 
 
 factorial models 
 autoregressive models 
 collapsed HDP sampling inference . 
 
 The inference can be run in parallel over multiple cores and/or multiple
machines (even on EC2!) using  ipython 's
excellent  ipython.parallel  module. Someday I might even document how to do
it! 
 Installing 
 You can clone this library and its dependencies with 
 git clone --recursive git://github.com/mattjj/pyhsmm.git 
 The library depends on  numpy ,  scipy , and, for visualization,  matplotlib . 
 Disabling assertions may speed things up; to disable assertions, run your
CPython interpreter with the  -O  flag. 
 A Simple Demonstration 
 Here's how to draw from the HDP-HSMM posterior over HSMMs given a sequence of
observations. (The same example, along with the code to generate the synthetic
data loaded in this example, can be found in  examples/basic.py .) 
 Let's say we have some 2D data in a data.txt file: 
 bash
 head -5 data.txt
-3.711962552600095444e-02 1.456401745267922598e-01
7.553818775915704942e-02 2.457422192223903679e-01
-2.465977987699214502e+00 5.537627981813508793e-01
-7.031638516485749779e-01 1.536468304146855757e-01
-9.224669847039665971e-01 3.680035337673161489e-01 
 In Python, we can plot the data in a 2D plot, collapsing out the time dimension: 
 ```python
import numpy as np
from matplotlib import pyplot as plt 
 data = np.loadtxt('data.txt')
plt.plot(data[:,0],data[:,1],'kx')
``` 
 
 We can also make a plot of time versus the first principal component: 
 python
from pyhsmm.util.plot import pca_project_data
plt.plot(pca_project_data(data,1)) 
 
 To learn an HSMM, we'll use  pyhsmm  to create an  HSMM  instance using some
reasonable hyperparameters. We'll ask this model to infer the number of states
as well (since an HDP-HSMM is instantiated by default), so we'll give it an
 Nmax  parameter: 
 ```python
import pyhsmm
import pyhsmm.basic.distributions as distributions 
 obs_dim = 2
Nmax = 25 
 obs_hypparams = {'mu_0':np.zeros(obs_dim),
                'sigma_0':np.eye(obs_dim),
                'kappa_0':0.3,
                'nu_0':obs_dim+5}
dur_hypparams = {'alpha_0':2*30,
                 'beta_0':2} 
 obs_distns = [distributions.Gaussian( obs_hypparams) for state in range(Nmax)]
dur_distns = [distributions.PoissonDuration( dur_hypparams) for state in range(Nmax)] 
 posteriormodel = pyhsmm.models.HSMM(
        alpha=6.,gamma=6., # better to sample over these; see concentration-resampling.py
        init_state_concentration=6., # pretty inconsequential
        obs_distns=obs_distns,
        dur_distns=dur_distns,
        trunc=60) # duration truncation speeds things up when it's possible
``` 
 (The first two arguments set the ""new-table"" proportionality constant for the
meta-Chinese Restaurant Process and the other CRPs, respectively, in the HDP
prior on transition matrices. For this example, they really don't matter at
all, but on real data it's much better to infer these parameters, as in
 examples/concentration_resampling.py .) 
 The  trunc  parameter is an optional argument that can speed up inference: it
sets a truncation limit on the maximum duration for any state. If you don't
pass in the  trunc  argument, no truncation is used and all possible state
duration lengths are considered. 
 Then, we add the data we want to condition on: 
 python
posteriormodel.add_data(data) 
 (If we had multiple observation sequences to learn from, we could add them to the
model just by calling  add_data()  for each observation sequence.) 
 Now we run a resampling loop. For each iteration of the loop, all the latent
variables of the model will be resampled by Gibbs sampling steps, including the
transition matrix, the observation means and covariances, the duration
parameters, and the hidden state sequence. We'll also copy some samples so that
we can plot them. 
 python
models = []
for idx in progprint_xrange(150):
    posteriormodel.resample_model()
    if (idx+1) % 10 == 0:
        models.append(copy.deepcopy(posteriormodel)) 
 Now we can plot our saved samples: 
 python
fig = plt.figure()
for idx, model in enumerate(models):
    plt.clf()
    model.plot()
    plt.gcf().suptitle('HDP-HSMM sampled after %d iterations' % (10*(idx+1)))
    plt.savefig('iter_%.3d.png' % (10*(idx+1))) 
 
 I generated these data from an HSMM that looked like this: 
 
 So the posterior samples look pretty good! 
 Speed 
 HSMMs constitute a much more powerful model class than plain-old HMMs, and that
enhanced power comes with a computational price: each sampling iteration for an
HSMM is much slower than that of an HMM. But that price is often worthwhile if
you want to place priors on state durations or have the model learn duration
structure present in the data. (In the example, strong duration structure is
what made the inference algorithm latch onto the correct explanation so
easily.) In addition, the increased cost of each iteration often pays for
itself, since HSMM samplers empirically seem to take fewer iterations to
converge than comparable HMM samplers. 
 Using my nothing-special i7-920 desktop machine and a NumPy/SciPy built against
Intel's MKL BLAS (which generally outperforms ATLAS for vectorized operations)
along with the Eigen-backed classes, here's how long the demo iterations took: 
 $ python examples/hsmm.py
.........................  [  25/100,    0.05sec avg,    3.95sec ETA ]
.........................  [  50/100,    0.05sec avg,    2.64sec ETA ]
.........................  [  75/100,    0.05sec avg,    1.34sec ETA ]
.........................  [ 100/100,    0.05sec avg,    0.05sec ETA ]
   0.05sec avg,    5.21sec total 
 Extending the Code 
 To add your own observation or duration distributions, implement the interfaces
defined in  basic/abstractions.py . Also see the plugins. To get a flavor of
the style, see  pybasicbayes . 
 Contributors 
 Contributions by Chia-ying Lee. 
 References 
 
 
 Matthew J. Johnson and Alan S. Willsky.  Bayesian Nonparametric Hidden
  Semi-Markov Models .
  Journal of Machine Learning Research (JMLR), 14:673â€“701, February 2013. 
 
 
 Matthew J. Johnson and Alan S. Willsky,  The Hierarchical Dirichlet Process
  Hidden Semi-Markov Model . 26th
  Conference on Uncertainty in Artificial Intelligence (UAI 2010), Avalon,
  California, July 2010. 
 
 
 bibtex
@article{johnson2013hdphsmm,
    title={Bayesian Nonparametric Hidden Semi-Markov Models},
    author={Johnson, Matthew J. and Willsky, Alan S.},
    journal={Journal of Machine Learning Research},
    pages={673--701},
    volume={14},
    month={February},
    year={2013},
}An analgesic for high-performance audio on iOS and OSX. 
 Really fast audio in iOS and Mac OS X using Audio Units is hard, and will leave you scarred and bloody. What used to take days can now be done with just a few lines of code. 
 Getting Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setInputBlock:^(float *newAudio, UInt32 numSamples, UInt32 numChannels) {
    // Now you're getting audio from the microphone every 20 milliseconds or so. How's that for easy?
    // Audio comes in interleaved, so,
    // if numChannels = 2, newAudio[0] is channel 1, newAudio[1] is channel 2, newAudio[2] is channel 1, etc.
}];
[audioManager play]; 
 Playing Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setOutputBlock:^(float *audioToPlay, UInt32 numSamples, UInt32 numChannels) {
    // All you have to do is put your audio into ""audioToPlay"".
}];
[audioManager play]; 
 Does anybody actually use it? 
 Yep. Novocaine is result of three years of work on the audio engine of  Octave ,  Fourier  and  oScope , a powerful suite of audio analysis apps. Please do check them out! 
 A thing to note: 
 The RingBuffer class is written in C++ to make things extra zippy, so the classes that use it will have to be Objective-C++. Change all the files that use RingBuffer from MyClass.m to MyClass.mm. 
 Want some examples? 
 Inside of ViewController.mm are a bunch of tiny little examples I wrote. Uncomment one and see how it sounds. 
Do note, however, for examples involving play-through, that you should be using headphones. Having the 
mic and speaker close to each other will produce some gnarly feedback.   
 Want to learn the nitty-gritty of Core Audio? 
 If you want to get down and dirty, if you want to get brave and get close to the hardware, I can only point you to the places where I learned how to do this stuff. Chris Adamson and Michael Tyson are two giants in the field of iOS audio, and they each wrote indispensable blog posts ( this is Chris's ,  this is Michael's ). Also, Chris Adamson now has a  whole gosh-darned BOOK on Core Audio . I would have done unspeakable things to get my hands on this when I was first starting. 
My Code for the Netflix Prize 
 I'm not aware of folks having published their code for the Netflix Prize. Here's mine. 
Under the team name ""Hi!"", I competed alone in college. I did it mostly for fun, and to learn modern machine learning techniques. It was an incredibly valuable, but strenuous, time. Well worth it on all fronts, though.  
I peaked out at #45 or so, and then dropped out to work on my senior thesis, and came in #145 or so.   
What I learned in the process was that smarter wasn't always better -- make an algorithm, and then scale it up, and then make a dozen tweaks to it, and then average all of the results together. That's how you climbed the leaderboard.    
 Anyhoo, I haven't touched this code in awhile, but perhaps it'll be useful to folks interested in competitive data mining. 
Specifically, the lessons I learned: 
 
 Get the raw data into a saved and manageable format  fast . The easier it is to load your data in and start mutating it, the better. 
 If doing simple pivots on your data is hard, and slows you down from visualizing whats in your data, spend time making data structures which make that easy.   
 Generalize. Iterate. If you have a method you think will work, but it has a lot of knobs, and you don't know the best way to set those knobs, make it easy for you to try  every possible iteration . There is often not a good way to figure out what the  best  approach is. You will have to try many of them in order to build up an intuition. Specifically, that means (for me) a pluggable architecture. If there's ten ways to try a particular step, make sure you write your overarching algorithm so that it takes a function that you can pass to it, as opposed to having a method hardwired in the code. That way, you can hotswap all your ideas.   
 Speed is a feature. Of course you make sure it works first. But your goal is to see if something works. If an algorithm takes a day to run, but you can spend five hours making it run in 1/3 of a day, do it. You'll be running it over and over again, and you'll learn more if you can iterate.  
 
 As for the technical nitty-gritty, everything that's speed sensitive is written in Cython, which was the best balance of speed and convenience in 2009. If I were to do it al again, I would use (Numba)[http://github.com/numba/numba].   
 The original data is gone, I believe, but I might have it stored somewhere. I'll look for that.  NURBS - Non Uniform Rational B-Splines. 
 This python module is a revival and update of Runar Tenfjord's NURBS toolbox, which itself
is a port of Mark Spink's SCILAB/MATLAB tolbox to python with help of numpy. 
 Dependency 
 Python 2.0 or above 
NumPy 
Dislin -> optional but recomended 
PyOpenGL -> optional   
 Installation 
 Just run   python setup.py install   
 License 
 Runar Tenfjord originally relased this package under the GPL Version 2 license,  
so I suppose that means it has to stay that way.    
 Originally by: Runar Tenfjord, runten@netcom.no 
Minor updates to work with NumPy by Alex Wiltschko  cuda-tests 
 Gotta learn some CUDA stuffpypatent 
 Scrape patents from the USPTOairruler 
 A ruler. Made of air. paralleltools 
 A summary of parallelizing moderate amounts of work in Pythonnsgt 
 Non-stationary Gabor transforms (GitHub mirror of http://grrrr.org/research/software/nsgt/)IDA 
 This code accompanies the publication from the Whitesides lab to Lab on a Chip, concerning automated analysis of red blood cell health using affordable field tests. Specifically, this code implements the automated extraction of scanned AMPS tubes from flatbed scanner images, the distillation of those images into 1D data traces, and then the automated identification of the anemic disease state of the blood in those 1D data traces, as well as the prediction of continuously-varying red blood cell (RBC) parameters. 
 Installation 
 This code requires Python, as well as some extra 3rd-party libraries. All routines have only been tested on Mac OS, but should work on Linux. No guarantees for Windows.
1) First, we recommend using the ""Anaconda"" Python distribution, specifically the Python 2.7 version.  Download and install here .
1) With anaconda installed, you will need one extra library, to read TIFF files.
 pip install imageio 
1) You should be able to run the notebooks now. Inside this code repository, start up an IPython notebook:
 jupyter notebook 
1) You should now be able to browser around the ""extraction"" and ""analysis"" folders, which contain the relevant code. 
 Running extraction 
 The first step required will be to prepare the raw data of TIFF file scans of 4x3=12 tubes from a flatbed scanner. We will also have to associate metadata for each patient that the blood in a tube was drawn from.
Our end goal will be a 1D array for each tube, along with the corresponding patient data (anemic state & RBC parameters). 
 The extraction algorithm is explained step-by-step in the notebook  extraction/Explaining the Extraction Algorithm.ipynb .
The implementation we use in the paper (which also fuses patient metadata with AMPS image data) can be found in  extraction/Data Extraction Pipeline.ipynb . Most of the code in this notebook is specific to the particular Excel file format that we used to record patient metadata, and may have to be largely rewritten for reuse. 
 Running analysis 
 There are two sets of analyses done in the paper: classification and regression. 
 Running classification analysis 
 The goal of this analysis is to predict disease state only from the 1D data trace extracted from each AMPS tube. We use logistic regression, a linear classifier, and transform the 1D data representation using PCA to remove redundancy and constrain the input dimensionality of the problem. We also used Bayesian Optimization (bayesopt) to tune the hyperparameters of the problem, including the specific output dimension of PCA, the regularization parameter of logistic regression, and some image preprocessing parameters. Unfortunately, the service we used for bayesopt is no longer available. If you would like to automatically tune these parameters, we recommend either using random search (a surprisingly effective hueristic), or the open source library ""Spearmint"", upon which the now-defunct service we used was based, or products from the company SigOpt, which also implements bayesopt. The file we used to automatically tune these hypers is  classify.py .
The best set of hyperparameters is stored in the notebook  Analyzing best classification.ipynb .
This notebook examines ROC performance of the classifier for discriminating different anemia types, as well as the effect of centrifugation time of the tube on IDA classification AUC performance. 
 Running regression analysis. 
 Similar to above, we used a defunct bayesopt service to automatically tune some parameters of this algorithm. The original file is in  regress.py . The original methodology will work well, even without automated tuning.
The best set of hyperparameters is stored in the notebook  Analyzing best regression.ipynb . 
 License 
 See the LICENSE file. It is under a GPL license, and this code may only be used for academic purposes.adabayes 
 To do: 
 
 [x] Find candidate last layer features (DeCAF, Overfeat) 
 [x] Find AlexNet code (5 convolutional layers with max-pooling, then three fully connected layers) 
 [X]  Find download script for MNIST dataset 
 [X]  Find download script for CIFAR10 dataset 
 [x] Fork torch-dist repo 
 [x] Update torch-dist repo for OS X 10.10 install 
 [x] Add new required submodules to distro (nnx, iTorch, ccn2, cunnx, cudnn, sdl2, cutorch) 
 [x] Figure out model serialization and loading 
 Built-in model serialization.  Loading  and  saving . 
 There is also facebook's  Thrift library , which I haven't seen many examples for. 
 
 
 [ ] Get the data out of the  DataSource  models that we're using 
 [ ] Train and Whetlab a net on MNIST (to get the whole workflow going) 
 [ ] Train and Whetlab a net on CIFAR10 
 [ ] Train and Whetlab a net on STL10 
 [ ] Build dumb ensemble on CIFAR10 
 [ ] Build dumb ensemble on STL10 
 [ ] Grok boosting criterion 
 [ ] Whetlab a net with progressive ensembling on CIFAR10 
 [ ] Whetlab a net with progressive ensembling on STL10 
 [ ] Whetlab a net with progressive ensembling on the last-layer features of ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on CIFAR10 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on STL10 
 [ ] Extract last-layer ImageNet features 
 [ ] Host last-layer ImageNet features 
 [ ] Build download script for last-layer ImageNet features 
 [ ] Train and Whetlab a net on last-layer features on ImageNet 
 [ ] Build a dumb ensemble on ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on the last-layer features of ImageNet 
 
 Collecting some resources 
 AlexNet:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/alexnet.lua 
 I think this is NiN:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/googlenet.lua 
 OverFeat:
https://github.com/facebook/fbcunn/blob/master/examples/imagenet/models/overfeat_cunn.lua 
 Multiclass criterion:
https://github.com/torch/nn/blob/master/doc/criterion.md#classnllcriterion 
 Some other interesting nets:
https://github.com/culurciello/profiling 
 Bunch of demos, not all nets:
https://github.com/torch/demos 
 Overfeat features:
http://cilvr.nyu.edu/doku.php?id=software:overfeat:start 
 Decaf ImageNet submission:
https://github.com/UCB-ICSI-Vision-Group/decaf-release/wiki/imagenet 
 Some other net implementations:
https://github.com/eladhoffer/ImageNet-TrainingConda recipes for installing packages from the Torch ecosystem. 
 NOTE: No longer maintained. 
 To install packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 conda install lua=5.2 lua-science -c alexbw 
 Available versions of Lua: 2.0, 5.1, 5.2, 5.3 
 2.0 is LuaJIT 
 ``` 
 To build packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Get the newest version of conda, as well as some conda build tools 
 conda update conda -y
conda install conda-build anaconda-client -y 
 Build all packages 
 sh build_all.sh 
 Ideally, all you have to do to install everything is this 
 conda install lua=5.2 lua-science
``` 
 TODO:
 - https://github.com/AlexMili/torch-dataframe
 - https://github.com/twitter/torch-ipc
 - https://github.com/twitter/torch-distlearn
 - https://github.com/twitter/torch-dataset 
 Resources: 
 
 
 Making packages relocatable (LuaJIT hard-codes path) 
 
 
 Build instructions for luarocks 
 
 
 Build instructions for Lua 
 
 
 Patching files with git diffs is finicky 
 
 
 Linking against readline  (need a few extra flags, and link against -lncursesw, not -lncurses) 
 
 
 Upgrading old Debian .  Also this . 
 
 
 Misc notes:
 metadata:ns_cfg() â€” defines for YAML directives
main_build: â€”Â defines version numbers 
environ:get_lua_include_dir() â€”Â uses version numbers to locate the include directory
config:Config._get_lua â€”Â uses version numbers to locate the binary
This is where the linked package name is converted into what is usedvalidata 
 Continuous integration for your data 
 We do continuous integration on code. Why not data?
Validata is a small package to run basic sanity checks on your data.
I haven't found anything that aggregates all of these checks and tricks in one place. 
 There is only one method which is exposed,  check(data,labels)  (optionally taking data or labels).
If any data check fails, it throws a well-named error, as well as hints for how you might fix the problem -- data covariance matrix ill-conditioned? Try whitening. 
 Initially, this will be a Python/NumPy only package running basic checks, but hopefully it becomes a resource of data sanity and sanitation checks.
Still very much a work in progress. 
 Examples (some implemented, some not) include: 
 
 If your labels are one-hot, are you using all slots? 
 Is the covariance matrix of your data ill-conditioned? 
 Do you have any constant variables? 
 Can you train a classifier to distinguish train and test data, using whether they are in train or test as a label? Indicates different data distributions. 
 If you're using integer labels, are the unique labels contiguous? 
 Do you have just one unique label? 
 Is the data under different labels statistically separable? 
 If you have an old dataset and a new dataset (or two halves of the same dataset), is the distribution of each dimension stationary? Check for divergence with a KS test. 
 What else? I end up applying these tricks in a very ad hoc fashion, whenever a subtle bug pops up, and not rigorously before each project I tackle. I'd like to stuff all these tricks in one place, and run them like a unit test, or a continuous integration test, on data that I start working with. 
 
 Should probably also think about engardebayarea-dl-summerschool 
 Torch notebooks and slides for the Bay Area Deep Learning Summer School 
 Installation Instructions 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 ```
conda install lua=5.2 lua-science -c alexbw 
 Although, you could install other Lua versions like 2.0 (LuaJIT), 5.1, 5.2 and 5.3 
 ``` 
 Clone this repository and start the notebook server 
 ```
git clone https://github.com/alexbw/bayarea-dl-summerschool.git
cd bayarea-dl-summerschool
itorch notebook 
 Will open a browser tab, then you can navigate to the notebooks 
 ```","Boston, MA",False,Google,7,DevOps,95,0.31,0.38,0.29,0,False,https://avatars.githubusercontent.com/u/161935?u=f722a589176ab3dce6285bcce174117e3c103ec3&v=4,2009-12-04T14:50:40Z,2022-08-23T18:31:52Z,,False,False,False,False,False,True,False,0,396,332,0,47,2016-08-15 18:39:55,1
JavaScript,alexbw,Alex Wiltschko,,alex.bw@gmail.com,"Sampling Inference for Bayesian HSMMs and HMMs 
 This is a Python library for approximate unsupervised sampling inference in
Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov
Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM
and HDP-HSMM, via the weak-limit approximation. 
 There are also some plugins to extend the functionality: 
 
 factorial models 
 autoregressive models 
 collapsed HDP sampling inference . 
 
 The inference can be run in parallel over multiple cores and/or multiple
machines (even on EC2!) using  ipython 's
excellent  ipython.parallel  module. Someday I might even document how to do
it! 
 Installing 
 You can clone this library and its dependencies with 
 git clone --recursive git://github.com/mattjj/pyhsmm.git 
 The library depends on  numpy ,  scipy , and, for visualization,  matplotlib . 
 Disabling assertions may speed things up; to disable assertions, run your
CPython interpreter with the  -O  flag. 
 A Simple Demonstration 
 Here's how to draw from the HDP-HSMM posterior over HSMMs given a sequence of
observations. (The same example, along with the code to generate the synthetic
data loaded in this example, can be found in  examples/basic.py .) 
 Let's say we have some 2D data in a data.txt file: 
 bash
 head -5 data.txt
-3.711962552600095444e-02 1.456401745267922598e-01
7.553818775915704942e-02 2.457422192223903679e-01
-2.465977987699214502e+00 5.537627981813508793e-01
-7.031638516485749779e-01 1.536468304146855757e-01
-9.224669847039665971e-01 3.680035337673161489e-01 
 In Python, we can plot the data in a 2D plot, collapsing out the time dimension: 
 ```python
import numpy as np
from matplotlib import pyplot as plt 
 data = np.loadtxt('data.txt')
plt.plot(data[:,0],data[:,1],'kx')
``` 
 
 We can also make a plot of time versus the first principal component: 
 python
from pyhsmm.util.plot import pca_project_data
plt.plot(pca_project_data(data,1)) 
 
 To learn an HSMM, we'll use  pyhsmm  to create an  HSMM  instance using some
reasonable hyperparameters. We'll ask this model to infer the number of states
as well (since an HDP-HSMM is instantiated by default), so we'll give it an
 Nmax  parameter: 
 ```python
import pyhsmm
import pyhsmm.basic.distributions as distributions 
 obs_dim = 2
Nmax = 25 
 obs_hypparams = {'mu_0':np.zeros(obs_dim),
                'sigma_0':np.eye(obs_dim),
                'kappa_0':0.3,
                'nu_0':obs_dim+5}
dur_hypparams = {'alpha_0':2*30,
                 'beta_0':2} 
 obs_distns = [distributions.Gaussian( obs_hypparams) for state in range(Nmax)]
dur_distns = [distributions.PoissonDuration( dur_hypparams) for state in range(Nmax)] 
 posteriormodel = pyhsmm.models.HSMM(
        alpha=6.,gamma=6., # better to sample over these; see concentration-resampling.py
        init_state_concentration=6., # pretty inconsequential
        obs_distns=obs_distns,
        dur_distns=dur_distns,
        trunc=60) # duration truncation speeds things up when it's possible
``` 
 (The first two arguments set the ""new-table"" proportionality constant for the
meta-Chinese Restaurant Process and the other CRPs, respectively, in the HDP
prior on transition matrices. For this example, they really don't matter at
all, but on real data it's much better to infer these parameters, as in
 examples/concentration_resampling.py .) 
 The  trunc  parameter is an optional argument that can speed up inference: it
sets a truncation limit on the maximum duration for any state. If you don't
pass in the  trunc  argument, no truncation is used and all possible state
duration lengths are considered. 
 Then, we add the data we want to condition on: 
 python
posteriormodel.add_data(data) 
 (If we had multiple observation sequences to learn from, we could add them to the
model just by calling  add_data()  for each observation sequence.) 
 Now we run a resampling loop. For each iteration of the loop, all the latent
variables of the model will be resampled by Gibbs sampling steps, including the
transition matrix, the observation means and covariances, the duration
parameters, and the hidden state sequence. We'll also copy some samples so that
we can plot them. 
 python
models = []
for idx in progprint_xrange(150):
    posteriormodel.resample_model()
    if (idx+1) % 10 == 0:
        models.append(copy.deepcopy(posteriormodel)) 
 Now we can plot our saved samples: 
 python
fig = plt.figure()
for idx, model in enumerate(models):
    plt.clf()
    model.plot()
    plt.gcf().suptitle('HDP-HSMM sampled after %d iterations' % (10*(idx+1)))
    plt.savefig('iter_%.3d.png' % (10*(idx+1))) 
 
 I generated these data from an HSMM that looked like this: 
 
 So the posterior samples look pretty good! 
 Speed 
 HSMMs constitute a much more powerful model class than plain-old HMMs, and that
enhanced power comes with a computational price: each sampling iteration for an
HSMM is much slower than that of an HMM. But that price is often worthwhile if
you want to place priors on state durations or have the model learn duration
structure present in the data. (In the example, strong duration structure is
what made the inference algorithm latch onto the correct explanation so
easily.) In addition, the increased cost of each iteration often pays for
itself, since HSMM samplers empirically seem to take fewer iterations to
converge than comparable HMM samplers. 
 Using my nothing-special i7-920 desktop machine and a NumPy/SciPy built against
Intel's MKL BLAS (which generally outperforms ATLAS for vectorized operations)
along with the Eigen-backed classes, here's how long the demo iterations took: 
 $ python examples/hsmm.py
.........................  [  25/100,    0.05sec avg,    3.95sec ETA ]
.........................  [  50/100,    0.05sec avg,    2.64sec ETA ]
.........................  [  75/100,    0.05sec avg,    1.34sec ETA ]
.........................  [ 100/100,    0.05sec avg,    0.05sec ETA ]
   0.05sec avg,    5.21sec total 
 Extending the Code 
 To add your own observation or duration distributions, implement the interfaces
defined in  basic/abstractions.py . Also see the plugins. To get a flavor of
the style, see  pybasicbayes . 
 Contributors 
 Contributions by Chia-ying Lee. 
 References 
 
 
 Matthew J. Johnson and Alan S. Willsky.  Bayesian Nonparametric Hidden
  Semi-Markov Models .
  Journal of Machine Learning Research (JMLR), 14:673â€“701, February 2013. 
 
 
 Matthew J. Johnson and Alan S. Willsky,  The Hierarchical Dirichlet Process
  Hidden Semi-Markov Model . 26th
  Conference on Uncertainty in Artificial Intelligence (UAI 2010), Avalon,
  California, July 2010. 
 
 
 bibtex
@article{johnson2013hdphsmm,
    title={Bayesian Nonparametric Hidden Semi-Markov Models},
    author={Johnson, Matthew J. and Willsky, Alan S.},
    journal={Journal of Machine Learning Research},
    pages={673--701},
    volume={14},
    month={February},
    year={2013},
}An analgesic for high-performance audio on iOS and OSX. 
 Really fast audio in iOS and Mac OS X using Audio Units is hard, and will leave you scarred and bloody. What used to take days can now be done with just a few lines of code. 
 Getting Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setInputBlock:^(float *newAudio, UInt32 numSamples, UInt32 numChannels) {
    // Now you're getting audio from the microphone every 20 milliseconds or so. How's that for easy?
    // Audio comes in interleaved, so,
    // if numChannels = 2, newAudio[0] is channel 1, newAudio[1] is channel 2, newAudio[2] is channel 1, etc.
}];
[audioManager play]; 
 Playing Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setOutputBlock:^(float *audioToPlay, UInt32 numSamples, UInt32 numChannels) {
    // All you have to do is put your audio into ""audioToPlay"".
}];
[audioManager play]; 
 Does anybody actually use it? 
 Yep. Novocaine is result of three years of work on the audio engine of  Octave ,  Fourier  and  oScope , a powerful suite of audio analysis apps. Please do check them out! 
 A thing to note: 
 The RingBuffer class is written in C++ to make things extra zippy, so the classes that use it will have to be Objective-C++. Change all the files that use RingBuffer from MyClass.m to MyClass.mm. 
 Want some examples? 
 Inside of ViewController.mm are a bunch of tiny little examples I wrote. Uncomment one and see how it sounds. 
Do note, however, for examples involving play-through, that you should be using headphones. Having the 
mic and speaker close to each other will produce some gnarly feedback.   
 Want to learn the nitty-gritty of Core Audio? 
 If you want to get down and dirty, if you want to get brave and get close to the hardware, I can only point you to the places where I learned how to do this stuff. Chris Adamson and Michael Tyson are two giants in the field of iOS audio, and they each wrote indispensable blog posts ( this is Chris's ,  this is Michael's ). Also, Chris Adamson now has a  whole gosh-darned BOOK on Core Audio . I would have done unspeakable things to get my hands on this when I was first starting. 
My Code for the Netflix Prize 
 I'm not aware of folks having published their code for the Netflix Prize. Here's mine. 
Under the team name ""Hi!"", I competed alone in college. I did it mostly for fun, and to learn modern machine learning techniques. It was an incredibly valuable, but strenuous, time. Well worth it on all fronts, though.  
I peaked out at #45 or so, and then dropped out to work on my senior thesis, and came in #145 or so.   
What I learned in the process was that smarter wasn't always better -- make an algorithm, and then scale it up, and then make a dozen tweaks to it, and then average all of the results together. That's how you climbed the leaderboard.    
 Anyhoo, I haven't touched this code in awhile, but perhaps it'll be useful to folks interested in competitive data mining. 
Specifically, the lessons I learned: 
 
 Get the raw data into a saved and manageable format  fast . The easier it is to load your data in and start mutating it, the better. 
 If doing simple pivots on your data is hard, and slows you down from visualizing whats in your data, spend time making data structures which make that easy.   
 Generalize. Iterate. If you have a method you think will work, but it has a lot of knobs, and you don't know the best way to set those knobs, make it easy for you to try  every possible iteration . There is often not a good way to figure out what the  best  approach is. You will have to try many of them in order to build up an intuition. Specifically, that means (for me) a pluggable architecture. If there's ten ways to try a particular step, make sure you write your overarching algorithm so that it takes a function that you can pass to it, as opposed to having a method hardwired in the code. That way, you can hotswap all your ideas.   
 Speed is a feature. Of course you make sure it works first. But your goal is to see if something works. If an algorithm takes a day to run, but you can spend five hours making it run in 1/3 of a day, do it. You'll be running it over and over again, and you'll learn more if you can iterate.  
 
 As for the technical nitty-gritty, everything that's speed sensitive is written in Cython, which was the best balance of speed and convenience in 2009. If I were to do it al again, I would use (Numba)[http://github.com/numba/numba].   
 The original data is gone, I believe, but I might have it stored somewhere. I'll look for that.  NURBS - Non Uniform Rational B-Splines. 
 This python module is a revival and update of Runar Tenfjord's NURBS toolbox, which itself
is a port of Mark Spink's SCILAB/MATLAB tolbox to python with help of numpy. 
 Dependency 
 Python 2.0 or above 
NumPy 
Dislin -> optional but recomended 
PyOpenGL -> optional   
 Installation 
 Just run   python setup.py install   
 License 
 Runar Tenfjord originally relased this package under the GPL Version 2 license,  
so I suppose that means it has to stay that way.    
 Originally by: Runar Tenfjord, runten@netcom.no 
Minor updates to work with NumPy by Alex Wiltschko  cuda-tests 
 Gotta learn some CUDA stuffpypatent 
 Scrape patents from the USPTOairruler 
 A ruler. Made of air. paralleltools 
 A summary of parallelizing moderate amounts of work in Pythonnsgt 
 Non-stationary Gabor transforms (GitHub mirror of http://grrrr.org/research/software/nsgt/)IDA 
 This code accompanies the publication from the Whitesides lab to Lab on a Chip, concerning automated analysis of red blood cell health using affordable field tests. Specifically, this code implements the automated extraction of scanned AMPS tubes from flatbed scanner images, the distillation of those images into 1D data traces, and then the automated identification of the anemic disease state of the blood in those 1D data traces, as well as the prediction of continuously-varying red blood cell (RBC) parameters. 
 Installation 
 This code requires Python, as well as some extra 3rd-party libraries. All routines have only been tested on Mac OS, but should work on Linux. No guarantees for Windows.
1) First, we recommend using the ""Anaconda"" Python distribution, specifically the Python 2.7 version.  Download and install here .
1) With anaconda installed, you will need one extra library, to read TIFF files.
 pip install imageio 
1) You should be able to run the notebooks now. Inside this code repository, start up an IPython notebook:
 jupyter notebook 
1) You should now be able to browser around the ""extraction"" and ""analysis"" folders, which contain the relevant code. 
 Running extraction 
 The first step required will be to prepare the raw data of TIFF file scans of 4x3=12 tubes from a flatbed scanner. We will also have to associate metadata for each patient that the blood in a tube was drawn from.
Our end goal will be a 1D array for each tube, along with the corresponding patient data (anemic state & RBC parameters). 
 The extraction algorithm is explained step-by-step in the notebook  extraction/Explaining the Extraction Algorithm.ipynb .
The implementation we use in the paper (which also fuses patient metadata with AMPS image data) can be found in  extraction/Data Extraction Pipeline.ipynb . Most of the code in this notebook is specific to the particular Excel file format that we used to record patient metadata, and may have to be largely rewritten for reuse. 
 Running analysis 
 There are two sets of analyses done in the paper: classification and regression. 
 Running classification analysis 
 The goal of this analysis is to predict disease state only from the 1D data trace extracted from each AMPS tube. We use logistic regression, a linear classifier, and transform the 1D data representation using PCA to remove redundancy and constrain the input dimensionality of the problem. We also used Bayesian Optimization (bayesopt) to tune the hyperparameters of the problem, including the specific output dimension of PCA, the regularization parameter of logistic regression, and some image preprocessing parameters. Unfortunately, the service we used for bayesopt is no longer available. If you would like to automatically tune these parameters, we recommend either using random search (a surprisingly effective hueristic), or the open source library ""Spearmint"", upon which the now-defunct service we used was based, or products from the company SigOpt, which also implements bayesopt. The file we used to automatically tune these hypers is  classify.py .
The best set of hyperparameters is stored in the notebook  Analyzing best classification.ipynb .
This notebook examines ROC performance of the classifier for discriminating different anemia types, as well as the effect of centrifugation time of the tube on IDA classification AUC performance. 
 Running regression analysis. 
 Similar to above, we used a defunct bayesopt service to automatically tune some parameters of this algorithm. The original file is in  regress.py . The original methodology will work well, even without automated tuning.
The best set of hyperparameters is stored in the notebook  Analyzing best regression.ipynb . 
 License 
 See the LICENSE file. It is under a GPL license, and this code may only be used for academic purposes.adabayes 
 To do: 
 
 [x] Find candidate last layer features (DeCAF, Overfeat) 
 [x] Find AlexNet code (5 convolutional layers with max-pooling, then three fully connected layers) 
 [X]  Find download script for MNIST dataset 
 [X]  Find download script for CIFAR10 dataset 
 [x] Fork torch-dist repo 
 [x] Update torch-dist repo for OS X 10.10 install 
 [x] Add new required submodules to distro (nnx, iTorch, ccn2, cunnx, cudnn, sdl2, cutorch) 
 [x] Figure out model serialization and loading 
 Built-in model serialization.  Loading  and  saving . 
 There is also facebook's  Thrift library , which I haven't seen many examples for. 
 
 
 [ ] Get the data out of the  DataSource  models that we're using 
 [ ] Train and Whetlab a net on MNIST (to get the whole workflow going) 
 [ ] Train and Whetlab a net on CIFAR10 
 [ ] Train and Whetlab a net on STL10 
 [ ] Build dumb ensemble on CIFAR10 
 [ ] Build dumb ensemble on STL10 
 [ ] Grok boosting criterion 
 [ ] Whetlab a net with progressive ensembling on CIFAR10 
 [ ] Whetlab a net with progressive ensembling on STL10 
 [ ] Whetlab a net with progressive ensembling on the last-layer features of ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on CIFAR10 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on STL10 
 [ ] Extract last-layer ImageNet features 
 [ ] Host last-layer ImageNet features 
 [ ] Build download script for last-layer ImageNet features 
 [ ] Train and Whetlab a net on last-layer features on ImageNet 
 [ ] Build a dumb ensemble on ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on the last-layer features of ImageNet 
 
 Collecting some resources 
 AlexNet:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/alexnet.lua 
 I think this is NiN:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/googlenet.lua 
 OverFeat:
https://github.com/facebook/fbcunn/blob/master/examples/imagenet/models/overfeat_cunn.lua 
 Multiclass criterion:
https://github.com/torch/nn/blob/master/doc/criterion.md#classnllcriterion 
 Some other interesting nets:
https://github.com/culurciello/profiling 
 Bunch of demos, not all nets:
https://github.com/torch/demos 
 Overfeat features:
http://cilvr.nyu.edu/doku.php?id=software:overfeat:start 
 Decaf ImageNet submission:
https://github.com/UCB-ICSI-Vision-Group/decaf-release/wiki/imagenet 
 Some other net implementations:
https://github.com/eladhoffer/ImageNet-TrainingConda recipes for installing packages from the Torch ecosystem. 
 NOTE: No longer maintained. 
 To install packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 conda install lua=5.2 lua-science -c alexbw 
 Available versions of Lua: 2.0, 5.1, 5.2, 5.3 
 2.0 is LuaJIT 
 ``` 
 To build packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Get the newest version of conda, as well as some conda build tools 
 conda update conda -y
conda install conda-build anaconda-client -y 
 Build all packages 
 sh build_all.sh 
 Ideally, all you have to do to install everything is this 
 conda install lua=5.2 lua-science
``` 
 TODO:
 - https://github.com/AlexMili/torch-dataframe
 - https://github.com/twitter/torch-ipc
 - https://github.com/twitter/torch-distlearn
 - https://github.com/twitter/torch-dataset 
 Resources: 
 
 
 Making packages relocatable (LuaJIT hard-codes path) 
 
 
 Build instructions for luarocks 
 
 
 Build instructions for Lua 
 
 
 Patching files with git diffs is finicky 
 
 
 Linking against readline  (need a few extra flags, and link against -lncursesw, not -lncurses) 
 
 
 Upgrading old Debian .  Also this . 
 
 
 Misc notes:
 metadata:ns_cfg() â€” defines for YAML directives
main_build: â€”Â defines version numbers 
environ:get_lua_include_dir() â€”Â uses version numbers to locate the include directory
config:Config._get_lua â€”Â uses version numbers to locate the binary
This is where the linked package name is converted into what is usedvalidata 
 Continuous integration for your data 
 We do continuous integration on code. Why not data?
Validata is a small package to run basic sanity checks on your data.
I haven't found anything that aggregates all of these checks and tricks in one place. 
 There is only one method which is exposed,  check(data,labels)  (optionally taking data or labels).
If any data check fails, it throws a well-named error, as well as hints for how you might fix the problem -- data covariance matrix ill-conditioned? Try whitening. 
 Initially, this will be a Python/NumPy only package running basic checks, but hopefully it becomes a resource of data sanity and sanitation checks.
Still very much a work in progress. 
 Examples (some implemented, some not) include: 
 
 If your labels are one-hot, are you using all slots? 
 Is the covariance matrix of your data ill-conditioned? 
 Do you have any constant variables? 
 Can you train a classifier to distinguish train and test data, using whether they are in train or test as a label? Indicates different data distributions. 
 If you're using integer labels, are the unique labels contiguous? 
 Do you have just one unique label? 
 Is the data under different labels statistically separable? 
 If you have an old dataset and a new dataset (or two halves of the same dataset), is the distribution of each dimension stationary? Check for divergence with a KS test. 
 What else? I end up applying these tricks in a very ad hoc fashion, whenever a subtle bug pops up, and not rigorously before each project I tackle. I'd like to stuff all these tricks in one place, and run them like a unit test, or a continuous integration test, on data that I start working with. 
 
 Should probably also think about engardebayarea-dl-summerschool 
 Torch notebooks and slides for the Bay Area Deep Learning Summer School 
 Installation Instructions 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 ```
conda install lua=5.2 lua-science -c alexbw 
 Although, you could install other Lua versions like 2.0 (LuaJIT), 5.1, 5.2 and 5.3 
 ``` 
 Clone this repository and start the notebook server 
 ```
git clone https://github.com/alexbw/bayarea-dl-summerschool.git
cd bayarea-dl-summerschool
itorch notebook 
 Will open a browser tab, then you can navigate to the notebooks 
 ```","Boston, MA",False,Google,7,DevOps,95,0.31,0.38,0.29,0,False,https://avatars.githubusercontent.com/u/161935?u=f722a589176ab3dce6285bcce174117e3c103ec3&v=4,2009-12-04T14:50:40Z,2022-08-23T18:31:52Z,,False,False,False,False,False,True,False,0,396,332,0,47,2016-08-15 18:39:55,3
Jupyter Notebook,alexbw,Alex Wiltschko,,alex.bw@gmail.com,"Sampling Inference for Bayesian HSMMs and HMMs 
 This is a Python library for approximate unsupervised sampling inference in
Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov
Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM
and HDP-HSMM, via the weak-limit approximation. 
 There are also some plugins to extend the functionality: 
 
 factorial models 
 autoregressive models 
 collapsed HDP sampling inference . 
 
 The inference can be run in parallel over multiple cores and/or multiple
machines (even on EC2!) using  ipython 's
excellent  ipython.parallel  module. Someday I might even document how to do
it! 
 Installing 
 You can clone this library and its dependencies with 
 git clone --recursive git://github.com/mattjj/pyhsmm.git 
 The library depends on  numpy ,  scipy , and, for visualization,  matplotlib . 
 Disabling assertions may speed things up; to disable assertions, run your
CPython interpreter with the  -O  flag. 
 A Simple Demonstration 
 Here's how to draw from the HDP-HSMM posterior over HSMMs given a sequence of
observations. (The same example, along with the code to generate the synthetic
data loaded in this example, can be found in  examples/basic.py .) 
 Let's say we have some 2D data in a data.txt file: 
 bash
 head -5 data.txt
-3.711962552600095444e-02 1.456401745267922598e-01
7.553818775915704942e-02 2.457422192223903679e-01
-2.465977987699214502e+00 5.537627981813508793e-01
-7.031638516485749779e-01 1.536468304146855757e-01
-9.224669847039665971e-01 3.680035337673161489e-01 
 In Python, we can plot the data in a 2D plot, collapsing out the time dimension: 
 ```python
import numpy as np
from matplotlib import pyplot as plt 
 data = np.loadtxt('data.txt')
plt.plot(data[:,0],data[:,1],'kx')
``` 
 
 We can also make a plot of time versus the first principal component: 
 python
from pyhsmm.util.plot import pca_project_data
plt.plot(pca_project_data(data,1)) 
 
 To learn an HSMM, we'll use  pyhsmm  to create an  HSMM  instance using some
reasonable hyperparameters. We'll ask this model to infer the number of states
as well (since an HDP-HSMM is instantiated by default), so we'll give it an
 Nmax  parameter: 
 ```python
import pyhsmm
import pyhsmm.basic.distributions as distributions 
 obs_dim = 2
Nmax = 25 
 obs_hypparams = {'mu_0':np.zeros(obs_dim),
                'sigma_0':np.eye(obs_dim),
                'kappa_0':0.3,
                'nu_0':obs_dim+5}
dur_hypparams = {'alpha_0':2*30,
                 'beta_0':2} 
 obs_distns = [distributions.Gaussian( obs_hypparams) for state in range(Nmax)]
dur_distns = [distributions.PoissonDuration( dur_hypparams) for state in range(Nmax)] 
 posteriormodel = pyhsmm.models.HSMM(
        alpha=6.,gamma=6., # better to sample over these; see concentration-resampling.py
        init_state_concentration=6., # pretty inconsequential
        obs_distns=obs_distns,
        dur_distns=dur_distns,
        trunc=60) # duration truncation speeds things up when it's possible
``` 
 (The first two arguments set the ""new-table"" proportionality constant for the
meta-Chinese Restaurant Process and the other CRPs, respectively, in the HDP
prior on transition matrices. For this example, they really don't matter at
all, but on real data it's much better to infer these parameters, as in
 examples/concentration_resampling.py .) 
 The  trunc  parameter is an optional argument that can speed up inference: it
sets a truncation limit on the maximum duration for any state. If you don't
pass in the  trunc  argument, no truncation is used and all possible state
duration lengths are considered. 
 Then, we add the data we want to condition on: 
 python
posteriormodel.add_data(data) 
 (If we had multiple observation sequences to learn from, we could add them to the
model just by calling  add_data()  for each observation sequence.) 
 Now we run a resampling loop. For each iteration of the loop, all the latent
variables of the model will be resampled by Gibbs sampling steps, including the
transition matrix, the observation means and covariances, the duration
parameters, and the hidden state sequence. We'll also copy some samples so that
we can plot them. 
 python
models = []
for idx in progprint_xrange(150):
    posteriormodel.resample_model()
    if (idx+1) % 10 == 0:
        models.append(copy.deepcopy(posteriormodel)) 
 Now we can plot our saved samples: 
 python
fig = plt.figure()
for idx, model in enumerate(models):
    plt.clf()
    model.plot()
    plt.gcf().suptitle('HDP-HSMM sampled after %d iterations' % (10*(idx+1)))
    plt.savefig('iter_%.3d.png' % (10*(idx+1))) 
 
 I generated these data from an HSMM that looked like this: 
 
 So the posterior samples look pretty good! 
 Speed 
 HSMMs constitute a much more powerful model class than plain-old HMMs, and that
enhanced power comes with a computational price: each sampling iteration for an
HSMM is much slower than that of an HMM. But that price is often worthwhile if
you want to place priors on state durations or have the model learn duration
structure present in the data. (In the example, strong duration structure is
what made the inference algorithm latch onto the correct explanation so
easily.) In addition, the increased cost of each iteration often pays for
itself, since HSMM samplers empirically seem to take fewer iterations to
converge than comparable HMM samplers. 
 Using my nothing-special i7-920 desktop machine and a NumPy/SciPy built against
Intel's MKL BLAS (which generally outperforms ATLAS for vectorized operations)
along with the Eigen-backed classes, here's how long the demo iterations took: 
 $ python examples/hsmm.py
.........................  [  25/100,    0.05sec avg,    3.95sec ETA ]
.........................  [  50/100,    0.05sec avg,    2.64sec ETA ]
.........................  [  75/100,    0.05sec avg,    1.34sec ETA ]
.........................  [ 100/100,    0.05sec avg,    0.05sec ETA ]
   0.05sec avg,    5.21sec total 
 Extending the Code 
 To add your own observation or duration distributions, implement the interfaces
defined in  basic/abstractions.py . Also see the plugins. To get a flavor of
the style, see  pybasicbayes . 
 Contributors 
 Contributions by Chia-ying Lee. 
 References 
 
 
 Matthew J. Johnson and Alan S. Willsky.  Bayesian Nonparametric Hidden
  Semi-Markov Models .
  Journal of Machine Learning Research (JMLR), 14:673â€“701, February 2013. 
 
 
 Matthew J. Johnson and Alan S. Willsky,  The Hierarchical Dirichlet Process
  Hidden Semi-Markov Model . 26th
  Conference on Uncertainty in Artificial Intelligence (UAI 2010), Avalon,
  California, July 2010. 
 
 
 bibtex
@article{johnson2013hdphsmm,
    title={Bayesian Nonparametric Hidden Semi-Markov Models},
    author={Johnson, Matthew J. and Willsky, Alan S.},
    journal={Journal of Machine Learning Research},
    pages={673--701},
    volume={14},
    month={February},
    year={2013},
}An analgesic for high-performance audio on iOS and OSX. 
 Really fast audio in iOS and Mac OS X using Audio Units is hard, and will leave you scarred and bloody. What used to take days can now be done with just a few lines of code. 
 Getting Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setInputBlock:^(float *newAudio, UInt32 numSamples, UInt32 numChannels) {
    // Now you're getting audio from the microphone every 20 milliseconds or so. How's that for easy?
    // Audio comes in interleaved, so,
    // if numChannels = 2, newAudio[0] is channel 1, newAudio[1] is channel 2, newAudio[2] is channel 1, etc.
}];
[audioManager play]; 
 Playing Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setOutputBlock:^(float *audioToPlay, UInt32 numSamples, UInt32 numChannels) {
    // All you have to do is put your audio into ""audioToPlay"".
}];
[audioManager play]; 
 Does anybody actually use it? 
 Yep. Novocaine is result of three years of work on the audio engine of  Octave ,  Fourier  and  oScope , a powerful suite of audio analysis apps. Please do check them out! 
 A thing to note: 
 The RingBuffer class is written in C++ to make things extra zippy, so the classes that use it will have to be Objective-C++. Change all the files that use RingBuffer from MyClass.m to MyClass.mm. 
 Want some examples? 
 Inside of ViewController.mm are a bunch of tiny little examples I wrote. Uncomment one and see how it sounds. 
Do note, however, for examples involving play-through, that you should be using headphones. Having the 
mic and speaker close to each other will produce some gnarly feedback.   
 Want to learn the nitty-gritty of Core Audio? 
 If you want to get down and dirty, if you want to get brave and get close to the hardware, I can only point you to the places where I learned how to do this stuff. Chris Adamson and Michael Tyson are two giants in the field of iOS audio, and they each wrote indispensable blog posts ( this is Chris's ,  this is Michael's ). Also, Chris Adamson now has a  whole gosh-darned BOOK on Core Audio . I would have done unspeakable things to get my hands on this when I was first starting. 
My Code for the Netflix Prize 
 I'm not aware of folks having published their code for the Netflix Prize. Here's mine. 
Under the team name ""Hi!"", I competed alone in college. I did it mostly for fun, and to learn modern machine learning techniques. It was an incredibly valuable, but strenuous, time. Well worth it on all fronts, though.  
I peaked out at #45 or so, and then dropped out to work on my senior thesis, and came in #145 or so.   
What I learned in the process was that smarter wasn't always better -- make an algorithm, and then scale it up, and then make a dozen tweaks to it, and then average all of the results together. That's how you climbed the leaderboard.    
 Anyhoo, I haven't touched this code in awhile, but perhaps it'll be useful to folks interested in competitive data mining. 
Specifically, the lessons I learned: 
 
 Get the raw data into a saved and manageable format  fast . The easier it is to load your data in and start mutating it, the better. 
 If doing simple pivots on your data is hard, and slows you down from visualizing whats in your data, spend time making data structures which make that easy.   
 Generalize. Iterate. If you have a method you think will work, but it has a lot of knobs, and you don't know the best way to set those knobs, make it easy for you to try  every possible iteration . There is often not a good way to figure out what the  best  approach is. You will have to try many of them in order to build up an intuition. Specifically, that means (for me) a pluggable architecture. If there's ten ways to try a particular step, make sure you write your overarching algorithm so that it takes a function that you can pass to it, as opposed to having a method hardwired in the code. That way, you can hotswap all your ideas.   
 Speed is a feature. Of course you make sure it works first. But your goal is to see if something works. If an algorithm takes a day to run, but you can spend five hours making it run in 1/3 of a day, do it. You'll be running it over and over again, and you'll learn more if you can iterate.  
 
 As for the technical nitty-gritty, everything that's speed sensitive is written in Cython, which was the best balance of speed and convenience in 2009. If I were to do it al again, I would use (Numba)[http://github.com/numba/numba].   
 The original data is gone, I believe, but I might have it stored somewhere. I'll look for that.  NURBS - Non Uniform Rational B-Splines. 
 This python module is a revival and update of Runar Tenfjord's NURBS toolbox, which itself
is a port of Mark Spink's SCILAB/MATLAB tolbox to python with help of numpy. 
 Dependency 
 Python 2.0 or above 
NumPy 
Dislin -> optional but recomended 
PyOpenGL -> optional   
 Installation 
 Just run   python setup.py install   
 License 
 Runar Tenfjord originally relased this package under the GPL Version 2 license,  
so I suppose that means it has to stay that way.    
 Originally by: Runar Tenfjord, runten@netcom.no 
Minor updates to work with NumPy by Alex Wiltschko  cuda-tests 
 Gotta learn some CUDA stuffpypatent 
 Scrape patents from the USPTOairruler 
 A ruler. Made of air. paralleltools 
 A summary of parallelizing moderate amounts of work in Pythonnsgt 
 Non-stationary Gabor transforms (GitHub mirror of http://grrrr.org/research/software/nsgt/)IDA 
 This code accompanies the publication from the Whitesides lab to Lab on a Chip, concerning automated analysis of red blood cell health using affordable field tests. Specifically, this code implements the automated extraction of scanned AMPS tubes from flatbed scanner images, the distillation of those images into 1D data traces, and then the automated identification of the anemic disease state of the blood in those 1D data traces, as well as the prediction of continuously-varying red blood cell (RBC) parameters. 
 Installation 
 This code requires Python, as well as some extra 3rd-party libraries. All routines have only been tested on Mac OS, but should work on Linux. No guarantees for Windows.
1) First, we recommend using the ""Anaconda"" Python distribution, specifically the Python 2.7 version.  Download and install here .
1) With anaconda installed, you will need one extra library, to read TIFF files.
 pip install imageio 
1) You should be able to run the notebooks now. Inside this code repository, start up an IPython notebook:
 jupyter notebook 
1) You should now be able to browser around the ""extraction"" and ""analysis"" folders, which contain the relevant code. 
 Running extraction 
 The first step required will be to prepare the raw data of TIFF file scans of 4x3=12 tubes from a flatbed scanner. We will also have to associate metadata for each patient that the blood in a tube was drawn from.
Our end goal will be a 1D array for each tube, along with the corresponding patient data (anemic state & RBC parameters). 
 The extraction algorithm is explained step-by-step in the notebook  extraction/Explaining the Extraction Algorithm.ipynb .
The implementation we use in the paper (which also fuses patient metadata with AMPS image data) can be found in  extraction/Data Extraction Pipeline.ipynb . Most of the code in this notebook is specific to the particular Excel file format that we used to record patient metadata, and may have to be largely rewritten for reuse. 
 Running analysis 
 There are two sets of analyses done in the paper: classification and regression. 
 Running classification analysis 
 The goal of this analysis is to predict disease state only from the 1D data trace extracted from each AMPS tube. We use logistic regression, a linear classifier, and transform the 1D data representation using PCA to remove redundancy and constrain the input dimensionality of the problem. We also used Bayesian Optimization (bayesopt) to tune the hyperparameters of the problem, including the specific output dimension of PCA, the regularization parameter of logistic regression, and some image preprocessing parameters. Unfortunately, the service we used for bayesopt is no longer available. If you would like to automatically tune these parameters, we recommend either using random search (a surprisingly effective hueristic), or the open source library ""Spearmint"", upon which the now-defunct service we used was based, or products from the company SigOpt, which also implements bayesopt. The file we used to automatically tune these hypers is  classify.py .
The best set of hyperparameters is stored in the notebook  Analyzing best classification.ipynb .
This notebook examines ROC performance of the classifier for discriminating different anemia types, as well as the effect of centrifugation time of the tube on IDA classification AUC performance. 
 Running regression analysis. 
 Similar to above, we used a defunct bayesopt service to automatically tune some parameters of this algorithm. The original file is in  regress.py . The original methodology will work well, even without automated tuning.
The best set of hyperparameters is stored in the notebook  Analyzing best regression.ipynb . 
 License 
 See the LICENSE file. It is under a GPL license, and this code may only be used for academic purposes.adabayes 
 To do: 
 
 [x] Find candidate last layer features (DeCAF, Overfeat) 
 [x] Find AlexNet code (5 convolutional layers with max-pooling, then three fully connected layers) 
 [X]  Find download script for MNIST dataset 
 [X]  Find download script for CIFAR10 dataset 
 [x] Fork torch-dist repo 
 [x] Update torch-dist repo for OS X 10.10 install 
 [x] Add new required submodules to distro (nnx, iTorch, ccn2, cunnx, cudnn, sdl2, cutorch) 
 [x] Figure out model serialization and loading 
 Built-in model serialization.  Loading  and  saving . 
 There is also facebook's  Thrift library , which I haven't seen many examples for. 
 
 
 [ ] Get the data out of the  DataSource  models that we're using 
 [ ] Train and Whetlab a net on MNIST (to get the whole workflow going) 
 [ ] Train and Whetlab a net on CIFAR10 
 [ ] Train and Whetlab a net on STL10 
 [ ] Build dumb ensemble on CIFAR10 
 [ ] Build dumb ensemble on STL10 
 [ ] Grok boosting criterion 
 [ ] Whetlab a net with progressive ensembling on CIFAR10 
 [ ] Whetlab a net with progressive ensembling on STL10 
 [ ] Whetlab a net with progressive ensembling on the last-layer features of ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on CIFAR10 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on STL10 
 [ ] Extract last-layer ImageNet features 
 [ ] Host last-layer ImageNet features 
 [ ] Build download script for last-layer ImageNet features 
 [ ] Train and Whetlab a net on last-layer features on ImageNet 
 [ ] Build a dumb ensemble on ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on the last-layer features of ImageNet 
 
 Collecting some resources 
 AlexNet:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/alexnet.lua 
 I think this is NiN:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/googlenet.lua 
 OverFeat:
https://github.com/facebook/fbcunn/blob/master/examples/imagenet/models/overfeat_cunn.lua 
 Multiclass criterion:
https://github.com/torch/nn/blob/master/doc/criterion.md#classnllcriterion 
 Some other interesting nets:
https://github.com/culurciello/profiling 
 Bunch of demos, not all nets:
https://github.com/torch/demos 
 Overfeat features:
http://cilvr.nyu.edu/doku.php?id=software:overfeat:start 
 Decaf ImageNet submission:
https://github.com/UCB-ICSI-Vision-Group/decaf-release/wiki/imagenet 
 Some other net implementations:
https://github.com/eladhoffer/ImageNet-TrainingConda recipes for installing packages from the Torch ecosystem. 
 NOTE: No longer maintained. 
 To install packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 conda install lua=5.2 lua-science -c alexbw 
 Available versions of Lua: 2.0, 5.1, 5.2, 5.3 
 2.0 is LuaJIT 
 ``` 
 To build packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Get the newest version of conda, as well as some conda build tools 
 conda update conda -y
conda install conda-build anaconda-client -y 
 Build all packages 
 sh build_all.sh 
 Ideally, all you have to do to install everything is this 
 conda install lua=5.2 lua-science
``` 
 TODO:
 - https://github.com/AlexMili/torch-dataframe
 - https://github.com/twitter/torch-ipc
 - https://github.com/twitter/torch-distlearn
 - https://github.com/twitter/torch-dataset 
 Resources: 
 
 
 Making packages relocatable (LuaJIT hard-codes path) 
 
 
 Build instructions for luarocks 
 
 
 Build instructions for Lua 
 
 
 Patching files with git diffs is finicky 
 
 
 Linking against readline  (need a few extra flags, and link against -lncursesw, not -lncurses) 
 
 
 Upgrading old Debian .  Also this . 
 
 
 Misc notes:
 metadata:ns_cfg() â€” defines for YAML directives
main_build: â€”Â defines version numbers 
environ:get_lua_include_dir() â€”Â uses version numbers to locate the include directory
config:Config._get_lua â€”Â uses version numbers to locate the binary
This is where the linked package name is converted into what is usedvalidata 
 Continuous integration for your data 
 We do continuous integration on code. Why not data?
Validata is a small package to run basic sanity checks on your data.
I haven't found anything that aggregates all of these checks and tricks in one place. 
 There is only one method which is exposed,  check(data,labels)  (optionally taking data or labels).
If any data check fails, it throws a well-named error, as well as hints for how you might fix the problem -- data covariance matrix ill-conditioned? Try whitening. 
 Initially, this will be a Python/NumPy only package running basic checks, but hopefully it becomes a resource of data sanity and sanitation checks.
Still very much a work in progress. 
 Examples (some implemented, some not) include: 
 
 If your labels are one-hot, are you using all slots? 
 Is the covariance matrix of your data ill-conditioned? 
 Do you have any constant variables? 
 Can you train a classifier to distinguish train and test data, using whether they are in train or test as a label? Indicates different data distributions. 
 If you're using integer labels, are the unique labels contiguous? 
 Do you have just one unique label? 
 Is the data under different labels statistically separable? 
 If you have an old dataset and a new dataset (or two halves of the same dataset), is the distribution of each dimension stationary? Check for divergence with a KS test. 
 What else? I end up applying these tricks in a very ad hoc fashion, whenever a subtle bug pops up, and not rigorously before each project I tackle. I'd like to stuff all these tricks in one place, and run them like a unit test, or a continuous integration test, on data that I start working with. 
 
 Should probably also think about engardebayarea-dl-summerschool 
 Torch notebooks and slides for the Bay Area Deep Learning Summer School 
 Installation Instructions 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 ```
conda install lua=5.2 lua-science -c alexbw 
 Although, you could install other Lua versions like 2.0 (LuaJIT), 5.1, 5.2 and 5.3 
 ``` 
 Clone this repository and start the notebook server 
 ```
git clone https://github.com/alexbw/bayarea-dl-summerschool.git
cd bayarea-dl-summerschool
itorch notebook 
 Will open a browser tab, then you can navigate to the notebooks 
 ```","Boston, MA",False,Google,7,DevOps,95,0.31,0.38,0.29,0,False,https://avatars.githubusercontent.com/u/161935?u=f722a589176ab3dce6285bcce174117e3c103ec3&v=4,2009-12-04T14:50:40Z,2022-08-23T18:31:52Z,,False,False,False,False,False,True,False,0,396,332,0,47,2016-08-15 18:39:55,5
Lua,alexbw,Alex Wiltschko,,alex.bw@gmail.com,"Sampling Inference for Bayesian HSMMs and HMMs 
 This is a Python library for approximate unsupervised sampling inference in
Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov
Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM
and HDP-HSMM, via the weak-limit approximation. 
 There are also some plugins to extend the functionality: 
 
 factorial models 
 autoregressive models 
 collapsed HDP sampling inference . 
 
 The inference can be run in parallel over multiple cores and/or multiple
machines (even on EC2!) using  ipython 's
excellent  ipython.parallel  module. Someday I might even document how to do
it! 
 Installing 
 You can clone this library and its dependencies with 
 git clone --recursive git://github.com/mattjj/pyhsmm.git 
 The library depends on  numpy ,  scipy , and, for visualization,  matplotlib . 
 Disabling assertions may speed things up; to disable assertions, run your
CPython interpreter with the  -O  flag. 
 A Simple Demonstration 
 Here's how to draw from the HDP-HSMM posterior over HSMMs given a sequence of
observations. (The same example, along with the code to generate the synthetic
data loaded in this example, can be found in  examples/basic.py .) 
 Let's say we have some 2D data in a data.txt file: 
 bash
 head -5 data.txt
-3.711962552600095444e-02 1.456401745267922598e-01
7.553818775915704942e-02 2.457422192223903679e-01
-2.465977987699214502e+00 5.537627981813508793e-01
-7.031638516485749779e-01 1.536468304146855757e-01
-9.224669847039665971e-01 3.680035337673161489e-01 
 In Python, we can plot the data in a 2D plot, collapsing out the time dimension: 
 ```python
import numpy as np
from matplotlib import pyplot as plt 
 data = np.loadtxt('data.txt')
plt.plot(data[:,0],data[:,1],'kx')
``` 
 
 We can also make a plot of time versus the first principal component: 
 python
from pyhsmm.util.plot import pca_project_data
plt.plot(pca_project_data(data,1)) 
 
 To learn an HSMM, we'll use  pyhsmm  to create an  HSMM  instance using some
reasonable hyperparameters. We'll ask this model to infer the number of states
as well (since an HDP-HSMM is instantiated by default), so we'll give it an
 Nmax  parameter: 
 ```python
import pyhsmm
import pyhsmm.basic.distributions as distributions 
 obs_dim = 2
Nmax = 25 
 obs_hypparams = {'mu_0':np.zeros(obs_dim),
                'sigma_0':np.eye(obs_dim),
                'kappa_0':0.3,
                'nu_0':obs_dim+5}
dur_hypparams = {'alpha_0':2*30,
                 'beta_0':2} 
 obs_distns = [distributions.Gaussian( obs_hypparams) for state in range(Nmax)]
dur_distns = [distributions.PoissonDuration( dur_hypparams) for state in range(Nmax)] 
 posteriormodel = pyhsmm.models.HSMM(
        alpha=6.,gamma=6., # better to sample over these; see concentration-resampling.py
        init_state_concentration=6., # pretty inconsequential
        obs_distns=obs_distns,
        dur_distns=dur_distns,
        trunc=60) # duration truncation speeds things up when it's possible
``` 
 (The first two arguments set the ""new-table"" proportionality constant for the
meta-Chinese Restaurant Process and the other CRPs, respectively, in the HDP
prior on transition matrices. For this example, they really don't matter at
all, but on real data it's much better to infer these parameters, as in
 examples/concentration_resampling.py .) 
 The  trunc  parameter is an optional argument that can speed up inference: it
sets a truncation limit on the maximum duration for any state. If you don't
pass in the  trunc  argument, no truncation is used and all possible state
duration lengths are considered. 
 Then, we add the data we want to condition on: 
 python
posteriormodel.add_data(data) 
 (If we had multiple observation sequences to learn from, we could add them to the
model just by calling  add_data()  for each observation sequence.) 
 Now we run a resampling loop. For each iteration of the loop, all the latent
variables of the model will be resampled by Gibbs sampling steps, including the
transition matrix, the observation means and covariances, the duration
parameters, and the hidden state sequence. We'll also copy some samples so that
we can plot them. 
 python
models = []
for idx in progprint_xrange(150):
    posteriormodel.resample_model()
    if (idx+1) % 10 == 0:
        models.append(copy.deepcopy(posteriormodel)) 
 Now we can plot our saved samples: 
 python
fig = plt.figure()
for idx, model in enumerate(models):
    plt.clf()
    model.plot()
    plt.gcf().suptitle('HDP-HSMM sampled after %d iterations' % (10*(idx+1)))
    plt.savefig('iter_%.3d.png' % (10*(idx+1))) 
 
 I generated these data from an HSMM that looked like this: 
 
 So the posterior samples look pretty good! 
 Speed 
 HSMMs constitute a much more powerful model class than plain-old HMMs, and that
enhanced power comes with a computational price: each sampling iteration for an
HSMM is much slower than that of an HMM. But that price is often worthwhile if
you want to place priors on state durations or have the model learn duration
structure present in the data. (In the example, strong duration structure is
what made the inference algorithm latch onto the correct explanation so
easily.) In addition, the increased cost of each iteration often pays for
itself, since HSMM samplers empirically seem to take fewer iterations to
converge than comparable HMM samplers. 
 Using my nothing-special i7-920 desktop machine and a NumPy/SciPy built against
Intel's MKL BLAS (which generally outperforms ATLAS for vectorized operations)
along with the Eigen-backed classes, here's how long the demo iterations took: 
 $ python examples/hsmm.py
.........................  [  25/100,    0.05sec avg,    3.95sec ETA ]
.........................  [  50/100,    0.05sec avg,    2.64sec ETA ]
.........................  [  75/100,    0.05sec avg,    1.34sec ETA ]
.........................  [ 100/100,    0.05sec avg,    0.05sec ETA ]
   0.05sec avg,    5.21sec total 
 Extending the Code 
 To add your own observation or duration distributions, implement the interfaces
defined in  basic/abstractions.py . Also see the plugins. To get a flavor of
the style, see  pybasicbayes . 
 Contributors 
 Contributions by Chia-ying Lee. 
 References 
 
 
 Matthew J. Johnson and Alan S. Willsky.  Bayesian Nonparametric Hidden
  Semi-Markov Models .
  Journal of Machine Learning Research (JMLR), 14:673â€“701, February 2013. 
 
 
 Matthew J. Johnson and Alan S. Willsky,  The Hierarchical Dirichlet Process
  Hidden Semi-Markov Model . 26th
  Conference on Uncertainty in Artificial Intelligence (UAI 2010), Avalon,
  California, July 2010. 
 
 
 bibtex
@article{johnson2013hdphsmm,
    title={Bayesian Nonparametric Hidden Semi-Markov Models},
    author={Johnson, Matthew J. and Willsky, Alan S.},
    journal={Journal of Machine Learning Research},
    pages={673--701},
    volume={14},
    month={February},
    year={2013},
}An analgesic for high-performance audio on iOS and OSX. 
 Really fast audio in iOS and Mac OS X using Audio Units is hard, and will leave you scarred and bloody. What used to take days can now be done with just a few lines of code. 
 Getting Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setInputBlock:^(float *newAudio, UInt32 numSamples, UInt32 numChannels) {
    // Now you're getting audio from the microphone every 20 milliseconds or so. How's that for easy?
    // Audio comes in interleaved, so,
    // if numChannels = 2, newAudio[0] is channel 1, newAudio[1] is channel 2, newAudio[2] is channel 1, etc.
}];
[audioManager play]; 
 Playing Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setOutputBlock:^(float *audioToPlay, UInt32 numSamples, UInt32 numChannels) {
    // All you have to do is put your audio into ""audioToPlay"".
}];
[audioManager play]; 
 Does anybody actually use it? 
 Yep. Novocaine is result of three years of work on the audio engine of  Octave ,  Fourier  and  oScope , a powerful suite of audio analysis apps. Please do check them out! 
 A thing to note: 
 The RingBuffer class is written in C++ to make things extra zippy, so the classes that use it will have to be Objective-C++. Change all the files that use RingBuffer from MyClass.m to MyClass.mm. 
 Want some examples? 
 Inside of ViewController.mm are a bunch of tiny little examples I wrote. Uncomment one and see how it sounds. 
Do note, however, for examples involving play-through, that you should be using headphones. Having the 
mic and speaker close to each other will produce some gnarly feedback.   
 Want to learn the nitty-gritty of Core Audio? 
 If you want to get down and dirty, if you want to get brave and get close to the hardware, I can only point you to the places where I learned how to do this stuff. Chris Adamson and Michael Tyson are two giants in the field of iOS audio, and they each wrote indispensable blog posts ( this is Chris's ,  this is Michael's ). Also, Chris Adamson now has a  whole gosh-darned BOOK on Core Audio . I would have done unspeakable things to get my hands on this when I was first starting. 
My Code for the Netflix Prize 
 I'm not aware of folks having published their code for the Netflix Prize. Here's mine. 
Under the team name ""Hi!"", I competed alone in college. I did it mostly for fun, and to learn modern machine learning techniques. It was an incredibly valuable, but strenuous, time. Well worth it on all fronts, though.  
I peaked out at #45 or so, and then dropped out to work on my senior thesis, and came in #145 or so.   
What I learned in the process was that smarter wasn't always better -- make an algorithm, and then scale it up, and then make a dozen tweaks to it, and then average all of the results together. That's how you climbed the leaderboard.    
 Anyhoo, I haven't touched this code in awhile, but perhaps it'll be useful to folks interested in competitive data mining. 
Specifically, the lessons I learned: 
 
 Get the raw data into a saved and manageable format  fast . The easier it is to load your data in and start mutating it, the better. 
 If doing simple pivots on your data is hard, and slows you down from visualizing whats in your data, spend time making data structures which make that easy.   
 Generalize. Iterate. If you have a method you think will work, but it has a lot of knobs, and you don't know the best way to set those knobs, make it easy for you to try  every possible iteration . There is often not a good way to figure out what the  best  approach is. You will have to try many of them in order to build up an intuition. Specifically, that means (for me) a pluggable architecture. If there's ten ways to try a particular step, make sure you write your overarching algorithm so that it takes a function that you can pass to it, as opposed to having a method hardwired in the code. That way, you can hotswap all your ideas.   
 Speed is a feature. Of course you make sure it works first. But your goal is to see if something works. If an algorithm takes a day to run, but you can spend five hours making it run in 1/3 of a day, do it. You'll be running it over and over again, and you'll learn more if you can iterate.  
 
 As for the technical nitty-gritty, everything that's speed sensitive is written in Cython, which was the best balance of speed and convenience in 2009. If I were to do it al again, I would use (Numba)[http://github.com/numba/numba].   
 The original data is gone, I believe, but I might have it stored somewhere. I'll look for that.  NURBS - Non Uniform Rational B-Splines. 
 This python module is a revival and update of Runar Tenfjord's NURBS toolbox, which itself
is a port of Mark Spink's SCILAB/MATLAB tolbox to python with help of numpy. 
 Dependency 
 Python 2.0 or above 
NumPy 
Dislin -> optional but recomended 
PyOpenGL -> optional   
 Installation 
 Just run   python setup.py install   
 License 
 Runar Tenfjord originally relased this package under the GPL Version 2 license,  
so I suppose that means it has to stay that way.    
 Originally by: Runar Tenfjord, runten@netcom.no 
Minor updates to work with NumPy by Alex Wiltschko  cuda-tests 
 Gotta learn some CUDA stuffpypatent 
 Scrape patents from the USPTOairruler 
 A ruler. Made of air. paralleltools 
 A summary of parallelizing moderate amounts of work in Pythonnsgt 
 Non-stationary Gabor transforms (GitHub mirror of http://grrrr.org/research/software/nsgt/)IDA 
 This code accompanies the publication from the Whitesides lab to Lab on a Chip, concerning automated analysis of red blood cell health using affordable field tests. Specifically, this code implements the automated extraction of scanned AMPS tubes from flatbed scanner images, the distillation of those images into 1D data traces, and then the automated identification of the anemic disease state of the blood in those 1D data traces, as well as the prediction of continuously-varying red blood cell (RBC) parameters. 
 Installation 
 This code requires Python, as well as some extra 3rd-party libraries. All routines have only been tested on Mac OS, but should work on Linux. No guarantees for Windows.
1) First, we recommend using the ""Anaconda"" Python distribution, specifically the Python 2.7 version.  Download and install here .
1) With anaconda installed, you will need one extra library, to read TIFF files.
 pip install imageio 
1) You should be able to run the notebooks now. Inside this code repository, start up an IPython notebook:
 jupyter notebook 
1) You should now be able to browser around the ""extraction"" and ""analysis"" folders, which contain the relevant code. 
 Running extraction 
 The first step required will be to prepare the raw data of TIFF file scans of 4x3=12 tubes from a flatbed scanner. We will also have to associate metadata for each patient that the blood in a tube was drawn from.
Our end goal will be a 1D array for each tube, along with the corresponding patient data (anemic state & RBC parameters). 
 The extraction algorithm is explained step-by-step in the notebook  extraction/Explaining the Extraction Algorithm.ipynb .
The implementation we use in the paper (which also fuses patient metadata with AMPS image data) can be found in  extraction/Data Extraction Pipeline.ipynb . Most of the code in this notebook is specific to the particular Excel file format that we used to record patient metadata, and may have to be largely rewritten for reuse. 
 Running analysis 
 There are two sets of analyses done in the paper: classification and regression. 
 Running classification analysis 
 The goal of this analysis is to predict disease state only from the 1D data trace extracted from each AMPS tube. We use logistic regression, a linear classifier, and transform the 1D data representation using PCA to remove redundancy and constrain the input dimensionality of the problem. We also used Bayesian Optimization (bayesopt) to tune the hyperparameters of the problem, including the specific output dimension of PCA, the regularization parameter of logistic regression, and some image preprocessing parameters. Unfortunately, the service we used for bayesopt is no longer available. If you would like to automatically tune these parameters, we recommend either using random search (a surprisingly effective hueristic), or the open source library ""Spearmint"", upon which the now-defunct service we used was based, or products from the company SigOpt, which also implements bayesopt. The file we used to automatically tune these hypers is  classify.py .
The best set of hyperparameters is stored in the notebook  Analyzing best classification.ipynb .
This notebook examines ROC performance of the classifier for discriminating different anemia types, as well as the effect of centrifugation time of the tube on IDA classification AUC performance. 
 Running regression analysis. 
 Similar to above, we used a defunct bayesopt service to automatically tune some parameters of this algorithm. The original file is in  regress.py . The original methodology will work well, even without automated tuning.
The best set of hyperparameters is stored in the notebook  Analyzing best regression.ipynb . 
 License 
 See the LICENSE file. It is under a GPL license, and this code may only be used for academic purposes.adabayes 
 To do: 
 
 [x] Find candidate last layer features (DeCAF, Overfeat) 
 [x] Find AlexNet code (5 convolutional layers with max-pooling, then three fully connected layers) 
 [X]  Find download script for MNIST dataset 
 [X]  Find download script for CIFAR10 dataset 
 [x] Fork torch-dist repo 
 [x] Update torch-dist repo for OS X 10.10 install 
 [x] Add new required submodules to distro (nnx, iTorch, ccn2, cunnx, cudnn, sdl2, cutorch) 
 [x] Figure out model serialization and loading 
 Built-in model serialization.  Loading  and  saving . 
 There is also facebook's  Thrift library , which I haven't seen many examples for. 
 
 
 [ ] Get the data out of the  DataSource  models that we're using 
 [ ] Train and Whetlab a net on MNIST (to get the whole workflow going) 
 [ ] Train and Whetlab a net on CIFAR10 
 [ ] Train and Whetlab a net on STL10 
 [ ] Build dumb ensemble on CIFAR10 
 [ ] Build dumb ensemble on STL10 
 [ ] Grok boosting criterion 
 [ ] Whetlab a net with progressive ensembling on CIFAR10 
 [ ] Whetlab a net with progressive ensembling on STL10 
 [ ] Whetlab a net with progressive ensembling on the last-layer features of ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on CIFAR10 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on STL10 
 [ ] Extract last-layer ImageNet features 
 [ ] Host last-layer ImageNet features 
 [ ] Build download script for last-layer ImageNet features 
 [ ] Train and Whetlab a net on last-layer features on ImageNet 
 [ ] Build a dumb ensemble on ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on the last-layer features of ImageNet 
 
 Collecting some resources 
 AlexNet:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/alexnet.lua 
 I think this is NiN:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/googlenet.lua 
 OverFeat:
https://github.com/facebook/fbcunn/blob/master/examples/imagenet/models/overfeat_cunn.lua 
 Multiclass criterion:
https://github.com/torch/nn/blob/master/doc/criterion.md#classnllcriterion 
 Some other interesting nets:
https://github.com/culurciello/profiling 
 Bunch of demos, not all nets:
https://github.com/torch/demos 
 Overfeat features:
http://cilvr.nyu.edu/doku.php?id=software:overfeat:start 
 Decaf ImageNet submission:
https://github.com/UCB-ICSI-Vision-Group/decaf-release/wiki/imagenet 
 Some other net implementations:
https://github.com/eladhoffer/ImageNet-TrainingConda recipes for installing packages from the Torch ecosystem. 
 NOTE: No longer maintained. 
 To install packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 conda install lua=5.2 lua-science -c alexbw 
 Available versions of Lua: 2.0, 5.1, 5.2, 5.3 
 2.0 is LuaJIT 
 ``` 
 To build packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Get the newest version of conda, as well as some conda build tools 
 conda update conda -y
conda install conda-build anaconda-client -y 
 Build all packages 
 sh build_all.sh 
 Ideally, all you have to do to install everything is this 
 conda install lua=5.2 lua-science
``` 
 TODO:
 - https://github.com/AlexMili/torch-dataframe
 - https://github.com/twitter/torch-ipc
 - https://github.com/twitter/torch-distlearn
 - https://github.com/twitter/torch-dataset 
 Resources: 
 
 
 Making packages relocatable (LuaJIT hard-codes path) 
 
 
 Build instructions for luarocks 
 
 
 Build instructions for Lua 
 
 
 Patching files with git diffs is finicky 
 
 
 Linking against readline  (need a few extra flags, and link against -lncursesw, not -lncurses) 
 
 
 Upgrading old Debian .  Also this . 
 
 
 Misc notes:
 metadata:ns_cfg() â€” defines for YAML directives
main_build: â€”Â defines version numbers 
environ:get_lua_include_dir() â€”Â uses version numbers to locate the include directory
config:Config._get_lua â€”Â uses version numbers to locate the binary
This is where the linked package name is converted into what is usedvalidata 
 Continuous integration for your data 
 We do continuous integration on code. Why not data?
Validata is a small package to run basic sanity checks on your data.
I haven't found anything that aggregates all of these checks and tricks in one place. 
 There is only one method which is exposed,  check(data,labels)  (optionally taking data or labels).
If any data check fails, it throws a well-named error, as well as hints for how you might fix the problem -- data covariance matrix ill-conditioned? Try whitening. 
 Initially, this will be a Python/NumPy only package running basic checks, but hopefully it becomes a resource of data sanity and sanitation checks.
Still very much a work in progress. 
 Examples (some implemented, some not) include: 
 
 If your labels are one-hot, are you using all slots? 
 Is the covariance matrix of your data ill-conditioned? 
 Do you have any constant variables? 
 Can you train a classifier to distinguish train and test data, using whether they are in train or test as a label? Indicates different data distributions. 
 If you're using integer labels, are the unique labels contiguous? 
 Do you have just one unique label? 
 Is the data under different labels statistically separable? 
 If you have an old dataset and a new dataset (or two halves of the same dataset), is the distribution of each dimension stationary? Check for divergence with a KS test. 
 What else? I end up applying these tricks in a very ad hoc fashion, whenever a subtle bug pops up, and not rigorously before each project I tackle. I'd like to stuff all these tricks in one place, and run them like a unit test, or a continuous integration test, on data that I start working with. 
 
 Should probably also think about engardebayarea-dl-summerschool 
 Torch notebooks and slides for the Bay Area Deep Learning Summer School 
 Installation Instructions 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 ```
conda install lua=5.2 lua-science -c alexbw 
 Although, you could install other Lua versions like 2.0 (LuaJIT), 5.1, 5.2 and 5.3 
 ``` 
 Clone this repository and start the notebook server 
 ```
git clone https://github.com/alexbw/bayarea-dl-summerschool.git
cd bayarea-dl-summerschool
itorch notebook 
 Will open a browser tab, then you can navigate to the notebooks 
 ```","Boston, MA",False,Google,7,DevOps,95,0.31,0.38,0.29,0,False,https://avatars.githubusercontent.com/u/161935?u=f722a589176ab3dce6285bcce174117e3c103ec3&v=4,2009-12-04T14:50:40Z,2022-08-23T18:31:52Z,,False,False,False,False,False,True,False,0,396,332,0,47,2016-08-15 18:39:55,4
Objective-C,alexbw,Alex Wiltschko,,alex.bw@gmail.com,"Sampling Inference for Bayesian HSMMs and HMMs 
 This is a Python library for approximate unsupervised sampling inference in
Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov
Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM
and HDP-HSMM, via the weak-limit approximation. 
 There are also some plugins to extend the functionality: 
 
 factorial models 
 autoregressive models 
 collapsed HDP sampling inference . 
 
 The inference can be run in parallel over multiple cores and/or multiple
machines (even on EC2!) using  ipython 's
excellent  ipython.parallel  module. Someday I might even document how to do
it! 
 Installing 
 You can clone this library and its dependencies with 
 git clone --recursive git://github.com/mattjj/pyhsmm.git 
 The library depends on  numpy ,  scipy , and, for visualization,  matplotlib . 
 Disabling assertions may speed things up; to disable assertions, run your
CPython interpreter with the  -O  flag. 
 A Simple Demonstration 
 Here's how to draw from the HDP-HSMM posterior over HSMMs given a sequence of
observations. (The same example, along with the code to generate the synthetic
data loaded in this example, can be found in  examples/basic.py .) 
 Let's say we have some 2D data in a data.txt file: 
 bash
 head -5 data.txt
-3.711962552600095444e-02 1.456401745267922598e-01
7.553818775915704942e-02 2.457422192223903679e-01
-2.465977987699214502e+00 5.537627981813508793e-01
-7.031638516485749779e-01 1.536468304146855757e-01
-9.224669847039665971e-01 3.680035337673161489e-01 
 In Python, we can plot the data in a 2D plot, collapsing out the time dimension: 
 ```python
import numpy as np
from matplotlib import pyplot as plt 
 data = np.loadtxt('data.txt')
plt.plot(data[:,0],data[:,1],'kx')
``` 
 
 We can also make a plot of time versus the first principal component: 
 python
from pyhsmm.util.plot import pca_project_data
plt.plot(pca_project_data(data,1)) 
 
 To learn an HSMM, we'll use  pyhsmm  to create an  HSMM  instance using some
reasonable hyperparameters. We'll ask this model to infer the number of states
as well (since an HDP-HSMM is instantiated by default), so we'll give it an
 Nmax  parameter: 
 ```python
import pyhsmm
import pyhsmm.basic.distributions as distributions 
 obs_dim = 2
Nmax = 25 
 obs_hypparams = {'mu_0':np.zeros(obs_dim),
                'sigma_0':np.eye(obs_dim),
                'kappa_0':0.3,
                'nu_0':obs_dim+5}
dur_hypparams = {'alpha_0':2*30,
                 'beta_0':2} 
 obs_distns = [distributions.Gaussian( obs_hypparams) for state in range(Nmax)]
dur_distns = [distributions.PoissonDuration( dur_hypparams) for state in range(Nmax)] 
 posteriormodel = pyhsmm.models.HSMM(
        alpha=6.,gamma=6., # better to sample over these; see concentration-resampling.py
        init_state_concentration=6., # pretty inconsequential
        obs_distns=obs_distns,
        dur_distns=dur_distns,
        trunc=60) # duration truncation speeds things up when it's possible
``` 
 (The first two arguments set the ""new-table"" proportionality constant for the
meta-Chinese Restaurant Process and the other CRPs, respectively, in the HDP
prior on transition matrices. For this example, they really don't matter at
all, but on real data it's much better to infer these parameters, as in
 examples/concentration_resampling.py .) 
 The  trunc  parameter is an optional argument that can speed up inference: it
sets a truncation limit on the maximum duration for any state. If you don't
pass in the  trunc  argument, no truncation is used and all possible state
duration lengths are considered. 
 Then, we add the data we want to condition on: 
 python
posteriormodel.add_data(data) 
 (If we had multiple observation sequences to learn from, we could add them to the
model just by calling  add_data()  for each observation sequence.) 
 Now we run a resampling loop. For each iteration of the loop, all the latent
variables of the model will be resampled by Gibbs sampling steps, including the
transition matrix, the observation means and covariances, the duration
parameters, and the hidden state sequence. We'll also copy some samples so that
we can plot them. 
 python
models = []
for idx in progprint_xrange(150):
    posteriormodel.resample_model()
    if (idx+1) % 10 == 0:
        models.append(copy.deepcopy(posteriormodel)) 
 Now we can plot our saved samples: 
 python
fig = plt.figure()
for idx, model in enumerate(models):
    plt.clf()
    model.plot()
    plt.gcf().suptitle('HDP-HSMM sampled after %d iterations' % (10*(idx+1)))
    plt.savefig('iter_%.3d.png' % (10*(idx+1))) 
 
 I generated these data from an HSMM that looked like this: 
 
 So the posterior samples look pretty good! 
 Speed 
 HSMMs constitute a much more powerful model class than plain-old HMMs, and that
enhanced power comes with a computational price: each sampling iteration for an
HSMM is much slower than that of an HMM. But that price is often worthwhile if
you want to place priors on state durations or have the model learn duration
structure present in the data. (In the example, strong duration structure is
what made the inference algorithm latch onto the correct explanation so
easily.) In addition, the increased cost of each iteration often pays for
itself, since HSMM samplers empirically seem to take fewer iterations to
converge than comparable HMM samplers. 
 Using my nothing-special i7-920 desktop machine and a NumPy/SciPy built against
Intel's MKL BLAS (which generally outperforms ATLAS for vectorized operations)
along with the Eigen-backed classes, here's how long the demo iterations took: 
 $ python examples/hsmm.py
.........................  [  25/100,    0.05sec avg,    3.95sec ETA ]
.........................  [  50/100,    0.05sec avg,    2.64sec ETA ]
.........................  [  75/100,    0.05sec avg,    1.34sec ETA ]
.........................  [ 100/100,    0.05sec avg,    0.05sec ETA ]
   0.05sec avg,    5.21sec total 
 Extending the Code 
 To add your own observation or duration distributions, implement the interfaces
defined in  basic/abstractions.py . Also see the plugins. To get a flavor of
the style, see  pybasicbayes . 
 Contributors 
 Contributions by Chia-ying Lee. 
 References 
 
 
 Matthew J. Johnson and Alan S. Willsky.  Bayesian Nonparametric Hidden
  Semi-Markov Models .
  Journal of Machine Learning Research (JMLR), 14:673â€“701, February 2013. 
 
 
 Matthew J. Johnson and Alan S. Willsky,  The Hierarchical Dirichlet Process
  Hidden Semi-Markov Model . 26th
  Conference on Uncertainty in Artificial Intelligence (UAI 2010), Avalon,
  California, July 2010. 
 
 
 bibtex
@article{johnson2013hdphsmm,
    title={Bayesian Nonparametric Hidden Semi-Markov Models},
    author={Johnson, Matthew J. and Willsky, Alan S.},
    journal={Journal of Machine Learning Research},
    pages={673--701},
    volume={14},
    month={February},
    year={2013},
}An analgesic for high-performance audio on iOS and OSX. 
 Really fast audio in iOS and Mac OS X using Audio Units is hard, and will leave you scarred and bloody. What used to take days can now be done with just a few lines of code. 
 Getting Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setInputBlock:^(float *newAudio, UInt32 numSamples, UInt32 numChannels) {
    // Now you're getting audio from the microphone every 20 milliseconds or so. How's that for easy?
    // Audio comes in interleaved, so,
    // if numChannels = 2, newAudio[0] is channel 1, newAudio[1] is channel 2, newAudio[2] is channel 1, etc.
}];
[audioManager play]; 
 Playing Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setOutputBlock:^(float *audioToPlay, UInt32 numSamples, UInt32 numChannels) {
    // All you have to do is put your audio into ""audioToPlay"".
}];
[audioManager play]; 
 Does anybody actually use it? 
 Yep. Novocaine is result of three years of work on the audio engine of  Octave ,  Fourier  and  oScope , a powerful suite of audio analysis apps. Please do check them out! 
 A thing to note: 
 The RingBuffer class is written in C++ to make things extra zippy, so the classes that use it will have to be Objective-C++. Change all the files that use RingBuffer from MyClass.m to MyClass.mm. 
 Want some examples? 
 Inside of ViewController.mm are a bunch of tiny little examples I wrote. Uncomment one and see how it sounds. 
Do note, however, for examples involving play-through, that you should be using headphones. Having the 
mic and speaker close to each other will produce some gnarly feedback.   
 Want to learn the nitty-gritty of Core Audio? 
 If you want to get down and dirty, if you want to get brave and get close to the hardware, I can only point you to the places where I learned how to do this stuff. Chris Adamson and Michael Tyson are two giants in the field of iOS audio, and they each wrote indispensable blog posts ( this is Chris's ,  this is Michael's ). Also, Chris Adamson now has a  whole gosh-darned BOOK on Core Audio . I would have done unspeakable things to get my hands on this when I was first starting. 
My Code for the Netflix Prize 
 I'm not aware of folks having published their code for the Netflix Prize. Here's mine. 
Under the team name ""Hi!"", I competed alone in college. I did it mostly for fun, and to learn modern machine learning techniques. It was an incredibly valuable, but strenuous, time. Well worth it on all fronts, though.  
I peaked out at #45 or so, and then dropped out to work on my senior thesis, and came in #145 or so.   
What I learned in the process was that smarter wasn't always better -- make an algorithm, and then scale it up, and then make a dozen tweaks to it, and then average all of the results together. That's how you climbed the leaderboard.    
 Anyhoo, I haven't touched this code in awhile, but perhaps it'll be useful to folks interested in competitive data mining. 
Specifically, the lessons I learned: 
 
 Get the raw data into a saved and manageable format  fast . The easier it is to load your data in and start mutating it, the better. 
 If doing simple pivots on your data is hard, and slows you down from visualizing whats in your data, spend time making data structures which make that easy.   
 Generalize. Iterate. If you have a method you think will work, but it has a lot of knobs, and you don't know the best way to set those knobs, make it easy for you to try  every possible iteration . There is often not a good way to figure out what the  best  approach is. You will have to try many of them in order to build up an intuition. Specifically, that means (for me) a pluggable architecture. If there's ten ways to try a particular step, make sure you write your overarching algorithm so that it takes a function that you can pass to it, as opposed to having a method hardwired in the code. That way, you can hotswap all your ideas.   
 Speed is a feature. Of course you make sure it works first. But your goal is to see if something works. If an algorithm takes a day to run, but you can spend five hours making it run in 1/3 of a day, do it. You'll be running it over and over again, and you'll learn more if you can iterate.  
 
 As for the technical nitty-gritty, everything that's speed sensitive is written in Cython, which was the best balance of speed and convenience in 2009. If I were to do it al again, I would use (Numba)[http://github.com/numba/numba].   
 The original data is gone, I believe, but I might have it stored somewhere. I'll look for that.  NURBS - Non Uniform Rational B-Splines. 
 This python module is a revival and update of Runar Tenfjord's NURBS toolbox, which itself
is a port of Mark Spink's SCILAB/MATLAB tolbox to python with help of numpy. 
 Dependency 
 Python 2.0 or above 
NumPy 
Dislin -> optional but recomended 
PyOpenGL -> optional   
 Installation 
 Just run   python setup.py install   
 License 
 Runar Tenfjord originally relased this package under the GPL Version 2 license,  
so I suppose that means it has to stay that way.    
 Originally by: Runar Tenfjord, runten@netcom.no 
Minor updates to work with NumPy by Alex Wiltschko  cuda-tests 
 Gotta learn some CUDA stuffpypatent 
 Scrape patents from the USPTOairruler 
 A ruler. Made of air. paralleltools 
 A summary of parallelizing moderate amounts of work in Pythonnsgt 
 Non-stationary Gabor transforms (GitHub mirror of http://grrrr.org/research/software/nsgt/)IDA 
 This code accompanies the publication from the Whitesides lab to Lab on a Chip, concerning automated analysis of red blood cell health using affordable field tests. Specifically, this code implements the automated extraction of scanned AMPS tubes from flatbed scanner images, the distillation of those images into 1D data traces, and then the automated identification of the anemic disease state of the blood in those 1D data traces, as well as the prediction of continuously-varying red blood cell (RBC) parameters. 
 Installation 
 This code requires Python, as well as some extra 3rd-party libraries. All routines have only been tested on Mac OS, but should work on Linux. No guarantees for Windows.
1) First, we recommend using the ""Anaconda"" Python distribution, specifically the Python 2.7 version.  Download and install here .
1) With anaconda installed, you will need one extra library, to read TIFF files.
 pip install imageio 
1) You should be able to run the notebooks now. Inside this code repository, start up an IPython notebook:
 jupyter notebook 
1) You should now be able to browser around the ""extraction"" and ""analysis"" folders, which contain the relevant code. 
 Running extraction 
 The first step required will be to prepare the raw data of TIFF file scans of 4x3=12 tubes from a flatbed scanner. We will also have to associate metadata for each patient that the blood in a tube was drawn from.
Our end goal will be a 1D array for each tube, along with the corresponding patient data (anemic state & RBC parameters). 
 The extraction algorithm is explained step-by-step in the notebook  extraction/Explaining the Extraction Algorithm.ipynb .
The implementation we use in the paper (which also fuses patient metadata with AMPS image data) can be found in  extraction/Data Extraction Pipeline.ipynb . Most of the code in this notebook is specific to the particular Excel file format that we used to record patient metadata, and may have to be largely rewritten for reuse. 
 Running analysis 
 There are two sets of analyses done in the paper: classification and regression. 
 Running classification analysis 
 The goal of this analysis is to predict disease state only from the 1D data trace extracted from each AMPS tube. We use logistic regression, a linear classifier, and transform the 1D data representation using PCA to remove redundancy and constrain the input dimensionality of the problem. We also used Bayesian Optimization (bayesopt) to tune the hyperparameters of the problem, including the specific output dimension of PCA, the regularization parameter of logistic regression, and some image preprocessing parameters. Unfortunately, the service we used for bayesopt is no longer available. If you would like to automatically tune these parameters, we recommend either using random search (a surprisingly effective hueristic), or the open source library ""Spearmint"", upon which the now-defunct service we used was based, or products from the company SigOpt, which also implements bayesopt. The file we used to automatically tune these hypers is  classify.py .
The best set of hyperparameters is stored in the notebook  Analyzing best classification.ipynb .
This notebook examines ROC performance of the classifier for discriminating different anemia types, as well as the effect of centrifugation time of the tube on IDA classification AUC performance. 
 Running regression analysis. 
 Similar to above, we used a defunct bayesopt service to automatically tune some parameters of this algorithm. The original file is in  regress.py . The original methodology will work well, even without automated tuning.
The best set of hyperparameters is stored in the notebook  Analyzing best regression.ipynb . 
 License 
 See the LICENSE file. It is under a GPL license, and this code may only be used for academic purposes.adabayes 
 To do: 
 
 [x] Find candidate last layer features (DeCAF, Overfeat) 
 [x] Find AlexNet code (5 convolutional layers with max-pooling, then three fully connected layers) 
 [X]  Find download script for MNIST dataset 
 [X]  Find download script for CIFAR10 dataset 
 [x] Fork torch-dist repo 
 [x] Update torch-dist repo for OS X 10.10 install 
 [x] Add new required submodules to distro (nnx, iTorch, ccn2, cunnx, cudnn, sdl2, cutorch) 
 [x] Figure out model serialization and loading 
 Built-in model serialization.  Loading  and  saving . 
 There is also facebook's  Thrift library , which I haven't seen many examples for. 
 
 
 [ ] Get the data out of the  DataSource  models that we're using 
 [ ] Train and Whetlab a net on MNIST (to get the whole workflow going) 
 [ ] Train and Whetlab a net on CIFAR10 
 [ ] Train and Whetlab a net on STL10 
 [ ] Build dumb ensemble on CIFAR10 
 [ ] Build dumb ensemble on STL10 
 [ ] Grok boosting criterion 
 [ ] Whetlab a net with progressive ensembling on CIFAR10 
 [ ] Whetlab a net with progressive ensembling on STL10 
 [ ] Whetlab a net with progressive ensembling on the last-layer features of ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on CIFAR10 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on STL10 
 [ ] Extract last-layer ImageNet features 
 [ ] Host last-layer ImageNet features 
 [ ] Build download script for last-layer ImageNet features 
 [ ] Train and Whetlab a net on last-layer features on ImageNet 
 [ ] Build a dumb ensemble on ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on the last-layer features of ImageNet 
 
 Collecting some resources 
 AlexNet:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/alexnet.lua 
 I think this is NiN:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/googlenet.lua 
 OverFeat:
https://github.com/facebook/fbcunn/blob/master/examples/imagenet/models/overfeat_cunn.lua 
 Multiclass criterion:
https://github.com/torch/nn/blob/master/doc/criterion.md#classnllcriterion 
 Some other interesting nets:
https://github.com/culurciello/profiling 
 Bunch of demos, not all nets:
https://github.com/torch/demos 
 Overfeat features:
http://cilvr.nyu.edu/doku.php?id=software:overfeat:start 
 Decaf ImageNet submission:
https://github.com/UCB-ICSI-Vision-Group/decaf-release/wiki/imagenet 
 Some other net implementations:
https://github.com/eladhoffer/ImageNet-TrainingConda recipes for installing packages from the Torch ecosystem. 
 NOTE: No longer maintained. 
 To install packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 conda install lua=5.2 lua-science -c alexbw 
 Available versions of Lua: 2.0, 5.1, 5.2, 5.3 
 2.0 is LuaJIT 
 ``` 
 To build packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Get the newest version of conda, as well as some conda build tools 
 conda update conda -y
conda install conda-build anaconda-client -y 
 Build all packages 
 sh build_all.sh 
 Ideally, all you have to do to install everything is this 
 conda install lua=5.2 lua-science
``` 
 TODO:
 - https://github.com/AlexMili/torch-dataframe
 - https://github.com/twitter/torch-ipc
 - https://github.com/twitter/torch-distlearn
 - https://github.com/twitter/torch-dataset 
 Resources: 
 
 
 Making packages relocatable (LuaJIT hard-codes path) 
 
 
 Build instructions for luarocks 
 
 
 Build instructions for Lua 
 
 
 Patching files with git diffs is finicky 
 
 
 Linking against readline  (need a few extra flags, and link against -lncursesw, not -lncurses) 
 
 
 Upgrading old Debian .  Also this . 
 
 
 Misc notes:
 metadata:ns_cfg() â€” defines for YAML directives
main_build: â€”Â defines version numbers 
environ:get_lua_include_dir() â€”Â uses version numbers to locate the include directory
config:Config._get_lua â€”Â uses version numbers to locate the binary
This is where the linked package name is converted into what is usedvalidata 
 Continuous integration for your data 
 We do continuous integration on code. Why not data?
Validata is a small package to run basic sanity checks on your data.
I haven't found anything that aggregates all of these checks and tricks in one place. 
 There is only one method which is exposed,  check(data,labels)  (optionally taking data or labels).
If any data check fails, it throws a well-named error, as well as hints for how you might fix the problem -- data covariance matrix ill-conditioned? Try whitening. 
 Initially, this will be a Python/NumPy only package running basic checks, but hopefully it becomes a resource of data sanity and sanitation checks.
Still very much a work in progress. 
 Examples (some implemented, some not) include: 
 
 If your labels are one-hot, are you using all slots? 
 Is the covariance matrix of your data ill-conditioned? 
 Do you have any constant variables? 
 Can you train a classifier to distinguish train and test data, using whether they are in train or test as a label? Indicates different data distributions. 
 If you're using integer labels, are the unique labels contiguous? 
 Do you have just one unique label? 
 Is the data under different labels statistically separable? 
 If you have an old dataset and a new dataset (or two halves of the same dataset), is the distribution of each dimension stationary? Check for divergence with a KS test. 
 What else? I end up applying these tricks in a very ad hoc fashion, whenever a subtle bug pops up, and not rigorously before each project I tackle. I'd like to stuff all these tricks in one place, and run them like a unit test, or a continuous integration test, on data that I start working with. 
 
 Should probably also think about engardebayarea-dl-summerschool 
 Torch notebooks and slides for the Bay Area Deep Learning Summer School 
 Installation Instructions 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 ```
conda install lua=5.2 lua-science -c alexbw 
 Although, you could install other Lua versions like 2.0 (LuaJIT), 5.1, 5.2 and 5.3 
 ``` 
 Clone this repository and start the notebook server 
 ```
git clone https://github.com/alexbw/bayarea-dl-summerschool.git
cd bayarea-dl-summerschool
itorch notebook 
 Will open a browser tab, then you can navigate to the notebooks 
 ```","Boston, MA",False,Google,7,DevOps,95,0.31,0.38,0.29,0,False,https://avatars.githubusercontent.com/u/161935?u=f722a589176ab3dce6285bcce174117e3c103ec3&v=4,2009-12-04T14:50:40Z,2022-08-23T18:31:52Z,,False,False,False,False,False,True,False,0,396,332,0,47,2016-08-15 18:39:55,5
Python,alexbw,Alex Wiltschko,,alex.bw@gmail.com,"Sampling Inference for Bayesian HSMMs and HMMs 
 This is a Python library for approximate unsupervised sampling inference in
Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov
Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM
and HDP-HSMM, via the weak-limit approximation. 
 There are also some plugins to extend the functionality: 
 
 factorial models 
 autoregressive models 
 collapsed HDP sampling inference . 
 
 The inference can be run in parallel over multiple cores and/or multiple
machines (even on EC2!) using  ipython 's
excellent  ipython.parallel  module. Someday I might even document how to do
it! 
 Installing 
 You can clone this library and its dependencies with 
 git clone --recursive git://github.com/mattjj/pyhsmm.git 
 The library depends on  numpy ,  scipy , and, for visualization,  matplotlib . 
 Disabling assertions may speed things up; to disable assertions, run your
CPython interpreter with the  -O  flag. 
 A Simple Demonstration 
 Here's how to draw from the HDP-HSMM posterior over HSMMs given a sequence of
observations. (The same example, along with the code to generate the synthetic
data loaded in this example, can be found in  examples/basic.py .) 
 Let's say we have some 2D data in a data.txt file: 
 bash
 head -5 data.txt
-3.711962552600095444e-02 1.456401745267922598e-01
7.553818775915704942e-02 2.457422192223903679e-01
-2.465977987699214502e+00 5.537627981813508793e-01
-7.031638516485749779e-01 1.536468304146855757e-01
-9.224669847039665971e-01 3.680035337673161489e-01 
 In Python, we can plot the data in a 2D plot, collapsing out the time dimension: 
 ```python
import numpy as np
from matplotlib import pyplot as plt 
 data = np.loadtxt('data.txt')
plt.plot(data[:,0],data[:,1],'kx')
``` 
 
 We can also make a plot of time versus the first principal component: 
 python
from pyhsmm.util.plot import pca_project_data
plt.plot(pca_project_data(data,1)) 
 
 To learn an HSMM, we'll use  pyhsmm  to create an  HSMM  instance using some
reasonable hyperparameters. We'll ask this model to infer the number of states
as well (since an HDP-HSMM is instantiated by default), so we'll give it an
 Nmax  parameter: 
 ```python
import pyhsmm
import pyhsmm.basic.distributions as distributions 
 obs_dim = 2
Nmax = 25 
 obs_hypparams = {'mu_0':np.zeros(obs_dim),
                'sigma_0':np.eye(obs_dim),
                'kappa_0':0.3,
                'nu_0':obs_dim+5}
dur_hypparams = {'alpha_0':2*30,
                 'beta_0':2} 
 obs_distns = [distributions.Gaussian( obs_hypparams) for state in range(Nmax)]
dur_distns = [distributions.PoissonDuration( dur_hypparams) for state in range(Nmax)] 
 posteriormodel = pyhsmm.models.HSMM(
        alpha=6.,gamma=6., # better to sample over these; see concentration-resampling.py
        init_state_concentration=6., # pretty inconsequential
        obs_distns=obs_distns,
        dur_distns=dur_distns,
        trunc=60) # duration truncation speeds things up when it's possible
``` 
 (The first two arguments set the ""new-table"" proportionality constant for the
meta-Chinese Restaurant Process and the other CRPs, respectively, in the HDP
prior on transition matrices. For this example, they really don't matter at
all, but on real data it's much better to infer these parameters, as in
 examples/concentration_resampling.py .) 
 The  trunc  parameter is an optional argument that can speed up inference: it
sets a truncation limit on the maximum duration for any state. If you don't
pass in the  trunc  argument, no truncation is used and all possible state
duration lengths are considered. 
 Then, we add the data we want to condition on: 
 python
posteriormodel.add_data(data) 
 (If we had multiple observation sequences to learn from, we could add them to the
model just by calling  add_data()  for each observation sequence.) 
 Now we run a resampling loop. For each iteration of the loop, all the latent
variables of the model will be resampled by Gibbs sampling steps, including the
transition matrix, the observation means and covariances, the duration
parameters, and the hidden state sequence. We'll also copy some samples so that
we can plot them. 
 python
models = []
for idx in progprint_xrange(150):
    posteriormodel.resample_model()
    if (idx+1) % 10 == 0:
        models.append(copy.deepcopy(posteriormodel)) 
 Now we can plot our saved samples: 
 python
fig = plt.figure()
for idx, model in enumerate(models):
    plt.clf()
    model.plot()
    plt.gcf().suptitle('HDP-HSMM sampled after %d iterations' % (10*(idx+1)))
    plt.savefig('iter_%.3d.png' % (10*(idx+1))) 
 
 I generated these data from an HSMM that looked like this: 
 
 So the posterior samples look pretty good! 
 Speed 
 HSMMs constitute a much more powerful model class than plain-old HMMs, and that
enhanced power comes with a computational price: each sampling iteration for an
HSMM is much slower than that of an HMM. But that price is often worthwhile if
you want to place priors on state durations or have the model learn duration
structure present in the data. (In the example, strong duration structure is
what made the inference algorithm latch onto the correct explanation so
easily.) In addition, the increased cost of each iteration often pays for
itself, since HSMM samplers empirically seem to take fewer iterations to
converge than comparable HMM samplers. 
 Using my nothing-special i7-920 desktop machine and a NumPy/SciPy built against
Intel's MKL BLAS (which generally outperforms ATLAS for vectorized operations)
along with the Eigen-backed classes, here's how long the demo iterations took: 
 $ python examples/hsmm.py
.........................  [  25/100,    0.05sec avg,    3.95sec ETA ]
.........................  [  50/100,    0.05sec avg,    2.64sec ETA ]
.........................  [  75/100,    0.05sec avg,    1.34sec ETA ]
.........................  [ 100/100,    0.05sec avg,    0.05sec ETA ]
   0.05sec avg,    5.21sec total 
 Extending the Code 
 To add your own observation or duration distributions, implement the interfaces
defined in  basic/abstractions.py . Also see the plugins. To get a flavor of
the style, see  pybasicbayes . 
 Contributors 
 Contributions by Chia-ying Lee. 
 References 
 
 
 Matthew J. Johnson and Alan S. Willsky.  Bayesian Nonparametric Hidden
  Semi-Markov Models .
  Journal of Machine Learning Research (JMLR), 14:673â€“701, February 2013. 
 
 
 Matthew J. Johnson and Alan S. Willsky,  The Hierarchical Dirichlet Process
  Hidden Semi-Markov Model . 26th
  Conference on Uncertainty in Artificial Intelligence (UAI 2010), Avalon,
  California, July 2010. 
 
 
 bibtex
@article{johnson2013hdphsmm,
    title={Bayesian Nonparametric Hidden Semi-Markov Models},
    author={Johnson, Matthew J. and Willsky, Alan S.},
    journal={Journal of Machine Learning Research},
    pages={673--701},
    volume={14},
    month={February},
    year={2013},
}An analgesic for high-performance audio on iOS and OSX. 
 Really fast audio in iOS and Mac OS X using Audio Units is hard, and will leave you scarred and bloody. What used to take days can now be done with just a few lines of code. 
 Getting Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setInputBlock:^(float *newAudio, UInt32 numSamples, UInt32 numChannels) {
    // Now you're getting audio from the microphone every 20 milliseconds or so. How's that for easy?
    // Audio comes in interleaved, so,
    // if numChannels = 2, newAudio[0] is channel 1, newAudio[1] is channel 2, newAudio[2] is channel 1, etc.
}];
[audioManager play]; 
 Playing Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setOutputBlock:^(float *audioToPlay, UInt32 numSamples, UInt32 numChannels) {
    // All you have to do is put your audio into ""audioToPlay"".
}];
[audioManager play]; 
 Does anybody actually use it? 
 Yep. Novocaine is result of three years of work on the audio engine of  Octave ,  Fourier  and  oScope , a powerful suite of audio analysis apps. Please do check them out! 
 A thing to note: 
 The RingBuffer class is written in C++ to make things extra zippy, so the classes that use it will have to be Objective-C++. Change all the files that use RingBuffer from MyClass.m to MyClass.mm. 
 Want some examples? 
 Inside of ViewController.mm are a bunch of tiny little examples I wrote. Uncomment one and see how it sounds. 
Do note, however, for examples involving play-through, that you should be using headphones. Having the 
mic and speaker close to each other will produce some gnarly feedback.   
 Want to learn the nitty-gritty of Core Audio? 
 If you want to get down and dirty, if you want to get brave and get close to the hardware, I can only point you to the places where I learned how to do this stuff. Chris Adamson and Michael Tyson are two giants in the field of iOS audio, and they each wrote indispensable blog posts ( this is Chris's ,  this is Michael's ). Also, Chris Adamson now has a  whole gosh-darned BOOK on Core Audio . I would have done unspeakable things to get my hands on this when I was first starting. 
My Code for the Netflix Prize 
 I'm not aware of folks having published their code for the Netflix Prize. Here's mine. 
Under the team name ""Hi!"", I competed alone in college. I did it mostly for fun, and to learn modern machine learning techniques. It was an incredibly valuable, but strenuous, time. Well worth it on all fronts, though.  
I peaked out at #45 or so, and then dropped out to work on my senior thesis, and came in #145 or so.   
What I learned in the process was that smarter wasn't always better -- make an algorithm, and then scale it up, and then make a dozen tweaks to it, and then average all of the results together. That's how you climbed the leaderboard.    
 Anyhoo, I haven't touched this code in awhile, but perhaps it'll be useful to folks interested in competitive data mining. 
Specifically, the lessons I learned: 
 
 Get the raw data into a saved and manageable format  fast . The easier it is to load your data in and start mutating it, the better. 
 If doing simple pivots on your data is hard, and slows you down from visualizing whats in your data, spend time making data structures which make that easy.   
 Generalize. Iterate. If you have a method you think will work, but it has a lot of knobs, and you don't know the best way to set those knobs, make it easy for you to try  every possible iteration . There is often not a good way to figure out what the  best  approach is. You will have to try many of them in order to build up an intuition. Specifically, that means (for me) a pluggable architecture. If there's ten ways to try a particular step, make sure you write your overarching algorithm so that it takes a function that you can pass to it, as opposed to having a method hardwired in the code. That way, you can hotswap all your ideas.   
 Speed is a feature. Of course you make sure it works first. But your goal is to see if something works. If an algorithm takes a day to run, but you can spend five hours making it run in 1/3 of a day, do it. You'll be running it over and over again, and you'll learn more if you can iterate.  
 
 As for the technical nitty-gritty, everything that's speed sensitive is written in Cython, which was the best balance of speed and convenience in 2009. If I were to do it al again, I would use (Numba)[http://github.com/numba/numba].   
 The original data is gone, I believe, but I might have it stored somewhere. I'll look for that.  NURBS - Non Uniform Rational B-Splines. 
 This python module is a revival and update of Runar Tenfjord's NURBS toolbox, which itself
is a port of Mark Spink's SCILAB/MATLAB tolbox to python with help of numpy. 
 Dependency 
 Python 2.0 or above 
NumPy 
Dislin -> optional but recomended 
PyOpenGL -> optional   
 Installation 
 Just run   python setup.py install   
 License 
 Runar Tenfjord originally relased this package under the GPL Version 2 license,  
so I suppose that means it has to stay that way.    
 Originally by: Runar Tenfjord, runten@netcom.no 
Minor updates to work with NumPy by Alex Wiltschko  cuda-tests 
 Gotta learn some CUDA stuffpypatent 
 Scrape patents from the USPTOairruler 
 A ruler. Made of air. paralleltools 
 A summary of parallelizing moderate amounts of work in Pythonnsgt 
 Non-stationary Gabor transforms (GitHub mirror of http://grrrr.org/research/software/nsgt/)IDA 
 This code accompanies the publication from the Whitesides lab to Lab on a Chip, concerning automated analysis of red blood cell health using affordable field tests. Specifically, this code implements the automated extraction of scanned AMPS tubes from flatbed scanner images, the distillation of those images into 1D data traces, and then the automated identification of the anemic disease state of the blood in those 1D data traces, as well as the prediction of continuously-varying red blood cell (RBC) parameters. 
 Installation 
 This code requires Python, as well as some extra 3rd-party libraries. All routines have only been tested on Mac OS, but should work on Linux. No guarantees for Windows.
1) First, we recommend using the ""Anaconda"" Python distribution, specifically the Python 2.7 version.  Download and install here .
1) With anaconda installed, you will need one extra library, to read TIFF files.
 pip install imageio 
1) You should be able to run the notebooks now. Inside this code repository, start up an IPython notebook:
 jupyter notebook 
1) You should now be able to browser around the ""extraction"" and ""analysis"" folders, which contain the relevant code. 
 Running extraction 
 The first step required will be to prepare the raw data of TIFF file scans of 4x3=12 tubes from a flatbed scanner. We will also have to associate metadata for each patient that the blood in a tube was drawn from.
Our end goal will be a 1D array for each tube, along with the corresponding patient data (anemic state & RBC parameters). 
 The extraction algorithm is explained step-by-step in the notebook  extraction/Explaining the Extraction Algorithm.ipynb .
The implementation we use in the paper (which also fuses patient metadata with AMPS image data) can be found in  extraction/Data Extraction Pipeline.ipynb . Most of the code in this notebook is specific to the particular Excel file format that we used to record patient metadata, and may have to be largely rewritten for reuse. 
 Running analysis 
 There are two sets of analyses done in the paper: classification and regression. 
 Running classification analysis 
 The goal of this analysis is to predict disease state only from the 1D data trace extracted from each AMPS tube. We use logistic regression, a linear classifier, and transform the 1D data representation using PCA to remove redundancy and constrain the input dimensionality of the problem. We also used Bayesian Optimization (bayesopt) to tune the hyperparameters of the problem, including the specific output dimension of PCA, the regularization parameter of logistic regression, and some image preprocessing parameters. Unfortunately, the service we used for bayesopt is no longer available. If you would like to automatically tune these parameters, we recommend either using random search (a surprisingly effective hueristic), or the open source library ""Spearmint"", upon which the now-defunct service we used was based, or products from the company SigOpt, which also implements bayesopt. The file we used to automatically tune these hypers is  classify.py .
The best set of hyperparameters is stored in the notebook  Analyzing best classification.ipynb .
This notebook examines ROC performance of the classifier for discriminating different anemia types, as well as the effect of centrifugation time of the tube on IDA classification AUC performance. 
 Running regression analysis. 
 Similar to above, we used a defunct bayesopt service to automatically tune some parameters of this algorithm. The original file is in  regress.py . The original methodology will work well, even without automated tuning.
The best set of hyperparameters is stored in the notebook  Analyzing best regression.ipynb . 
 License 
 See the LICENSE file. It is under a GPL license, and this code may only be used for academic purposes.adabayes 
 To do: 
 
 [x] Find candidate last layer features (DeCAF, Overfeat) 
 [x] Find AlexNet code (5 convolutional layers with max-pooling, then three fully connected layers) 
 [X]  Find download script for MNIST dataset 
 [X]  Find download script for CIFAR10 dataset 
 [x] Fork torch-dist repo 
 [x] Update torch-dist repo for OS X 10.10 install 
 [x] Add new required submodules to distro (nnx, iTorch, ccn2, cunnx, cudnn, sdl2, cutorch) 
 [x] Figure out model serialization and loading 
 Built-in model serialization.  Loading  and  saving . 
 There is also facebook's  Thrift library , which I haven't seen many examples for. 
 
 
 [ ] Get the data out of the  DataSource  models that we're using 
 [ ] Train and Whetlab a net on MNIST (to get the whole workflow going) 
 [ ] Train and Whetlab a net on CIFAR10 
 [ ] Train and Whetlab a net on STL10 
 [ ] Build dumb ensemble on CIFAR10 
 [ ] Build dumb ensemble on STL10 
 [ ] Grok boosting criterion 
 [ ] Whetlab a net with progressive ensembling on CIFAR10 
 [ ] Whetlab a net with progressive ensembling on STL10 
 [ ] Whetlab a net with progressive ensembling on the last-layer features of ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on CIFAR10 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on STL10 
 [ ] Extract last-layer ImageNet features 
 [ ] Host last-layer ImageNet features 
 [ ] Build download script for last-layer ImageNet features 
 [ ] Train and Whetlab a net on last-layer features on ImageNet 
 [ ] Build a dumb ensemble on ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on the last-layer features of ImageNet 
 
 Collecting some resources 
 AlexNet:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/alexnet.lua 
 I think this is NiN:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/googlenet.lua 
 OverFeat:
https://github.com/facebook/fbcunn/blob/master/examples/imagenet/models/overfeat_cunn.lua 
 Multiclass criterion:
https://github.com/torch/nn/blob/master/doc/criterion.md#classnllcriterion 
 Some other interesting nets:
https://github.com/culurciello/profiling 
 Bunch of demos, not all nets:
https://github.com/torch/demos 
 Overfeat features:
http://cilvr.nyu.edu/doku.php?id=software:overfeat:start 
 Decaf ImageNet submission:
https://github.com/UCB-ICSI-Vision-Group/decaf-release/wiki/imagenet 
 Some other net implementations:
https://github.com/eladhoffer/ImageNet-TrainingConda recipes for installing packages from the Torch ecosystem. 
 NOTE: No longer maintained. 
 To install packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 conda install lua=5.2 lua-science -c alexbw 
 Available versions of Lua: 2.0, 5.1, 5.2, 5.3 
 2.0 is LuaJIT 
 ``` 
 To build packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Get the newest version of conda, as well as some conda build tools 
 conda update conda -y
conda install conda-build anaconda-client -y 
 Build all packages 
 sh build_all.sh 
 Ideally, all you have to do to install everything is this 
 conda install lua=5.2 lua-science
``` 
 TODO:
 - https://github.com/AlexMili/torch-dataframe
 - https://github.com/twitter/torch-ipc
 - https://github.com/twitter/torch-distlearn
 - https://github.com/twitter/torch-dataset 
 Resources: 
 
 
 Making packages relocatable (LuaJIT hard-codes path) 
 
 
 Build instructions for luarocks 
 
 
 Build instructions for Lua 
 
 
 Patching files with git diffs is finicky 
 
 
 Linking against readline  (need a few extra flags, and link against -lncursesw, not -lncurses) 
 
 
 Upgrading old Debian .  Also this . 
 
 
 Misc notes:
 metadata:ns_cfg() â€” defines for YAML directives
main_build: â€”Â defines version numbers 
environ:get_lua_include_dir() â€”Â uses version numbers to locate the include directory
config:Config._get_lua â€”Â uses version numbers to locate the binary
This is where the linked package name is converted into what is usedvalidata 
 Continuous integration for your data 
 We do continuous integration on code. Why not data?
Validata is a small package to run basic sanity checks on your data.
I haven't found anything that aggregates all of these checks and tricks in one place. 
 There is only one method which is exposed,  check(data,labels)  (optionally taking data or labels).
If any data check fails, it throws a well-named error, as well as hints for how you might fix the problem -- data covariance matrix ill-conditioned? Try whitening. 
 Initially, this will be a Python/NumPy only package running basic checks, but hopefully it becomes a resource of data sanity and sanitation checks.
Still very much a work in progress. 
 Examples (some implemented, some not) include: 
 
 If your labels are one-hot, are you using all slots? 
 Is the covariance matrix of your data ill-conditioned? 
 Do you have any constant variables? 
 Can you train a classifier to distinguish train and test data, using whether they are in train or test as a label? Indicates different data distributions. 
 If you're using integer labels, are the unique labels contiguous? 
 Do you have just one unique label? 
 Is the data under different labels statistically separable? 
 If you have an old dataset and a new dataset (or two halves of the same dataset), is the distribution of each dimension stationary? Check for divergence with a KS test. 
 What else? I end up applying these tricks in a very ad hoc fashion, whenever a subtle bug pops up, and not rigorously before each project I tackle. I'd like to stuff all these tricks in one place, and run them like a unit test, or a continuous integration test, on data that I start working with. 
 
 Should probably also think about engardebayarea-dl-summerschool 
 Torch notebooks and slides for the Bay Area Deep Learning Summer School 
 Installation Instructions 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 ```
conda install lua=5.2 lua-science -c alexbw 
 Although, you could install other Lua versions like 2.0 (LuaJIT), 5.1, 5.2 and 5.3 
 ``` 
 Clone this repository and start the notebook server 
 ```
git clone https://github.com/alexbw/bayarea-dl-summerschool.git
cd bayarea-dl-summerschool
itorch notebook 
 Will open a browser tab, then you can navigate to the notebooks 
 ```","Boston, MA",False,Google,7,DevOps,95,0.31,0.38,0.29,0,False,https://avatars.githubusercontent.com/u/161935?u=f722a589176ab3dce6285bcce174117e3c103ec3&v=4,2009-12-04T14:50:40Z,2022-08-23T18:31:52Z,,False,False,False,False,False,True,False,0,396,332,0,47,2016-08-15 18:39:55,14
Shell,alexbw,Alex Wiltschko,,alex.bw@gmail.com,"Sampling Inference for Bayesian HSMMs and HMMs 
 This is a Python library for approximate unsupervised sampling inference in
Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov
Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM
and HDP-HSMM, via the weak-limit approximation. 
 There are also some plugins to extend the functionality: 
 
 factorial models 
 autoregressive models 
 collapsed HDP sampling inference . 
 
 The inference can be run in parallel over multiple cores and/or multiple
machines (even on EC2!) using  ipython 's
excellent  ipython.parallel  module. Someday I might even document how to do
it! 
 Installing 
 You can clone this library and its dependencies with 
 git clone --recursive git://github.com/mattjj/pyhsmm.git 
 The library depends on  numpy ,  scipy , and, for visualization,  matplotlib . 
 Disabling assertions may speed things up; to disable assertions, run your
CPython interpreter with the  -O  flag. 
 A Simple Demonstration 
 Here's how to draw from the HDP-HSMM posterior over HSMMs given a sequence of
observations. (The same example, along with the code to generate the synthetic
data loaded in this example, can be found in  examples/basic.py .) 
 Let's say we have some 2D data in a data.txt file: 
 bash
 head -5 data.txt
-3.711962552600095444e-02 1.456401745267922598e-01
7.553818775915704942e-02 2.457422192223903679e-01
-2.465977987699214502e+00 5.537627981813508793e-01
-7.031638516485749779e-01 1.536468304146855757e-01
-9.224669847039665971e-01 3.680035337673161489e-01 
 In Python, we can plot the data in a 2D plot, collapsing out the time dimension: 
 ```python
import numpy as np
from matplotlib import pyplot as plt 
 data = np.loadtxt('data.txt')
plt.plot(data[:,0],data[:,1],'kx')
``` 
 
 We can also make a plot of time versus the first principal component: 
 python
from pyhsmm.util.plot import pca_project_data
plt.plot(pca_project_data(data,1)) 
 
 To learn an HSMM, we'll use  pyhsmm  to create an  HSMM  instance using some
reasonable hyperparameters. We'll ask this model to infer the number of states
as well (since an HDP-HSMM is instantiated by default), so we'll give it an
 Nmax  parameter: 
 ```python
import pyhsmm
import pyhsmm.basic.distributions as distributions 
 obs_dim = 2
Nmax = 25 
 obs_hypparams = {'mu_0':np.zeros(obs_dim),
                'sigma_0':np.eye(obs_dim),
                'kappa_0':0.3,
                'nu_0':obs_dim+5}
dur_hypparams = {'alpha_0':2*30,
                 'beta_0':2} 
 obs_distns = [distributions.Gaussian( obs_hypparams) for state in range(Nmax)]
dur_distns = [distributions.PoissonDuration( dur_hypparams) for state in range(Nmax)] 
 posteriormodel = pyhsmm.models.HSMM(
        alpha=6.,gamma=6., # better to sample over these; see concentration-resampling.py
        init_state_concentration=6., # pretty inconsequential
        obs_distns=obs_distns,
        dur_distns=dur_distns,
        trunc=60) # duration truncation speeds things up when it's possible
``` 
 (The first two arguments set the ""new-table"" proportionality constant for the
meta-Chinese Restaurant Process and the other CRPs, respectively, in the HDP
prior on transition matrices. For this example, they really don't matter at
all, but on real data it's much better to infer these parameters, as in
 examples/concentration_resampling.py .) 
 The  trunc  parameter is an optional argument that can speed up inference: it
sets a truncation limit on the maximum duration for any state. If you don't
pass in the  trunc  argument, no truncation is used and all possible state
duration lengths are considered. 
 Then, we add the data we want to condition on: 
 python
posteriormodel.add_data(data) 
 (If we had multiple observation sequences to learn from, we could add them to the
model just by calling  add_data()  for each observation sequence.) 
 Now we run a resampling loop. For each iteration of the loop, all the latent
variables of the model will be resampled by Gibbs sampling steps, including the
transition matrix, the observation means and covariances, the duration
parameters, and the hidden state sequence. We'll also copy some samples so that
we can plot them. 
 python
models = []
for idx in progprint_xrange(150):
    posteriormodel.resample_model()
    if (idx+1) % 10 == 0:
        models.append(copy.deepcopy(posteriormodel)) 
 Now we can plot our saved samples: 
 python
fig = plt.figure()
for idx, model in enumerate(models):
    plt.clf()
    model.plot()
    plt.gcf().suptitle('HDP-HSMM sampled after %d iterations' % (10*(idx+1)))
    plt.savefig('iter_%.3d.png' % (10*(idx+1))) 
 
 I generated these data from an HSMM that looked like this: 
 
 So the posterior samples look pretty good! 
 Speed 
 HSMMs constitute a much more powerful model class than plain-old HMMs, and that
enhanced power comes with a computational price: each sampling iteration for an
HSMM is much slower than that of an HMM. But that price is often worthwhile if
you want to place priors on state durations or have the model learn duration
structure present in the data. (In the example, strong duration structure is
what made the inference algorithm latch onto the correct explanation so
easily.) In addition, the increased cost of each iteration often pays for
itself, since HSMM samplers empirically seem to take fewer iterations to
converge than comparable HMM samplers. 
 Using my nothing-special i7-920 desktop machine and a NumPy/SciPy built against
Intel's MKL BLAS (which generally outperforms ATLAS for vectorized operations)
along with the Eigen-backed classes, here's how long the demo iterations took: 
 $ python examples/hsmm.py
.........................  [  25/100,    0.05sec avg,    3.95sec ETA ]
.........................  [  50/100,    0.05sec avg,    2.64sec ETA ]
.........................  [  75/100,    0.05sec avg,    1.34sec ETA ]
.........................  [ 100/100,    0.05sec avg,    0.05sec ETA ]
   0.05sec avg,    5.21sec total 
 Extending the Code 
 To add your own observation or duration distributions, implement the interfaces
defined in  basic/abstractions.py . Also see the plugins. To get a flavor of
the style, see  pybasicbayes . 
 Contributors 
 Contributions by Chia-ying Lee. 
 References 
 
 
 Matthew J. Johnson and Alan S. Willsky.  Bayesian Nonparametric Hidden
  Semi-Markov Models .
  Journal of Machine Learning Research (JMLR), 14:673â€“701, February 2013. 
 
 
 Matthew J. Johnson and Alan S. Willsky,  The Hierarchical Dirichlet Process
  Hidden Semi-Markov Model . 26th
  Conference on Uncertainty in Artificial Intelligence (UAI 2010), Avalon,
  California, July 2010. 
 
 
 bibtex
@article{johnson2013hdphsmm,
    title={Bayesian Nonparametric Hidden Semi-Markov Models},
    author={Johnson, Matthew J. and Willsky, Alan S.},
    journal={Journal of Machine Learning Research},
    pages={673--701},
    volume={14},
    month={February},
    year={2013},
}An analgesic for high-performance audio on iOS and OSX. 
 Really fast audio in iOS and Mac OS X using Audio Units is hard, and will leave you scarred and bloody. What used to take days can now be done with just a few lines of code. 
 Getting Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setInputBlock:^(float *newAudio, UInt32 numSamples, UInt32 numChannels) {
    // Now you're getting audio from the microphone every 20 milliseconds or so. How's that for easy?
    // Audio comes in interleaved, so,
    // if numChannels = 2, newAudio[0] is channel 1, newAudio[1] is channel 2, newAudio[2] is channel 1, etc.
}];
[audioManager play]; 
 Playing Audio 
 objective-c
Novocaine *audioManager = [Novocaine audioManager];
[audioManager setOutputBlock:^(float *audioToPlay, UInt32 numSamples, UInt32 numChannels) {
    // All you have to do is put your audio into ""audioToPlay"".
}];
[audioManager play]; 
 Does anybody actually use it? 
 Yep. Novocaine is result of three years of work on the audio engine of  Octave ,  Fourier  and  oScope , a powerful suite of audio analysis apps. Please do check them out! 
 A thing to note: 
 The RingBuffer class is written in C++ to make things extra zippy, so the classes that use it will have to be Objective-C++. Change all the files that use RingBuffer from MyClass.m to MyClass.mm. 
 Want some examples? 
 Inside of ViewController.mm are a bunch of tiny little examples I wrote. Uncomment one and see how it sounds. 
Do note, however, for examples involving play-through, that you should be using headphones. Having the 
mic and speaker close to each other will produce some gnarly feedback.   
 Want to learn the nitty-gritty of Core Audio? 
 If you want to get down and dirty, if you want to get brave and get close to the hardware, I can only point you to the places where I learned how to do this stuff. Chris Adamson and Michael Tyson are two giants in the field of iOS audio, and they each wrote indispensable blog posts ( this is Chris's ,  this is Michael's ). Also, Chris Adamson now has a  whole gosh-darned BOOK on Core Audio . I would have done unspeakable things to get my hands on this when I was first starting. 
My Code for the Netflix Prize 
 I'm not aware of folks having published their code for the Netflix Prize. Here's mine. 
Under the team name ""Hi!"", I competed alone in college. I did it mostly for fun, and to learn modern machine learning techniques. It was an incredibly valuable, but strenuous, time. Well worth it on all fronts, though.  
I peaked out at #45 or so, and then dropped out to work on my senior thesis, and came in #145 or so.   
What I learned in the process was that smarter wasn't always better -- make an algorithm, and then scale it up, and then make a dozen tweaks to it, and then average all of the results together. That's how you climbed the leaderboard.    
 Anyhoo, I haven't touched this code in awhile, but perhaps it'll be useful to folks interested in competitive data mining. 
Specifically, the lessons I learned: 
 
 Get the raw data into a saved and manageable format  fast . The easier it is to load your data in and start mutating it, the better. 
 If doing simple pivots on your data is hard, and slows you down from visualizing whats in your data, spend time making data structures which make that easy.   
 Generalize. Iterate. If you have a method you think will work, but it has a lot of knobs, and you don't know the best way to set those knobs, make it easy for you to try  every possible iteration . There is often not a good way to figure out what the  best  approach is. You will have to try many of them in order to build up an intuition. Specifically, that means (for me) a pluggable architecture. If there's ten ways to try a particular step, make sure you write your overarching algorithm so that it takes a function that you can pass to it, as opposed to having a method hardwired in the code. That way, you can hotswap all your ideas.   
 Speed is a feature. Of course you make sure it works first. But your goal is to see if something works. If an algorithm takes a day to run, but you can spend five hours making it run in 1/3 of a day, do it. You'll be running it over and over again, and you'll learn more if you can iterate.  
 
 As for the technical nitty-gritty, everything that's speed sensitive is written in Cython, which was the best balance of speed and convenience in 2009. If I were to do it al again, I would use (Numba)[http://github.com/numba/numba].   
 The original data is gone, I believe, but I might have it stored somewhere. I'll look for that.  NURBS - Non Uniform Rational B-Splines. 
 This python module is a revival and update of Runar Tenfjord's NURBS toolbox, which itself
is a port of Mark Spink's SCILAB/MATLAB tolbox to python with help of numpy. 
 Dependency 
 Python 2.0 or above 
NumPy 
Dislin -> optional but recomended 
PyOpenGL -> optional   
 Installation 
 Just run   python setup.py install   
 License 
 Runar Tenfjord originally relased this package under the GPL Version 2 license,  
so I suppose that means it has to stay that way.    
 Originally by: Runar Tenfjord, runten@netcom.no 
Minor updates to work with NumPy by Alex Wiltschko  cuda-tests 
 Gotta learn some CUDA stuffpypatent 
 Scrape patents from the USPTOairruler 
 A ruler. Made of air. paralleltools 
 A summary of parallelizing moderate amounts of work in Pythonnsgt 
 Non-stationary Gabor transforms (GitHub mirror of http://grrrr.org/research/software/nsgt/)IDA 
 This code accompanies the publication from the Whitesides lab to Lab on a Chip, concerning automated analysis of red blood cell health using affordable field tests. Specifically, this code implements the automated extraction of scanned AMPS tubes from flatbed scanner images, the distillation of those images into 1D data traces, and then the automated identification of the anemic disease state of the blood in those 1D data traces, as well as the prediction of continuously-varying red blood cell (RBC) parameters. 
 Installation 
 This code requires Python, as well as some extra 3rd-party libraries. All routines have only been tested on Mac OS, but should work on Linux. No guarantees for Windows.
1) First, we recommend using the ""Anaconda"" Python distribution, specifically the Python 2.7 version.  Download and install here .
1) With anaconda installed, you will need one extra library, to read TIFF files.
 pip install imageio 
1) You should be able to run the notebooks now. Inside this code repository, start up an IPython notebook:
 jupyter notebook 
1) You should now be able to browser around the ""extraction"" and ""analysis"" folders, which contain the relevant code. 
 Running extraction 
 The first step required will be to prepare the raw data of TIFF file scans of 4x3=12 tubes from a flatbed scanner. We will also have to associate metadata for each patient that the blood in a tube was drawn from.
Our end goal will be a 1D array for each tube, along with the corresponding patient data (anemic state & RBC parameters). 
 The extraction algorithm is explained step-by-step in the notebook  extraction/Explaining the Extraction Algorithm.ipynb .
The implementation we use in the paper (which also fuses patient metadata with AMPS image data) can be found in  extraction/Data Extraction Pipeline.ipynb . Most of the code in this notebook is specific to the particular Excel file format that we used to record patient metadata, and may have to be largely rewritten for reuse. 
 Running analysis 
 There are two sets of analyses done in the paper: classification and regression. 
 Running classification analysis 
 The goal of this analysis is to predict disease state only from the 1D data trace extracted from each AMPS tube. We use logistic regression, a linear classifier, and transform the 1D data representation using PCA to remove redundancy and constrain the input dimensionality of the problem. We also used Bayesian Optimization (bayesopt) to tune the hyperparameters of the problem, including the specific output dimension of PCA, the regularization parameter of logistic regression, and some image preprocessing parameters. Unfortunately, the service we used for bayesopt is no longer available. If you would like to automatically tune these parameters, we recommend either using random search (a surprisingly effective hueristic), or the open source library ""Spearmint"", upon which the now-defunct service we used was based, or products from the company SigOpt, which also implements bayesopt. The file we used to automatically tune these hypers is  classify.py .
The best set of hyperparameters is stored in the notebook  Analyzing best classification.ipynb .
This notebook examines ROC performance of the classifier for discriminating different anemia types, as well as the effect of centrifugation time of the tube on IDA classification AUC performance. 
 Running regression analysis. 
 Similar to above, we used a defunct bayesopt service to automatically tune some parameters of this algorithm. The original file is in  regress.py . The original methodology will work well, even without automated tuning.
The best set of hyperparameters is stored in the notebook  Analyzing best regression.ipynb . 
 License 
 See the LICENSE file. It is under a GPL license, and this code may only be used for academic purposes.adabayes 
 To do: 
 
 [x] Find candidate last layer features (DeCAF, Overfeat) 
 [x] Find AlexNet code (5 convolutional layers with max-pooling, then three fully connected layers) 
 [X]  Find download script for MNIST dataset 
 [X]  Find download script for CIFAR10 dataset 
 [x] Fork torch-dist repo 
 [x] Update torch-dist repo for OS X 10.10 install 
 [x] Add new required submodules to distro (nnx, iTorch, ccn2, cunnx, cudnn, sdl2, cutorch) 
 [x] Figure out model serialization and loading 
 Built-in model serialization.  Loading  and  saving . 
 There is also facebook's  Thrift library , which I haven't seen many examples for. 
 
 
 [ ] Get the data out of the  DataSource  models that we're using 
 [ ] Train and Whetlab a net on MNIST (to get the whole workflow going) 
 [ ] Train and Whetlab a net on CIFAR10 
 [ ] Train and Whetlab a net on STL10 
 [ ] Build dumb ensemble on CIFAR10 
 [ ] Build dumb ensemble on STL10 
 [ ] Grok boosting criterion 
 [ ] Whetlab a net with progressive ensembling on CIFAR10 
 [ ] Whetlab a net with progressive ensembling on STL10 
 [ ] Whetlab a net with progressive ensembling on the last-layer features of ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on CIFAR10 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on STL10 
 [ ] Extract last-layer ImageNet features 
 [ ] Host last-layer ImageNet features 
 [ ] Build download script for last-layer ImageNet features 
 [ ] Train and Whetlab a net on last-layer features on ImageNet 
 [ ] Build a dumb ensemble on ImageNet 
 [ ] Whetlab a net with progressive ensembling and tuned class weights on the last-layer features of ImageNet 
 
 Collecting some resources 
 AlexNet:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/alexnet.lua 
 I think this is NiN:
https://github.com/soumith/convnet-benchmarks/blob/master/torch7/imagenet_winners/googlenet.lua 
 OverFeat:
https://github.com/facebook/fbcunn/blob/master/examples/imagenet/models/overfeat_cunn.lua 
 Multiclass criterion:
https://github.com/torch/nn/blob/master/doc/criterion.md#classnllcriterion 
 Some other interesting nets:
https://github.com/culurciello/profiling 
 Bunch of demos, not all nets:
https://github.com/torch/demos 
 Overfeat features:
http://cilvr.nyu.edu/doku.php?id=software:overfeat:start 
 Decaf ImageNet submission:
https://github.com/UCB-ICSI-Vision-Group/decaf-release/wiki/imagenet 
 Some other net implementations:
https://github.com/eladhoffer/ImageNet-TrainingConda recipes for installing packages from the Torch ecosystem. 
 NOTE: No longer maintained. 
 To install packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 conda install lua=5.2 lua-science -c alexbw 
 Available versions of Lua: 2.0, 5.1, 5.2, 5.3 
 2.0 is LuaJIT 
 ``` 
 To build packages 
 ``` 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Get the newest version of conda, as well as some conda build tools 
 conda update conda -y
conda install conda-build anaconda-client -y 
 Build all packages 
 sh build_all.sh 
 Ideally, all you have to do to install everything is this 
 conda install lua=5.2 lua-science
``` 
 TODO:
 - https://github.com/AlexMili/torch-dataframe
 - https://github.com/twitter/torch-ipc
 - https://github.com/twitter/torch-distlearn
 - https://github.com/twitter/torch-dataset 
 Resources: 
 
 
 Making packages relocatable (LuaJIT hard-codes path) 
 
 
 Build instructions for luarocks 
 
 
 Build instructions for Lua 
 
 
 Patching files with git diffs is finicky 
 
 
 Linking against readline  (need a few extra flags, and link against -lncursesw, not -lncurses) 
 
 
 Upgrading old Debian .  Also this . 
 
 
 Misc notes:
 metadata:ns_cfg() â€” defines for YAML directives
main_build: â€”Â defines version numbers 
environ:get_lua_include_dir() â€”Â uses version numbers to locate the include directory
config:Config._get_lua â€”Â uses version numbers to locate the binary
This is where the linked package name is converted into what is usedvalidata 
 Continuous integration for your data 
 We do continuous integration on code. Why not data?
Validata is a small package to run basic sanity checks on your data.
I haven't found anything that aggregates all of these checks and tricks in one place. 
 There is only one method which is exposed,  check(data,labels)  (optionally taking data or labels).
If any data check fails, it throws a well-named error, as well as hints for how you might fix the problem -- data covariance matrix ill-conditioned? Try whitening. 
 Initially, this will be a Python/NumPy only package running basic checks, but hopefully it becomes a resource of data sanity and sanitation checks.
Still very much a work in progress. 
 Examples (some implemented, some not) include: 
 
 If your labels are one-hot, are you using all slots? 
 Is the covariance matrix of your data ill-conditioned? 
 Do you have any constant variables? 
 Can you train a classifier to distinguish train and test data, using whether they are in train or test as a label? Indicates different data distributions. 
 If you're using integer labels, are the unique labels contiguous? 
 Do you have just one unique label? 
 Is the data under different labels statistically separable? 
 If you have an old dataset and a new dataset (or two halves of the same dataset), is the distribution of each dimension stationary? Check for divergence with a KS test. 
 What else? I end up applying these tricks in a very ad hoc fashion, whenever a subtle bug pops up, and not rigorously before each project I tackle. I'd like to stuff all these tricks in one place, and run them like a unit test, or a continuous integration test, on data that I start working with. 
 
 Should probably also think about engardebayarea-dl-summerschool 
 Torch notebooks and slides for the Bay Area Deep Learning Summer School 
 Installation Instructions 
 Install anaconda if you don't have it (instructions here for OS X) 
 wget http://repo.continuum.io/miniconda/Miniconda-latest-MacOSX-x86_64.sh
sh Miniconda-latest-MacOSX-x86_64.sh -b -p $HOME/anaconda 
 Add anaconda to your $PATH 
 export PATH=$HOME/anaconda/bin:$PATH 
 Install Lua & Torch 
 ```
conda install lua=5.2 lua-science -c alexbw 
 Although, you could install other Lua versions like 2.0 (LuaJIT), 5.1, 5.2 and 5.3 
 ``` 
 Clone this repository and start the notebook server 
 ```
git clone https://github.com/alexbw/bayarea-dl-summerschool.git
cd bayarea-dl-summerschool
itorch notebook 
 Will open a browser tab, then you can navigate to the notebooks 
 ```","Boston, MA",False,Google,7,DevOps,95,0.31,0.38,0.29,0,False,https://avatars.githubusercontent.com/u/161935?u=f722a589176ab3dce6285bcce174117e3c103ec3&v=4,2009-12-04T14:50:40Z,2022-08-23T18:31:52Z,,False,False,False,False,False,True,False,0,396,332,0,47,2016-08-15 18:39:55,2
