{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Libraries #\n",
    "#############\n",
    "import json\n",
    "import wget\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#############\n",
    "# Constants #\n",
    "#############\n",
    "\n",
    "URL = \"https://api.github.com/search/repositories?q=\"  # The basic URL to use the GitHub API\n",
    "QUERY = \"user:MustafaYasin\"  # The personalized query (for instance, to get repositories from user 'MustafaYasin')\n",
    "SUB_QUERIES = [\"+created%3A<%3D2021-03-31\",\n",
    "              \"+created%3A>%3D2014-01-01\"]  # Different sub-queries if you need to collect more than 1000 elements\n",
    "PARAMETERS = \"&per_page=100\"  # Additional parameters for the query (by default 100 items per page)\n",
    "DELAY_BETWEEN_QUERIES = 10  # The time to wait between different queries to GitHub (to avoid be banned)\n",
    "OUTPUT_FOLDER = \"../user_data_csv/\"  # Folder where ZIP files will be stored\n",
    "OUTPUT_CSV_FILE = \"../user_data_csv/repositories.csv\"  # Path to the CSV file generated as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Functions #\n",
    "#############\n",
    "\n",
    "def getUrl(url):\n",
    "    \"\"\" Given a URL it returns its body \"\"\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subquery 1 of 2 ...\n",
      "No. of pages = 1\n",
      "No. of pages = 1\n",
      "Processing page 1 of 1 ...\n",
      "Downloading repository 'MustafaYasin' from user 'MustafaYasin' ...\n",
      "Downloading repository 'asp' from user 'MustafaYasin' ...\n",
      "Downloading repository 'connectfour' from user 'MustafaYasin' ...\n",
      "Downloading repository 'infovis' from user 'MustafaYasin' ...\n",
      "Downloading repository 'vscode' from user 'MustafaYasin' ...\n",
      "Downloading repository 'homepage' from user 'MustafaYasin' ...\n",
      "Sleeping 10 seconds before the new query ...\n",
      "Processing subquery 2 of 2 ...\n",
      "No. of pages = 1\n",
      "No. of pages = 1\n",
      "Processing page 1 of 1 ...\n",
      "Downloading repository 'iui' from user 'MustafaYasin' ...\n",
      "Downloading repository 'MustafaYasin' from user 'MustafaYasin' ...\n",
      "Downloading repository 'asp' from user 'MustafaYasin' ...\n",
      "Downloading repository 'connectfour' from user 'MustafaYasin' ...\n",
      "Downloading repository 'pytorch-tutorials' from user 'MustafaYasin' ...\n",
      "Downloading repository 'pyaem' from user 'MustafaYasin' ...\n",
      "Downloading repository 'infovis' from user 'MustafaYasin' ...\n",
      "Downloading repository 'vscode' from user 'MustafaYasin' ...\n",
      "Downloading repository 'task-tracker' from user 'MustafaYasin' ...\n",
      "Downloading repository 'ubungen' from user 'MustafaYasin' ...\n",
      "Downloading repository 'thesis' from user 'MustafaYasin' ...\n",
      "Downloading repository 'pem-ml' from user 'MustafaYasin' ...\n",
      "Downloading repository 'homepage' from user 'MustafaYasin' ...\n",
      "Downloading repository 'DataStructuresAndAlgorithms' from user 'MustafaYasin' ...\n",
      "DONE! 20 repositories have been processed.\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# MAIN #\n",
    "########\n",
    "\n",
    "def download_zip(download_url, out_file_path, user, repository, clone_url)\n",
    "    try:\n",
    "        wget.download(download_url, out=out_file_path)\n",
    "        repositories.writerow([user, repository, clone_url, \"downloaded\"])\n",
    "    except Exception as e:\n",
    "        print(\"Could not download file {}\".format(download_url))\n",
    "        print(e)\n",
    "        repositories.writerow([user, repository, clone_url, \"error when downloading\"])\n",
    "\n",
    "def make_zip(item):\n",
    "    user = item['owner']['login']\n",
    "    repository = item['name']\n",
    "    # Download the zip file of the current project\n",
    "    print(\"Downloading repository '%s' from user '%s' ...\" % (repository, user))\n",
    "    clone_url = item['clone_url']\n",
    "    fileToDownload = url[0:len(url) - 4] + \"/archive/refs/heads/master.zip\"\n",
    "    fileName = item['full_name'].replace(\"/\", \"#\") + \".zip\"\n",
    "    return fileToDownload, fileName, user, repository, clone_url\n",
    "# To save the number of repositories processed\n",
    "countOfRepositories = 0\n",
    "\n",
    "# Output CSV file which will contain information about repositories\n",
    "\n",
    "\n",
    "with open(OUTPUT_CSV_FILE, 'w') as csv_file:\n",
    "    repositories = csv.writer(csv_file, delimiter=',')\n",
    "    # Run queries to get information in json format and download ZIP file for each repository\n",
    "    for subquery in range(1, len(SUB_QUERIES) + 1):\n",
    "\n",
    "        print(\"Processing subquery \" + str(subquery) + \" of \" + str(len(SUB_QUERIES)) + \" ...\")\n",
    "        # Obtain the number of pages for the current subquery (by default each page contains 100 items)\n",
    "\n",
    "        url = URL + QUERY + str(SUB_QUERIES[subquery - 1]) + PARAMETERS\n",
    "        data = json.loads(json.dumps(getUrl(url)))\n",
    "        numberOfPages = int(math.ceil(data['total_count'] / 100.0))\n",
    "        \n",
    "        print(\"No. of pages = \" + str(numberOfPages))\n",
    "        print(\"No. of pages = \" + str(numberOfPages))\n",
    "\n",
    "        # Results are in different pages\n",
    "        for currentPage in range(1, numberOfPages + 1):\n",
    "            print(\"Processing page \" + str(currentPage) + \" of \" + str(numberOfPages) + \" ...\")\n",
    "            url = URL + QUERY + str(SUB_QUERIES[subquery - 1]) + PARAMETERS + \"&page=\" + str(currentPage)\n",
    "            data = json.loads(json.dumps(getUrl(url)))\n",
    "            # Iteration over all the repositories in the current json content page\n",
    "            for item in data['items']:\n",
    "                # Obtain user and repository names\n",
    "                fileToDownload, fileName, user, repository, clone_url = make_zip(item)\n",
    "                download_zip(fileToDownload, OUTPUT_FOLDER + fileName, user, repository, clone_url)\n",
    "                # Update repositories counter\n",
    "                countOfRepositories = countOfRepositories + 1\n",
    "\n",
    "        # A delay between different sub-queries\n",
    "        if subquery < len(SUB_QUERIES):\n",
    "            print(\"Sleeping \" + str(DELAY_BETWEEN_QUERIES) + \" seconds before the new query ...\")\n",
    "            time.sleep(DELAY_BETWEEN_QUERIES)\n",
    "\n",
    "    print(\"DONE! \" + str(countOfRepositories) + \" repositories have been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "474cabef28ef5f39850ae0283db27a2b2b64f747313c5bcb210a7b2692fe8216"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
