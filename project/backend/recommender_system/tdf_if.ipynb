{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import copy\n",
    "import pickle\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/myasin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERNAMES</th>\n",
       "      <th>READMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alexbw</td>\n",
       "      <td>Sampling Inference for Bayesian HSMMs and HMMs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iassael</td>\n",
       "      <td>DEARanking \\n Proposing a hybrid DEA/Polynomia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bshillingford</td>\n",
       "      <td>id3tag-fix codehackathon2014 \\n Team members:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hmansell</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clementfarabet</td>\n",
       "      <td>sys \\n Has moved to a more community friendly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ajabri</td>\n",
       "      <td>pytorch-maml \\n This is a PyTorch implementati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USERNAMES</td>\n",
       "      <td>READMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coryf</td>\n",
       "      <td>homebrew \\n Personal homebrew formula Sudoku C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jrodrigomg</td>\n",
       "      <td>SERVIDOR NODEJS PROYECTO 1, SISTEMAS OPERATIVO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vascofernandes</td>\n",
       "      <td>CustomersVRPF \\n The project consists of two m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        USERNAMES                                            READMES\n",
       "0          alexbw  Sampling Inference for Bayesian HSMMs and HMMs...\n",
       "1         iassael  DEARanking \\n Proposing a hybrid DEA/Polynomia...\n",
       "2   bshillingford  id3tag-fix codehackathon2014 \\n Team members:\\...\n",
       "3        hmansell                                                NaN\n",
       "4  clementfarabet  sys \\n Has moved to a more community friendly ...\n",
       "5          ajabri  pytorch-maml \\n This is a PyTorch implementati...\n",
       "6       USERNAMES                                            READMES\n",
       "7           coryf  homebrew \\n Personal homebrew formula Sudoku C...\n",
       "8      jrodrigomg  SERVIDOR NODEJS PROYECTO 1, SISTEMAS OPERATIVO...\n",
       "9  vascofernandes  CustomersVRPF \\n The project consists of two m..."
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the csv file with all downloaded READMES\n",
    "df = pd.read_csv(\"../user_data_csv/csv_readme_per_user.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different methods to clean the text e.g. remove appestorph and unnessary signs\n",
    "def clean_df(df):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    df['READMES'] = df['READMES'].str.replace('[^a-zA-Z0-9]', ' ', regex=True).str.strip()\n",
    "    df[\"READMES\"] = df[\"READMES\"].apply(str)\n",
    "    df[\"READMES\"] = df[\"READMES\"].str.replace(r\"[\\\"\\',]\", '')\n",
    "    df[\"READMES\"] = df[\"READMES\"].apply(lambda x: ''.join(ch for ch in x if ch not in set(symbols)))\n",
    "    df['READMES'] = df['READMES'].str.replace('\\d+', '') \n",
    "    df['READMES'] = df['READMES'].str.lower()\n",
    "    df = df.dropna(how='all')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctiation\n",
    "def remove_punctuation(df):\n",
    "    df[\"READMES\"] = df['READMES'].str.replace('[^\\w\\s]','')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remvoe all stopwords from the READMES column\n",
    "def remove_stop_words(df):\n",
    "    # import the stopwords from the nltk library\n",
    "    stop_words = stopwords.words('english')\n",
    "    df[\"READMES\"] = df[\"READMES\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all single characters from the READMES column\n",
    "def remove_single_characters(df):\n",
    "    df['READMES'] = df['READMES'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stemming the READMES form the dataframe column\n",
    "# def stemming(df):\n",
    "#     stemmer= PorterStemmer()\n",
    "#     df['READMES'] = df['READMES'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call all function to clean and preprosses the READMES\n",
    "def preprocess(df):\n",
    "    df = clean_df(df)\n",
    "    df = remove_stop_words(df)\n",
    "    df = remove_punctuation(df) \n",
    "    df = remove_single_characters(df)\n",
    "    df = df[df['READMES'].notna()]\n",
    "    # df = stemming(df)\n",
    "    df.to_csv(\"cleaned_df.csv\", index=False)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['READMES'].notna()]\n",
    "df.to_csv(\"cleaned_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(df):\n",
    "    word_frequency_dict = {}\n",
    "    for username,readme in zip(df[\"USERNAMES\"], df[\"READMES\"].str.lower()):\n",
    "        word_frequency_dict[username] = {}\n",
    "        for word in readme.split():\n",
    "            if word not in word_frequency_dict[username].keys():\n",
    "                word_frequency_dict[username][word] = 1\n",
    "            else:\n",
    "                word_frequency_dict[username][word] += 1\n",
    "        word_frequency_dict[username] = (sorted(word_frequency_dict[username].items(), key=lambda x: -x[1]))\n",
    "    return word_frequency_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERNAMES</th>\n",
       "      <th>READMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alexbw</td>\n",
       "      <td>sampling inference bayesian hsmms hmms python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iassael</td>\n",
       "      <td>dearanking proposing hybrid dea polynomial int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bshillingford</td>\n",
       "      <td>idtag fix codehackathon team members brendan s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clementfarabet</td>\n",
       "      <td>sys moved community friendly repo xlua moved c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ajabri</td>\n",
       "      <td>pytorch maml pytorch implementation supervised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USERNAMES</td>\n",
       "      <td>readmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coryf</td>\n",
       "      <td>homebrew personal homebrew formula sudoku curses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jrodrigomg</td>\n",
       "      <td>servidor nodejs proyecto sistemas operativos e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vascofernandes</td>\n",
       "      <td>customersvrpf project consists two main parts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>seba-1511</td>\n",
       "      <td>arduino chrono arduino based chronometer toosk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         USERNAMES                                            READMES\n",
       "0           alexbw  sampling inference bayesian hsmms hmms python ...\n",
       "1          iassael  dearanking proposing hybrid dea polynomial int...\n",
       "2    bshillingford  idtag fix codehackathon team members brendan s...\n",
       "4   clementfarabet  sys moved community friendly repo xlua moved c...\n",
       "5           ajabri  pytorch maml pytorch implementation supervised...\n",
       "6        USERNAMES                                            readmes\n",
       "7            coryf   homebrew personal homebrew formula sudoku curses\n",
       "8       jrodrigomg  servidor nodejs proyecto sistemas operativos e...\n",
       "9   vascofernandes  customersvrpf project consists two main parts ...\n",
       "10       seba-1511  arduino chrono arduino based chronometer toosk..."
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_df.csv\")\n",
    "df = df[df['READMES'].notna()]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(df):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(df['READMES'])]\n",
    "\n",
    "df['READMES'] = df.apply(lemmatize_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0.01, stop_words='english')\n",
    "vectors = vectorizer.fit_transform(df[\"READMES\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termfreq = vectorizer.vocabulary_\n",
    "termfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Computer vison\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = vectorizer.transform([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cosine_similarity(vectors,query_vec).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.03132484, 0.        , 0.00186666, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0212221 , 0.00077672, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01239263, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00301312, 0.        , 0.01311174, 0.        ,\n",
       "       0.01594991, 0.00964138, 0.        , 0.0096587 , 0.        ,\n",
       "       0.        , 0.01870219, 0.        , 0.        , 0.        ,\n",
       "       0.00750794, 0.        , 0.00393149, 0.03187163, 0.0036445 ,\n",
       "       0.        , 0.01126518, 0.00298295, 0.        , 0.        ,\n",
       "       0.00056448, 0.        , 0.00821828, 0.        , 0.        ,\n",
       "       0.00788182, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02371912, 0.        , 0.        , 0.01109768, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0093301 , 0.00682192,\n",
       "       0.        , 0.        , 0.0013319 , 0.        , 0.01074537,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02071307, 0.02803271, 0.        ,\n",
       "       0.00691653, 0.        , 0.        , 0.        , 0.00616765,\n",
       "       0.02039962, 0.        , 0.        , 0.00510396, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02346214, 0.        ,\n",
       "       0.00811301, 0.02092952, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0075885 , 0.        , 0.        , 0.00667834,\n",
       "       0.        , 0.        , 0.        , 0.02570341, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00776567, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00952048, 0.        ,\n",
       "       0.00315152, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01154453, 0.01474028, 0.        , 0.00861914, 0.        ,\n",
       "       0.0051469 , 0.00544334, 0.        , 0.        , 0.        ,\n",
       "       0.00497547, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02097046, 0.        , 0.03691244, 0.        ,\n",
       "       0.04030318, 0.        , 0.01833438, 0.        , 0.        ,\n",
       "       0.0337705 , 0.        , 0.0123471 , 0.        , 0.02009533,\n",
       "       0.        , 0.00356645, 0.01494324, 0.01935998, 0.00888231,\n",
       "       0.        , 0.01371096, 0.01212159, 0.        , 0.        ,\n",
       "       0.00038216, 0.04647568, 0.        , 0.        , 0.01333444,\n",
       "       0.        , 0.01585445, 0.        , 0.01906719, 0.        ,\n",
       "       0.02286885, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00888113, 0.0248141 , 0.        , 0.        , 0.00778169,\n",
       "       0.00387446, 0.00854808, 0.        , 0.        , 0.        ,\n",
       "       0.05401933, 0.        , 0.        , 0.01174953, 0.        ,\n",
       "       0.        , 0.01029907, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01595822, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02931451,\n",
       "       0.06879901, 0.        , 0.01134466, 0.        , 0.        ,\n",
       "       0.03867786, 0.        , 0.        , 0.00379309, 0.01553332,\n",
       "       0.        , 0.        , 0.01874091, 0.00129571, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00902505, 0.        , 0.01579848,\n",
       "       0.00837126, 0.01011938, 0.        , 0.        , 0.        ,\n",
       "       0.03553219, 0.        , 0.07904648, 0.        , 0.0520315 ,\n",
       "       0.        , 0.        , 0.        , 0.00423012, 0.        ,\n",
       "       0.        , 0.00377706, 0.00730462, 0.01071862, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00441957, 0.02729033, 0.        ,\n",
       "       0.        , 0.02215567, 0.        , 0.        , 0.00562289,\n",
       "       0.        , 0.        , 0.        , 0.00685716, 0.        ,\n",
       "       0.0038708 , 0.02558752, 0.        , 0.00947168, 0.        ,\n",
       "       0.01099003, 0.        , 0.        , 0.        , 0.03322675,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00431126,\n",
       "       0.        , 0.00144785, 0.        , 0.01789924, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01009277,\n",
       "       0.        , 0.00370509, 0.        , 0.00567805, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00846405, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02272925, 0.05207871,\n",
       "       0.        , 0.        , 0.00904371, 0.        , 0.0182828 ,\n",
       "       0.        , 0.        , 0.        , 0.04878296, 0.00180273,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01015771, 0.        , 0.        , 0.        , 0.01779512,\n",
       "       0.        , 0.        , 0.00304856, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00895872, 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "themadarchitect\n",
      "edgarriba\n",
      "intermilan\n",
      "rAm1n\n",
      "amirsaffari\n",
      "mirceamironenco\n",
      "SalemAmeen\n",
      "alxndrkalinin\n",
      "gr33ndata\n",
      "valthom\n"
     ]
    }
   ],
   "source": [
    "# Print Top 10 results\n",
    "for i in results.argsort()[-10:][::-1]:\n",
    "    print(df.iloc[i,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(df, query):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    results = cosine_similarity(vectors,query_vec).reshape((-1,))\n",
    "    for name in results.argsort()[-10:][::-1]:\n",
    "        print(df.iloc[name,0])\n",
    "    return results.argsort()[-10:][::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "474cabef28ef5f39850ae0283db27a2b2b64f747313c5bcb210a7b2692fe8216"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
